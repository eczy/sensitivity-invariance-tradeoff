{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import sampler\n",
    "import backbone\n",
    "from losses import TripletLoss\n",
    "import attacks\n",
    "\n",
    "#1. parse input parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', type=str, help=\"config for model\", default=\"./config_mnist.json\")\n",
    "parser.add_argument('--device', type=str, help=\"cuda device no.\", required=True)\n",
    "parser.add_argument('--reset', '-r', action='store_true', help=\"whether or not to reset model dir.\")\n",
    "input_args = parser.parse_args()\n",
    "\n",
    "#2. setup configs\n",
    "with open(input_args.config) as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "root_dir = config['root_dir']\n",
    "model_name = config['model_name']\n",
    "lr_rate = config['lr_rate']\n",
    "batch_size = config['batch_size']\n",
    "n_epochs = config['n_epochs']\n",
    "margin = config['margin']\n",
    "eps = config['epsilon']\n",
    "patience = config['patience']\n",
    "device_no = 0\n",
    "device = torch.device('cuda:{}'.format(input_args.device))\n",
    "\n",
    "model_dir = os.path.join(root_dir, model_name)\n",
    "if input_args.reset and os.path.exists(model_dir): \n",
    "    shutil.rmtree(model_dir)\n",
    "if not os.path.exists(model_dir): \n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "#3. prepare the dataset\n",
    "mean, std = 0.1307, 0.3081\n",
    "train_dataset = MNIST(root='../data/MNIST',\n",
    "                      train=True, \n",
    "                      download=True,\n",
    "                      transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((mean,), (std,))]))\n",
    "test_dataset = MNIST(root='../data/MNIST', \n",
    "                     train=False, \n",
    "                     download=True,\n",
    "                     transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((mean,), (std,))]))\n",
    "n_classes = 10\n",
    "\n",
    "#4.sampler \n",
    "# online\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "#5. set up model \n",
    "model = backbone.EmbeddingNet()\n",
    "# model = backbone.TripletNet(embedding_net)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)\n",
    "loss_fn = TripletLoss(margin=margin)\n",
    "nll_loss = torch.nn.NLLLoss()\n",
    "\n",
    "#6. train\n",
    "last_epoch_improved = 0\n",
    "epoch = 0\n",
    "best_loss = np.inf\n",
    "\n",
    "while epoch - last_epoch_improved < patience:\n",
    "    running_train_loss = 0.0\n",
    "    running_test_loss = 0.0\n",
    "\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        inputs, labels  = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        nat_embeddings = model.get_embedding(inputs)\n",
    "        adv_image = attacks.fgsm_attack(model=model, images=inputs, labels=labels, device=device, margin=margin, eps=eps)\n",
    "        adv_embeddings = model.get_embedding(adv_image)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        metric_loss, pos_mask, neg_mask = sampler.online_mine_angular_hard(labels, nat_embeddings, adv_embeddings, angular=True, margin=margin, squared=True, reg=True,device=device)\n",
    "        xe_loss = nll_loss(outputs, labels)\n",
    "        loss = xe_loss + (0.5*metric_loss)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "        if idx%20 == 0:\n",
    "            print(f\"Training @ epoch = {epoch}, {idx}/{len(train_loader)}, loss = {loss:.5f}, pos_mask = {pos_mask}, neg_mask = {neg_mask}\", end='\\r')\n",
    "    train_epoch_loss = running_train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "    # test - but keep the grad bc we still need to do attacks \n",
    "    for idx, data in enumerate(test_loader):\n",
    "        inputs, labels  = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        nat_embeddings = model.get_embedding(inputs)\n",
    "        adv_image = attacks.fgsm_attack(model=model, images=inputs, labels=labels, device=device, margin=margin, eps=eps)\n",
    "        adv_embeddings = model.get_embedding(adv_image)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # import pdb; pdb.set_trace();\n",
    "        metric_loss, pos_mask, neg_mask = sampler.online_mine_angular_hard(labels, nat_embeddings, adv_embeddings, angular=True, margin=margin, squared=True, reg=True,device=device)\n",
    "        xe_loss = nll_loss(outputs, labels)\n",
    "        loss = xe_loss + (0.5*metric_loss)\n",
    "        \n",
    "        #adversarial notes\n",
    "        #1. get the x_p, x_n --> use our sampler --> our embedding net\n",
    "        #2. get x_p' --> use an attack --> (pgd/fgsm/online invariance)\n",
    "        # loss = metric_loss\n",
    "\n",
    "        running_test_loss += loss.item()\n",
    "    test_epoch_loss = running_test_loss / len(test_loader)\n",
    "\n",
    "    # save model/ embedding info\n",
    "    if test_epoch_loss < best_loss:\n",
    "        torch.save(model, os.path.join(model_dir, 'model'))\n",
    "        best_loss = test_epoch_loss\n",
    "        last_improved = epoch\n",
    "\n",
    "        #TODO pickle the best embeddings\n",
    "        #TODO add TSNE plotting\n",
    "        #TODO tensorboard\n",
    "    else: \n",
    "        patience-=1\n",
    "\n",
    "    epoch +=1\n",
    "    print(f\"\\nPatience= {patience}, train_epoch_loss = {train_epoch_loss}, test_epoch_loss = {test_epoch_loss}\")\n",
    "    print(\" \"*100)\n",
    "print('Finished Training!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv",
   "language": "python",
   "name": "adv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
