args: Namespace(config='./configs/nll_ml_invariance.ini', device=0, reset=False)
*****Plotting embeddings at iter: 0****
Training @ epoch = 0, 0/235, loss = 2.39248, pos_mask = 0.06326309591531754, neg_mask = 0.011449724435806274
Training @ epoch = 0, 60/235, loss = 2.30636, pos_mask = 0.22776725888252258, neg_mask = 0.03505144268274307
Training @ epoch = 0, 120/235, loss = 1.88814, pos_mask = 0.2670842707157135, neg_mask = 0.022072909399867058
Training @ epoch = 0, 180/235, loss = 1.55380, pos_mask = 0.25064054131507874, neg_mask = 0.052389051765203476
***********original test set **********
Accuracy: 67.18
***********sensitivity test set **********
Accuracy: 65.27
***********invariance test set **********
Accuracy: 46.76

Patience= 50, Time=0.51185, train_epoch_loss = 1.893442188425267, test_epoch_acc = 46.76
                                                                                                    
Training @ epoch = 1, 0/235, loss = 1.32552, pos_mask = 0.3205447196960449, neg_mask = 0.0874667763710022
Training @ epoch = 1, 60/235, loss = 1.20838, pos_mask = 0.3458079695701599, neg_mask = 0.1476072520017624
Training @ epoch = 1, 120/235, loss = 1.22188, pos_mask = 0.4736025035381317, neg_mask = 0.14598669111728668
Training @ epoch = 1, 180/235, loss = 1.13004, pos_mask = 0.5265934467315674, neg_mask = 0.21034541726112366
***********original test set **********
Accuracy: 88.3
***********sensitivity test set **********
Accuracy: 83.21
***********invariance test set **********
Accuracy: 64.85

Patience= 50, Time=0.94730, train_epoch_loss = 1.1657259971537488, test_epoch_acc = 64.85
                                                                                                    
Training @ epoch = 2, 0/235, loss = 0.95293, pos_mask = 0.46598005294799805, neg_mask = 0.22309765219688416
Training @ epoch = 2, 60/235, loss = 0.97690, pos_mask = 0.478860080242157, neg_mask = 0.20101845264434814
Training @ epoch = 2, 120/235, loss = 0.86672, pos_mask = 0.46724680066108704, neg_mask = 0.21203020215034485
Training @ epoch = 2, 180/235, loss = 0.72214, pos_mask = 0.3515775501728058, neg_mask = 0.1787223517894745
***********original test set **********
Accuracy: 92.49
***********sensitivity test set **********
Accuracy: 90.33
***********invariance test set **********
Accuracy: 72.25

Patience= 50, Time=1.37943, train_epoch_loss = 0.8557846604509557, test_epoch_acc = 72.25
                                                                                                    
Training @ epoch = 3, 0/235, loss = 0.76993, pos_mask = 0.3530693054199219, neg_mask = 0.11936967074871063
Training @ epoch = 3, 60/235, loss = 0.77641, pos_mask = 0.420060932636261, neg_mask = 0.12631359696388245
Training @ epoch = 3, 120/235, loss = 0.72481, pos_mask = 0.4316808581352234, neg_mask = 0.09711062908172607
Training @ epoch = 3, 180/235, loss = 0.74974, pos_mask = 0.5085270404815674, neg_mask = 0.1826445460319519
***********original test set **********
Accuracy: 93.99
***********sensitivity test set **********
Accuracy: 92.87
***********invariance test set **********
Accuracy: 75.01

Patience= 50, Time=1.81468, train_epoch_loss = 0.6989867129224412, test_epoch_acc = 75.01
                                                                                                    
Training @ epoch = 4, 0/235, loss = 0.64122, pos_mask = 0.3602381944656372, neg_mask = 0.17437317967414856
Training @ epoch = 4, 60/235, loss = 0.67603, pos_mask = 0.42131784558296204, neg_mask = 0.14082632958889008
Training @ epoch = 4, 120/235, loss = 0.63488, pos_mask = 0.41396287083625793, neg_mask = 0.22402605414390564
Training @ epoch = 4, 180/235, loss = 0.67245, pos_mask = 0.4942070543766022, neg_mask = 0.10388284921646118
***********original test set **********
Accuracy: 94.48
***********sensitivity test set **********
Accuracy: 93.01
***********invariance test set **********
Accuracy: 78.84

Patience= 50, Time=2.24407, train_epoch_loss = 0.6116505668518392, test_epoch_acc = 78.84
                                                                                                    
Training @ epoch = 5, 0/235, loss = 0.57629, pos_mask = 0.3875218331813812, neg_mask = 0.20552407205104828
Training @ epoch = 5, 60/235, loss = 0.49602, pos_mask = 0.21513225138187408, neg_mask = 0.24331045150756836
Training @ epoch = 5, 120/235, loss = 0.49222, pos_mask = 0.23841798305511475, neg_mask = 0.18928395211696625
Training @ epoch = 5, 180/235, loss = 0.45872, pos_mask = 0.21777231991291046, neg_mask = 0.2256142795085907
***********original test set **********
Accuracy: 95.4
***********sensitivity test set **********
Accuracy: 94.6
***********invariance test set **********
Accuracy: 77.46

Patience= 49, Time=2.68037, train_epoch_loss = 0.5429534062426141, test_epoch_acc = 77.46
                                                                                                    
Training @ epoch = 6, 0/235, loss = 0.56137, pos_mask = 0.36244112253189087, neg_mask = 0.0995824784040451
Training @ epoch = 6, 60/235, loss = 0.48212, pos_mask = 0.3791160583496094, neg_mask = 0.2245776355266571
Training @ epoch = 6, 120/235, loss = 0.61241, pos_mask = 0.374087929725647, neg_mask = 0.20770344138145447
Training @ epoch = 6, 180/235, loss = 0.49314, pos_mask = 0.40698689222335815, neg_mask = 0.25090616941452026
***********original test set **********
Accuracy: 95.39
***********sensitivity test set **********
Accuracy: 94.82
***********invariance test set **********
Accuracy: 83.07

Patience= 49, Time=3.11478, train_epoch_loss = 0.4947101459858265, test_epoch_acc = 83.07
                                                                                                    
Training @ epoch = 7, 0/235, loss = 0.42309, pos_mask = 0.39891743659973145, neg_mask = 0.24007561802864075
Training @ epoch = 7, 60/235, loss = 0.38877, pos_mask = 0.21636228263378143, neg_mask = 0.2396630346775055
Training @ epoch = 7, 120/235, loss = 0.37740, pos_mask = 0.18782871961593628, neg_mask = 0.21590760350227356
Training @ epoch = 7, 180/235, loss = 0.48886, pos_mask = 0.3119499981403351, neg_mask = 0.13675498962402344
***********original test set **********
Accuracy: 96.55
***********sensitivity test set **********
Accuracy: 96.12
***********invariance test set **********
Accuracy: 83.8

Patience= 49, Time=3.54624, train_epoch_loss = 0.44778374585699526, test_epoch_acc = 83.8
                                                                                                    
Training @ epoch = 8, 0/235, loss = 0.35548, pos_mask = 0.2019738256931305, neg_mask = 0.2129877507686615
Training @ epoch = 8, 60/235, loss = 0.40468, pos_mask = 0.2522270083427429, neg_mask = 0.23732152581214905
Training @ epoch = 8, 120/235, loss = 0.40716, pos_mask = 0.29330432415008545, neg_mask = 0.16491806507110596
Training @ epoch = 8, 180/235, loss = 0.46316, pos_mask = 0.33113929629325867, neg_mask = 0.20693260431289673
***********original test set **********
Accuracy: 96.82
***********sensitivity test set **********
Accuracy: 96.2
***********invariance test set **********
Accuracy: 81.92

Patience= 48, Time=3.97919, train_epoch_loss = 0.4120284398819538, test_epoch_acc = 81.92
                                                                                                    
Training @ epoch = 9, 0/235, loss = 0.39557, pos_mask = 0.28828296065330505, neg_mask = 0.1793656200170517
Training @ epoch = 9, 60/235, loss = 0.37064, pos_mask = 0.3542552888393402, neg_mask = 0.2335750162601471
Training @ epoch = 9, 120/235, loss = 0.35277, pos_mask = 0.2882131040096283, neg_mask = 0.19125545024871826
Training @ epoch = 9, 180/235, loss = 0.39662, pos_mask = 0.4105532765388489, neg_mask = 0.19478748738765717
***********original test set **********
Accuracy: 97.18
***********sensitivity test set **********
Accuracy: 96.89
***********invariance test set **********
Accuracy: 86.26

Patience= 48, Time=4.41754, train_epoch_loss = 0.37765852377769793, test_epoch_acc = 86.26
                                                                                                    
Training @ epoch = 10, 0/235, loss = 0.38726, pos_mask = 0.38192829489707947, neg_mask = 0.25948604941368103
Training @ epoch = 10, 60/235, loss = 0.25697, pos_mask = 0.20584014058113098, neg_mask = 0.2561757564544678
Training @ epoch = 10, 120/235, loss = 0.36714, pos_mask = 0.35733336210250854, neg_mask = 0.27843087911605835
Training @ epoch = 10, 180/235, loss = 0.36808, pos_mask = 0.3421328067779541, neg_mask = 0.2690695822238922
***********original test set **********
Accuracy: 97.52
***********sensitivity test set **********
Accuracy: 97.24
***********invariance test set **********
Accuracy: 87.18

Patience= 48, Time=4.85353, train_epoch_loss = 0.3476459709887809, test_epoch_acc = 87.18
                                                                                                    
Training @ epoch = 11, 0/235, loss = 0.29833, pos_mask = 0.25212615728378296, neg_mask = 0.244764044880867
Training @ epoch = 11, 60/235, loss = 0.33097, pos_mask = 0.30444881319999695, neg_mask = 0.2587844431400299
Training @ epoch = 11, 120/235, loss = 0.30194, pos_mask = 0.2869107127189636, neg_mask = 0.28718501329421997
Training @ epoch = 11, 180/235, loss = 0.43177, pos_mask = 0.4355911910533905, neg_mask = 0.1554032862186432
***********original test set **********
Accuracy: 97.49
***********sensitivity test set **********
Accuracy: 97.19
***********invariance test set **********
Accuracy: 84.89

Patience= 47, Time=5.29081, train_epoch_loss = 0.32324823109393425, test_epoch_acc = 84.89
                                                                                                    
Training @ epoch = 12, 0/235, loss = 0.30854, pos_mask = 0.26822346448898315, neg_mask = 0.2787003219127655
Training @ epoch = 12, 60/235, loss = 0.34274, pos_mask = 0.3754725754261017, neg_mask = 0.2315380722284317
Training @ epoch = 12, 120/235, loss = 0.24168, pos_mask = 0.22332903742790222, neg_mask = 0.2239232361316681
Training @ epoch = 12, 180/235, loss = 0.27282, pos_mask = 0.24397924542427063, neg_mask = 0.2539047300815582
***********original test set **********
Accuracy: 97.36
***********sensitivity test set **********
Accuracy: 97.05
***********invariance test set **********
Accuracy: 84.26

Patience= 46, Time=5.72494, train_epoch_loss = 0.29813490884101135, test_epoch_acc = 84.26
                                                                                                    
Training @ epoch = 13, 0/235, loss = 0.36040, pos_mask = 0.3268013596534729, neg_mask = 0.26718419790267944
Training @ epoch = 13, 60/235, loss = 0.22836, pos_mask = 0.2612038254737854, neg_mask = 0.2683600187301636
Training @ epoch = 13, 120/235, loss = 0.23397, pos_mask = 0.31702813506126404, neg_mask = 0.303061842918396
Training @ epoch = 13, 180/235, loss = 0.21822, pos_mask = 0.2684004604816437, neg_mask = 0.30040106177330017
***********original test set **********
Accuracy: 97.93
***********sensitivity test set **********
Accuracy: 97.75
***********invariance test set **********
Accuracy: 88.81

Patience= 46, Time=6.15834, train_epoch_loss = 0.27500713714893826, test_epoch_acc = 88.81
                                                                                                    
Training @ epoch = 14, 0/235, loss = 0.27439, pos_mask = 0.29751405119895935, neg_mask = 0.25565603375434875
Training @ epoch = 14, 60/235, loss = 0.28308, pos_mask = 0.3218153119087219, neg_mask = 0.24635253846645355
Training @ epoch = 14, 120/235, loss = 0.35905, pos_mask = 0.514956533908844, neg_mask = 0.2904626131057739
Training @ epoch = 14, 180/235, loss = 0.30532, pos_mask = 0.36356639862060547, neg_mask = 0.28840160369873047
***********original test set **********
Accuracy: 98.0
***********sensitivity test set **********
Accuracy: 97.81
***********invariance test set **********
Accuracy: 86.27

Patience= 45, Time=6.58992, train_epoch_loss = 0.2532963272738964, test_epoch_acc = 86.27
                                                                                                    
Training @ epoch = 15, 0/235, loss = 0.30274, pos_mask = 0.4083552360534668, neg_mask = 0.30172768235206604
Training @ epoch = 15, 60/235, loss = 0.26620, pos_mask = 0.2796851098537445, neg_mask = 0.2776981294155121
Training @ epoch = 15, 120/235, loss = 0.18574, pos_mask = 0.1677127480506897, neg_mask = 0.3179546594619751
Training @ epoch = 15, 180/235, loss = 0.23897, pos_mask = 0.20176176726818085, neg_mask = 0.2880421280860901
***********original test set **********
Accuracy: 97.48
***********sensitivity test set **********
Accuracy: 97.57
***********invariance test set **********
Accuracy: 87.05

Patience= 44, Time=7.02185, train_epoch_loss = 0.2388664094057489, test_epoch_acc = 87.05
                                                                                                    
Training @ epoch = 16, 0/235, loss = 0.27640, pos_mask = 0.2895073890686035, neg_mask = 0.2959403693675995
Training @ epoch = 16, 60/235, loss = 0.17044, pos_mask = 0.1741047203540802, neg_mask = 0.29730191826820374
Training @ epoch = 16, 120/235, loss = 0.21793, pos_mask = 0.22290284931659698, neg_mask = 0.2836689054965973
Training @ epoch = 16, 180/235, loss = 0.25645, pos_mask = 0.3107392191886902, neg_mask = 0.30784833431243896
***********original test set **********
Accuracy: 98.3
***********sensitivity test set **********
Accuracy: 98.05
***********invariance test set **********
Accuracy: 88.18

Patience= 43, Time=7.45130, train_epoch_loss = 0.21952388426090808, test_epoch_acc = 88.18
                                                                                                    
Training @ epoch = 17, 0/235, loss = 0.16176, pos_mask = 0.17386475205421448, neg_mask = 0.3625539541244507
Training @ epoch = 17, 60/235, loss = 0.20140, pos_mask = 0.28491541743278503, neg_mask = 0.3267575800418854
Training @ epoch = 17, 120/235, loss = 0.16345, pos_mask = 0.20646795630455017, neg_mask = 0.2989034652709961
Training @ epoch = 17, 180/235, loss = 0.16428, pos_mask = 0.23828822374343872, neg_mask = 0.332255482673645
***********original test set **********
Accuracy: 98.37
***********sensitivity test set **********
Accuracy: 98.03
***********invariance test set **********
Accuracy: 88.72

Patience= 42, Time=7.88583, train_epoch_loss = 0.20617245746419785, test_epoch_acc = 88.72
                                                                                                    
Training @ epoch = 18, 0/235, loss = 0.19562, pos_mask = 0.27267691493034363, neg_mask = 0.29730597138404846
Training @ epoch = 18, 60/235, loss = 0.16211, pos_mask = 0.18708479404449463, neg_mask = 0.3176949620246887
Training @ epoch = 18, 120/235, loss = 0.25387, pos_mask = 0.3772229850292206, neg_mask = 0.24434378743171692
Training @ epoch = 18, 180/235, loss = 0.18529, pos_mask = 0.24255134165287018, neg_mask = 0.3165200352668762
***********original test set **********
Accuracy: 98.36
***********sensitivity test set **********
Accuracy: 98.2
***********invariance test set **********
Accuracy: 89.27

Patience= 42, Time=8.31928, train_epoch_loss = 0.1921380048102521, test_epoch_acc = 89.27
                                                                                                    
Training @ epoch = 19, 0/235, loss = 0.29545, pos_mask = 0.40998101234436035, neg_mask = 0.19943802058696747
Training @ epoch = 19, 60/235, loss = 0.17630, pos_mask = 0.2070612609386444, neg_mask = 0.32607895135879517
Training @ epoch = 19, 120/235, loss = 0.20044, pos_mask = 0.3029128909111023, neg_mask = 0.32625657320022583
Training @ epoch = 19, 180/235, loss = 0.14586, pos_mask = 0.1727955937385559, neg_mask = 0.33453369140625
***********original test set **********
Accuracy: 98.39
***********sensitivity test set **********
Accuracy: 98.35
***********invariance test set **********
Accuracy: 87.91

Patience= 41, Time=8.75465, train_epoch_loss = 0.17909870426705543, test_epoch_acc = 87.91
                                                                                                    
Training @ epoch = 20, 0/235, loss = 0.14027, pos_mask = 0.21304886043071747, neg_mask = 0.3382173180580139
Training @ epoch = 20, 60/235, loss = 0.15670, pos_mask = 0.20717337727546692, neg_mask = 0.3295151889324188
Training @ epoch = 20, 120/235, loss = 0.29260, pos_mask = 0.3939119875431061, neg_mask = 0.2807745337486267
Training @ epoch = 20, 180/235, loss = 0.25419, pos_mask = 0.3178301453590393, neg_mask = 0.2753463387489319
***********original test set **********
Accuracy: 98.4
***********sensitivity test set **********
Accuracy: 98.34
***********invariance test set **********
Accuracy: 86.96

Patience= 40, Time=9.18886, train_epoch_loss = 0.1679221568272469, test_epoch_acc = 86.96
                                                                                                    
Training @ epoch = 21, 0/235, loss = 0.15801, pos_mask = 0.23002149164676666, neg_mask = 0.366905152797699
Training @ epoch = 21, 60/235, loss = 0.23472, pos_mask = 0.36676448583602905, neg_mask = 0.3304436206817627
Training @ epoch = 21, 120/235, loss = 0.12068, pos_mask = 0.150125190615654, neg_mask = 0.370882123708725
Training @ epoch = 21, 180/235, loss = 0.18118, pos_mask = 0.22640837728977203, neg_mask = 0.2925143837928772
***********original test set **********
Accuracy: 98.55
***********sensitivity test set **********
Accuracy: 98.45
***********invariance test set **********
Accuracy: 90.1

Patience= 40, Time=9.61594, train_epoch_loss = 0.15920245894726287, test_epoch_acc = 90.1
                                                                                                    
Training @ epoch = 22, 0/235, loss = 0.13087, pos_mask = 0.15677349269390106, neg_mask = 0.3841713070869446
Training @ epoch = 22, 60/235, loss = 0.14653, pos_mask = 0.22571581602096558, neg_mask = 0.3485775589942932
Training @ epoch = 22, 120/235, loss = 0.13289, pos_mask = 0.19090691208839417, neg_mask = 0.35335493087768555
Training @ epoch = 22, 180/235, loss = 0.12157, pos_mask = 0.1719316840171814, neg_mask = 0.3727700710296631
***********original test set **********
Accuracy: 98.53
***********sensitivity test set **********
Accuracy: 98.45
***********invariance test set **********
Accuracy: 89.38

Patience= 39, Time=10.05254, train_epoch_loss = 0.15041714117248006, test_epoch_acc = 89.38
                                                                                                    
Training @ epoch = 23, 0/235, loss = 0.14659, pos_mask = 0.2689465582370758, neg_mask = 0.3836977779865265
Training @ epoch = 23, 60/235, loss = 0.14354, pos_mask = 0.19456373155117035, neg_mask = 0.31553253531455994
Training @ epoch = 23, 120/235, loss = 0.16125, pos_mask = 0.22420036792755127, neg_mask = 0.34301823377609253
Training @ epoch = 23, 180/235, loss = 0.15685, pos_mask = 0.24664504826068878, neg_mask = 0.32546061277389526
***********original test set **********
Accuracy: 98.58
***********sensitivity test set **********
Accuracy: 98.66
***********invariance test set **********
Accuracy: 89.33

Patience= 38, Time=10.49098, train_epoch_loss = 0.1404021217467937, test_epoch_acc = 89.33
                                                                                                    
Training @ epoch = 24, 0/235, loss = 0.13382, pos_mask = 0.20428955554962158, neg_mask = 0.31916457414627075
Training @ epoch = 24, 60/235, loss = 0.12511, pos_mask = 0.18571501970291138, neg_mask = 0.3357570767402649
Training @ epoch = 24, 120/235, loss = 0.13642, pos_mask = 0.19060558080673218, neg_mask = 0.31501710414886475
Training @ epoch = 24, 180/235, loss = 0.16353, pos_mask = 0.15655487775802612, neg_mask = 0.3061474561691284
***********original test set **********
Accuracy: 98.65
***********sensitivity test set **********
Accuracy: 98.33
***********invariance test set **********
Accuracy: 88.06

Patience= 37, Time=10.92570, train_epoch_loss = 0.13193673707069234, test_epoch_acc = 88.06
                                                                                                    
Training @ epoch = 25, 0/235, loss = 0.10611, pos_mask = 0.15986619889736176, neg_mask = 0.36900633573532104
Training @ epoch = 25, 60/235, loss = 0.09326, pos_mask = 0.12621375918388367, neg_mask = 0.3942030668258667
Training @ epoch = 25, 120/235, loss = 0.11509, pos_mask = 0.1998167484998703, neg_mask = 0.3546221852302551
Training @ epoch = 25, 180/235, loss = 0.10121, pos_mask = 0.1412675380706787, neg_mask = 0.40980005264282227
***********original test set **********
Accuracy: 98.79
***********sensitivity test set **********
Accuracy: 98.66
***********invariance test set **********
Accuracy: 90.31

Patience= 37, Time=11.36222, train_epoch_loss = 0.12560009683700318, test_epoch_acc = 90.31
                                                                                                    
Training @ epoch = 26, 0/235, loss = 0.09800, pos_mask = 0.15659500658512115, neg_mask = 0.40280261635780334
Training @ epoch = 26, 60/235, loss = 0.10176, pos_mask = 0.1335911601781845, neg_mask = 0.35841161012649536
Training @ epoch = 26, 120/235, loss = 0.12731, pos_mask = 0.21558162569999695, neg_mask = 0.36293819546699524
Training @ epoch = 26, 180/235, loss = 0.12978, pos_mask = 0.18843379616737366, neg_mask = 0.32551077008247375
***********original test set **********
Accuracy: 98.81
***********sensitivity test set **********
Accuracy: 98.68
***********invariance test set **********
Accuracy: 90.24

Patience= 36, Time=11.79466, train_epoch_loss = 0.11870566612862526, test_epoch_acc = 90.24
                                                                                                    
Training @ epoch = 27, 0/235, loss = 0.12237, pos_mask = 0.19780632853507996, neg_mask = 0.36786848306655884
Training @ epoch = 27, 60/235, loss = 0.14313, pos_mask = 0.2200055867433548, neg_mask = 0.3968011736869812
Training @ epoch = 27, 120/235, loss = 0.08306, pos_mask = 0.15252718329429626, neg_mask = 0.4138025939464569
Training @ epoch = 27, 180/235, loss = 0.10213, pos_mask = 0.1543864607810974, neg_mask = 0.36431461572647095
***********original test set **********
Accuracy: 98.69
***********sensitivity test set **********
Accuracy: 98.49
***********invariance test set **********
Accuracy: 88.42

Patience= 35, Time=12.22746, train_epoch_loss = 0.11038139877801245, test_epoch_acc = 88.42
                                                                                                    
Training @ epoch = 28, 0/235, loss = 0.10229, pos_mask = 0.20291738212108612, neg_mask = 0.3884769082069397
Training @ epoch = 28, 60/235, loss = 0.07943, pos_mask = 0.1413928121328354, neg_mask = 0.4074522852897644
Training @ epoch = 28, 120/235, loss = 0.15279, pos_mask = 0.31260842084884644, neg_mask = 0.402288556098938
Training @ epoch = 28, 180/235, loss = 0.09982, pos_mask = 0.1537446826696396, neg_mask = 0.3945522606372833
***********original test set **********
Accuracy: 98.68
***********sensitivity test set **********
Accuracy: 98.55
***********invariance test set **********
Accuracy: 88.82

Patience= 34, Time=12.66328, train_epoch_loss = 0.10510667131302205, test_epoch_acc = 88.82
                                                                                                    
Training @ epoch = 29, 0/235, loss = 0.09167, pos_mask = 0.1620888113975525, neg_mask = 0.39633700251579285
Training @ epoch = 29, 60/235, loss = 0.09654, pos_mask = 0.2003793567419052, neg_mask = 0.3599538207054138
Training @ epoch = 29, 120/235, loss = 0.08590, pos_mask = 0.16919191181659698, neg_mask = 0.39827242493629456
Training @ epoch = 29, 180/235, loss = 0.11587, pos_mask = 0.23326507210731506, neg_mask = 0.39786243438720703
***********original test set **********
Accuracy: 98.84
***********sensitivity test set **********
Accuracy: 98.64
***********invariance test set **********
Accuracy: 90.04

Patience= 33, Time=13.08939, train_epoch_loss = 0.09849184691271884, test_epoch_acc = 90.04
                                                                                                    
Training @ epoch = 30, 0/235, loss = 0.08224, pos_mask = 0.14362099766731262, neg_mask = 0.3941248655319214
Training @ epoch = 30, 60/235, loss = 0.07263, pos_mask = 0.11179953813552856, neg_mask = 0.4290757179260254
Training @ epoch = 30, 120/235, loss = 0.08415, pos_mask = 0.20072713494300842, neg_mask = 0.3531634211540222
Training @ epoch = 30, 180/235, loss = 0.08415, pos_mask = 0.15461879968643188, neg_mask = 0.40500393509864807
***********original test set **********
Accuracy: 98.91
***********sensitivity test set **********
Accuracy: 98.68
***********invariance test set **********
Accuracy: 90.19

Patience= 32, Time=13.52185, train_epoch_loss = 0.09447109340987307, test_epoch_acc = 90.19
                                                                                                    
Training @ epoch = 31, 0/235, loss = 0.08181, pos_mask = 0.1205577701330185, neg_mask = 0.4047165513038635
Training @ epoch = 31, 60/235, loss = 0.11136, pos_mask = 0.1890815943479538, neg_mask = 0.39453786611557007
Training @ epoch = 31, 120/235, loss = 0.13073, pos_mask = 0.19632112979888916, neg_mask = 0.3435841202735901
Training @ epoch = 31, 180/235, loss = 0.07446, pos_mask = 0.13377860188484192, neg_mask = 0.4378544092178345
***********original test set **********
Accuracy: 98.89
***********sensitivity test set **********
Accuracy: 98.77
***********invariance test set **********
Accuracy: 90.68

Patience= 32, Time=13.95896, train_epoch_loss = 0.09154336864643908, test_epoch_acc = 90.68
                                                                                                    
Training @ epoch = 32, 0/235, loss = 0.07945, pos_mask = 0.12513110041618347, neg_mask = 0.3972902297973633
Training @ epoch = 32, 60/235, loss = 0.09817, pos_mask = 0.1774534285068512, neg_mask = 0.3679504692554474
Training @ epoch = 32, 120/235, loss = 0.14090, pos_mask = 0.2395244538784027, neg_mask = 0.3949365019798279
Training @ epoch = 32, 180/235, loss = 0.07155, pos_mask = 0.12172448635101318, neg_mask = 0.4647873044013977
***********original test set **********
Accuracy: 98.76
***********sensitivity test set **********
Accuracy: 98.66
***********invariance test set **********
Accuracy: 90.49

Patience= 31, Time=14.38872, train_epoch_loss = 0.08611421084150354, test_epoch_acc = 90.49
                                                                                                    
Training @ epoch = 33, 0/235, loss = 0.07602, pos_mask = 0.1110832467675209, neg_mask = 0.4032358229160309
Training @ epoch = 33, 60/235, loss = 0.08354, pos_mask = 0.16004589200019836, neg_mask = 0.38771897554397583
Training @ epoch = 33, 120/235, loss = 0.07308, pos_mask = 0.13344773650169373, neg_mask = 0.40002578496932983
Training @ epoch = 33, 180/235, loss = 0.07201, pos_mask = 0.11739535629749298, neg_mask = 0.4067017436027527
***********original test set **********
Accuracy: 98.99
***********sensitivity test set **********
Accuracy: 98.77
***********invariance test set **********
Accuracy: 89.97

Patience= 30, Time=14.82062, train_epoch_loss = 0.08170952261128324, test_epoch_acc = 89.97
                                                                                                    
Training @ epoch = 34, 0/235, loss = 0.07616, pos_mask = 0.16994494199752808, neg_mask = 0.4059337377548218
Training @ epoch = 34, 60/235, loss = 0.07485, pos_mask = 0.13596928119659424, neg_mask = 0.4356883764266968
Training @ epoch = 34, 120/235, loss = 0.08851, pos_mask = 0.19995008409023285, neg_mask = 0.4143841862678528
Training @ epoch = 34, 180/235, loss = 0.07496, pos_mask = 0.12288763374090195, neg_mask = 0.38126397132873535
***********original test set **********
Accuracy: 98.85
***********sensitivity test set **********
Accuracy: 98.69
***********invariance test set **********
Accuracy: 90.1

Patience= 29, Time=15.25448, train_epoch_loss = 0.07705289269698427, test_epoch_acc = 90.1
                                                                                                    
Training @ epoch = 35, 0/235, loss = 0.08217, pos_mask = 0.14577904343605042, neg_mask = 0.376417875289917
Training @ epoch = 35, 60/235, loss = 0.07322, pos_mask = 0.13907986879348755, neg_mask = 0.3780420422554016
Training @ epoch = 35, 120/235, loss = 0.06320, pos_mask = 0.12206609547138214, neg_mask = 0.4237409830093384
Training @ epoch = 35, 180/235, loss = 0.06856, pos_mask = 0.14480425417423248, neg_mask = 0.42458319664001465
***********original test set **********
Accuracy: 98.86
***********sensitivity test set **********
Accuracy: 98.84
***********invariance test set **********
Accuracy: 90.72

Patience= 29, Time=15.68759, train_epoch_loss = 0.07504225666535662, test_epoch_acc = 90.72
                                                                                                    
Training @ epoch = 36, 0/235, loss = 0.08313, pos_mask = 0.17752698063850403, neg_mask = 0.4059293568134308
Training @ epoch = 36, 60/235, loss = 0.06624, pos_mask = 0.0898890346288681, neg_mask = 0.4478686451911926
Training @ epoch = 36, 120/235, loss = 0.08204, pos_mask = 0.20667806267738342, neg_mask = 0.38818830251693726
Training @ epoch = 36, 180/235, loss = 0.06424, pos_mask = 0.12221139669418335, neg_mask = 0.41652712225914
***********original test set **********
Accuracy: 99.07
***********sensitivity test set **********
Accuracy: 98.8
***********invariance test set **********
Accuracy: 90.72

Patience= 28, Time=16.12043, train_epoch_loss = 0.07040471161933655, test_epoch_acc = 90.72
                                                                                                    
Training @ epoch = 37, 0/235, loss = 0.06702, pos_mask = 0.14836956560611725, neg_mask = 0.3817726969718933
Training @ epoch = 37, 60/235, loss = 0.05898, pos_mask = 0.08619768172502518, neg_mask = 0.4295930862426758
Training @ epoch = 37, 120/235, loss = 0.07779, pos_mask = 0.16363030672073364, neg_mask = 0.389793336391449
Training @ epoch = 37, 180/235, loss = 0.06189, pos_mask = 0.11208505183458328, neg_mask = 0.4082891643047333
***********original test set **********
Accuracy: 98.97
***********sensitivity test set **********
Accuracy: 98.83
***********invariance test set **********
Accuracy: 90.82

Patience= 28, Time=16.55315, train_epoch_loss = 0.06629207159610505, test_epoch_acc = 90.82
                                                                                                    
Training @ epoch = 38, 0/235, loss = 0.06437, pos_mask = 0.11979973316192627, neg_mask = 0.4653128385543823
Training @ epoch = 38, 60/235, loss = 0.07020, pos_mask = 0.15078136324882507, neg_mask = 0.37071719765663147
Training @ epoch = 38, 120/235, loss = 0.05691, pos_mask = 0.12206917256116867, neg_mask = 0.44303011894226074
Training @ epoch = 38, 180/235, loss = 0.06387, pos_mask = 0.13236434757709503, neg_mask = 0.42146795988082886
***********original test set **********
Accuracy: 98.98
***********sensitivity test set **********
Accuracy: 98.96
***********invariance test set **********
Accuracy: 90.55

Patience= 27, Time=16.98624, train_epoch_loss = 0.06435538818861576, test_epoch_acc = 90.55
                                                                                                    
Training @ epoch = 39, 0/235, loss = 0.06038, pos_mask = 0.10316868126392365, neg_mask = 0.44929996132850647
Training @ epoch = 39, 60/235, loss = 0.05768, pos_mask = 0.10328302532434464, neg_mask = 0.4309921860694885
Training @ epoch = 39, 120/235, loss = 0.05725, pos_mask = 0.10840381681919098, neg_mask = 0.45858922600746155
Training @ epoch = 39, 180/235, loss = 0.05806, pos_mask = 0.11506529152393341, neg_mask = 0.43791505694389343
***********original test set **********
Accuracy: 98.99
***********sensitivity test set **********
Accuracy: 98.81
***********invariance test set **********
Accuracy: 90.55

Patience= 26, Time=17.42044, train_epoch_loss = 0.06054748299908131, test_epoch_acc = 90.55
                                                                                                    
Training @ epoch = 40, 0/235, loss = 0.05601, pos_mask = 0.10930119454860687, neg_mask = 0.4473740756511688
Training @ epoch = 40, 60/235, loss = 0.05485, pos_mask = 0.12330124527215958, neg_mask = 0.397592693567276
Training @ epoch = 40, 120/235, loss = 0.06462, pos_mask = 0.12185130268335342, neg_mask = 0.44168636202812195
Training @ epoch = 40, 180/235, loss = 0.05139, pos_mask = 0.0671987235546112, neg_mask = 0.48922237753868103
***********original test set **********
Accuracy: 99.05
***********sensitivity test set **********
Accuracy: 98.89
***********invariance test set **********
Accuracy: 90.81

Patience= 25, Time=17.85419, train_epoch_loss = 0.05813758289243313, test_epoch_acc = 90.81
                                                                                                    
Training @ epoch = 41, 0/235, loss = 0.05539, pos_mask = 0.09549941122531891, neg_mask = 0.4521057605743408
Training @ epoch = 41, 60/235, loss = 0.05367, pos_mask = 0.08880765736103058, neg_mask = 0.4334210157394409
Training @ epoch = 41, 120/235, loss = 0.05163, pos_mask = 0.08966498076915741, neg_mask = 0.4489993453025818
Training @ epoch = 41, 180/235, loss = 0.06242, pos_mask = 0.13048464059829712, neg_mask = 0.42424413561820984
***********original test set **********
Accuracy: 99.0
***********sensitivity test set **********
Accuracy: 98.83
***********invariance test set **********
Accuracy: 91.24

Patience= 25, Time=18.28971, train_epoch_loss = 0.05869435739326984, test_epoch_acc = 91.24
                                                                                                    
Training @ epoch = 42, 0/235, loss = 0.05192, pos_mask = 0.09180227667093277, neg_mask = 0.47332921624183655
Training @ epoch = 42, 60/235, loss = 0.05294, pos_mask = 0.0892956331372261, neg_mask = 0.43330395221710205
Training @ epoch = 42, 120/235, loss = 0.05623, pos_mask = 0.13007116317749023, neg_mask = 0.4118402600288391
Training @ epoch = 42, 180/235, loss = 0.05405, pos_mask = 0.10980136692523956, neg_mask = 0.446113646030426
***********original test set **********
Accuracy: 99.03
***********sensitivity test set **********
Accuracy: 98.86
***********invariance test set **********
Accuracy: 91.11

Patience= 24, Time=18.72707, train_epoch_loss = 0.056515200404410666, test_epoch_acc = 91.11
                                                                                                    
Training @ epoch = 43, 0/235, loss = 0.04772, pos_mask = 0.07149724662303925, neg_mask = 0.4973585605621338
Training @ epoch = 43, 60/235, loss = 0.05136, pos_mask = 0.11193128675222397, neg_mask = 0.43161365389823914
Training @ epoch = 43, 120/235, loss = 0.05173, pos_mask = 0.09500189125537872, neg_mask = 0.4586968719959259
Training @ epoch = 43, 180/235, loss = 0.05247, pos_mask = 0.11060789227485657, neg_mask = 0.44122111797332764
***********original test set **********
Accuracy: 98.92
***********sensitivity test set **********
Accuracy: 98.84
***********invariance test set **********
Accuracy: 89.5

Patience= 23, Time=19.16226, train_epoch_loss = 0.05225593324037309, test_epoch_acc = 89.5
                                                                                                    
Training @ epoch = 44, 0/235, loss = 0.04966, pos_mask = 0.13318537175655365, neg_mask = 0.40736231207847595
Training @ epoch = 44, 60/235, loss = 0.07218, pos_mask = 0.1321176141500473, neg_mask = 0.39562827348709106
Training @ epoch = 44, 120/235, loss = 0.04839, pos_mask = 0.10516342520713806, neg_mask = 0.47271865606307983
Training @ epoch = 44, 180/235, loss = 0.04686, pos_mask = 0.07023119926452637, neg_mask = 0.4981888234615326
***********original test set **********
Accuracy: 99.05
***********sensitivity test set **********
Accuracy: 98.91
***********invariance test set **********
Accuracy: 91.18

Patience= 22, Time=19.59536, train_epoch_loss = 0.051004792385278865, test_epoch_acc = 91.18
                                                                                                    
Training @ epoch = 45, 0/235, loss = 0.04498, pos_mask = 0.06911830604076385, neg_mask = 0.5000373125076294
Training @ epoch = 45, 60/235, loss = 0.04904, pos_mask = 0.09403344243764877, neg_mask = 0.4626418948173523
Training @ epoch = 45, 120/235, loss = 0.04427, pos_mask = 0.10716176778078079, neg_mask = 0.4637097716331482
Training @ epoch = 45, 180/235, loss = 0.05069, pos_mask = 0.14300628006458282, neg_mask = 0.4544042944908142
***********original test set **********
Accuracy: 99.02
***********sensitivity test set **********
Accuracy: 98.87
***********invariance test set **********
Accuracy: 91.69

Patience= 22, Time=20.03196, train_epoch_loss = 0.050307691763056085, test_epoch_acc = 91.69
                                                                                                    
Training @ epoch = 46, 0/235, loss = 0.04903, pos_mask = 0.08492352068424225, neg_mask = 0.4705921709537506
Training @ epoch = 46, 60/235, loss = 0.05006, pos_mask = 0.08699822425842285, neg_mask = 0.44389593601226807
Training @ epoch = 46, 120/235, loss = 0.04838, pos_mask = 0.11448347568511963, neg_mask = 0.45340967178344727
Training @ epoch = 46, 180/235, loss = 0.05170, pos_mask = 0.11931292712688446, neg_mask = 0.43487536907196045
***********original test set **********
Accuracy: 99.08
***********sensitivity test set **********
Accuracy: 98.95
***********invariance test set **********
Accuracy: 91.01

Patience= 21, Time=20.46231, train_epoch_loss = 0.04691659779624736, test_epoch_acc = 91.01
                                                                                                    
Training @ epoch = 47, 0/235, loss = 0.04487, pos_mask = 0.10319232195615768, neg_mask = 0.4500141143798828
Training @ epoch = 47, 60/235, loss = 0.05139, pos_mask = 0.11157289892435074, neg_mask = 0.4643886089324951
Training @ epoch = 47, 120/235, loss = 0.04653, pos_mask = 0.1341613233089447, neg_mask = 0.4468180537223816
Training @ epoch = 47, 180/235, loss = 0.04340, pos_mask = 0.07974350452423096, neg_mask = 0.4454382061958313
***********original test set **********
Accuracy: 99.05
***********sensitivity test set **********
Accuracy: 98.83
***********invariance test set **********
Accuracy: 90.53

Patience= 20, Time=20.89509, train_epoch_loss = 0.045572494842270585, test_epoch_acc = 90.53
                                                                                                    
Training @ epoch = 48, 0/235, loss = 0.05013, pos_mask = 0.14491519331932068, neg_mask = 0.3923479914665222
Training @ epoch = 48, 60/235, loss = 0.04243, pos_mask = 0.1009894460439682, neg_mask = 0.4583572447299957
Training @ epoch = 48, 120/235, loss = 0.04406, pos_mask = 0.08936640620231628, neg_mask = 0.48029637336730957
Training @ epoch = 48, 180/235, loss = 0.04147, pos_mask = 0.09414082765579224, neg_mask = 0.48132285475730896
***********original test set **********
Accuracy: 99.02
***********sensitivity test set **********
Accuracy: 98.96
***********invariance test set **********
Accuracy: 91.1

Patience= 19, Time=21.33009, train_epoch_loss = 0.044221054524817366, test_epoch_acc = 91.1
                                                                                                    
Training @ epoch = 49, 0/235, loss = 0.04685, pos_mask = 0.10758110135793686, neg_mask = 0.45322826504707336
Training @ epoch = 49, 60/235, loss = 0.04376, pos_mask = 0.07617770880460739, neg_mask = 0.4843507409095764
Training @ epoch = 49, 120/235, loss = 0.04363, pos_mask = 0.08736258745193481, neg_mask = 0.45914149284362793
Training @ epoch = 49, 180/235, loss = 0.04530, pos_mask = 0.09954796731472015, neg_mask = 0.46644526720046997
***********original test set **********
Accuracy: 99.03
***********sensitivity test set **********
Accuracy: 98.93
***********invariance test set **********
Accuracy: 90.41

Patience= 18, Time=21.76699, train_epoch_loss = 0.0437305693930768, test_epoch_acc = 90.41
                                                                                                    
Training @ epoch = 50, 0/235, loss = 0.04256, pos_mask = 0.07312984764575958, neg_mask = 0.4810669422149658
Training @ epoch = 50, 60/235, loss = 0.04466, pos_mask = 0.08541987836360931, neg_mask = 0.4379475712776184
Training @ epoch = 50, 120/235, loss = 0.04291, pos_mask = 0.10087371617555618, neg_mask = 0.48722028732299805
Training @ epoch = 50, 180/235, loss = 0.04319, pos_mask = 0.11696435511112213, neg_mask = 0.4364587962627411
***********original test set **********
Accuracy: 99.03
***********sensitivity test set **********
Accuracy: 98.9
***********invariance test set **********
Accuracy: 90.43

Patience= 17, Time=22.20440, train_epoch_loss = 0.042371428837167456, test_epoch_acc = 90.43
                                                                                                    
Training @ epoch = 51, 0/235, loss = 0.04344, pos_mask = 0.07177121937274933, neg_mask = 0.5125436186790466
Training @ epoch = 51, 60/235, loss = 0.03858, pos_mask = 0.09928901493549347, neg_mask = 0.48135846853256226
Training @ epoch = 51, 120/235, loss = 0.04231, pos_mask = 0.09898429363965988, neg_mask = 0.47452661395072937
Training @ epoch = 51, 180/235, loss = 0.03963, pos_mask = 0.08849738538265228, neg_mask = 0.4857144355773926
***********original test set **********
Accuracy: 98.99
***********sensitivity test set **********
Accuracy: 98.81
***********invariance test set **********
Accuracy: 90.19

Patience= 16, Time=22.64130, train_epoch_loss = 0.04132398693485463, test_epoch_acc = 90.19
                                                                                                    
Training @ epoch = 52, 0/235, loss = 0.04311, pos_mask = 0.11783130466938019, neg_mask = 0.4768107533454895
Training @ epoch = 52, 60/235, loss = 0.04423, pos_mask = 0.08564464747905731, neg_mask = 0.470694363117218
Training @ epoch = 52, 120/235, loss = 0.03925, pos_mask = 0.08030658960342407, neg_mask = 0.49952584505081177
Training @ epoch = 52, 180/235, loss = 0.03999, pos_mask = 0.0771784782409668, neg_mask = 0.4793596565723419
***********original test set **********
Accuracy: 99.12
***********sensitivity test set **********
Accuracy: 98.95
***********invariance test set **********
Accuracy: 91.35

Patience= 15, Time=23.07291, train_epoch_loss = 0.0406259298007539, test_epoch_acc = 91.35
                                                                                                    
Training @ epoch = 53, 0/235, loss = 0.03859, pos_mask = 0.06856001913547516, neg_mask = 0.49901244044303894
Training @ epoch = 53, 60/235, loss = 0.04038, pos_mask = 0.0995619148015976, neg_mask = 0.4323658347129822
Training @ epoch = 53, 120/235, loss = 0.03916, pos_mask = 0.08934671431779861, neg_mask = 0.4713979661464691
Training @ epoch = 53, 180/235, loss = 0.03758, pos_mask = 0.07368817925453186, neg_mask = 0.49658817052841187
***********original test set **********
Accuracy: 99.01
***********sensitivity test set **********
Accuracy: 98.95
***********invariance test set **********
Accuracy: 91.04

Patience= 14, Time=23.51022, train_epoch_loss = 0.03876624380020385, test_epoch_acc = 91.04
                                                                                                    
Training @ epoch = 54, 0/235, loss = 0.03798, pos_mask = 0.06487354636192322, neg_mask = 0.5014975070953369
Training @ epoch = 54, 60/235, loss = 0.03815, pos_mask = 0.07424367219209671, neg_mask = 0.49424976110458374
Training @ epoch = 54, 120/235, loss = 0.03808, pos_mask = 0.06137188524007797, neg_mask = 0.4997994899749756
Training @ epoch = 54, 180/235, loss = 0.03555, pos_mask = 0.08406931161880493, neg_mask = 0.4671120047569275
***********original test set **********
Accuracy: 99.06
***********sensitivity test set **********
Accuracy: 98.92
***********invariance test set **********
Accuracy: 90.7

Patience= 13, Time=23.94288, train_epoch_loss = 0.03776129666478076, test_epoch_acc = 90.7
                                                                                                    
Training @ epoch = 55, 0/235, loss = 0.03957, pos_mask = 0.07200844585895538, neg_mask = 0.5189025402069092
Training @ epoch = 55, 60/235, loss = 0.03662, pos_mask = 0.07785731554031372, neg_mask = 0.5026078224182129
Training @ epoch = 55, 120/235, loss = 0.03739, pos_mask = 0.07804310321807861, neg_mask = 0.4941755533218384
Training @ epoch = 55, 180/235, loss = 0.03670, pos_mask = 0.08015131950378418, neg_mask = 0.495629221200943
***********original test set **********
Accuracy: 99.1
***********sensitivity test set **********
Accuracy: 98.87
***********invariance test set **********
Accuracy: 91.36

Patience= 12, Time=24.37367, train_epoch_loss = 0.03713796929793155, test_epoch_acc = 91.36
                                                                                                    
Training @ epoch = 56, 0/235, loss = 0.03601, pos_mask = 0.06881450861692429, neg_mask = 0.4943446218967438
Training @ epoch = 56, 60/235, loss = 0.03546, pos_mask = 0.06980182230472565, neg_mask = 0.5262777209281921
Training @ epoch = 56, 120/235, loss = 0.03567, pos_mask = 0.07376587390899658, neg_mask = 0.5302742719650269
Training @ epoch = 56, 180/235, loss = 0.03630, pos_mask = 0.0674511045217514, neg_mask = 0.5291140079498291
***********original test set **********
Accuracy: 99.05
***********sensitivity test set **********
Accuracy: 98.98
***********invariance test set **********
Accuracy: 91.23

Patience= 11, Time=24.80842, train_epoch_loss = 0.03610496102495397, test_epoch_acc = 91.23
                                                                                                    
Training @ epoch = 57, 0/235, loss = 0.03314, pos_mask = 0.09570969641208649, neg_mask = 0.4630029499530792
Training @ epoch = 57, 60/235, loss = 0.03441, pos_mask = 0.06919075548648834, neg_mask = 0.4954579472541809
Training @ epoch = 57, 120/235, loss = 0.03472, pos_mask = 0.08691315352916718, neg_mask = 0.4962760806083679
Training @ epoch = 57, 180/235, loss = 0.03456, pos_mask = 0.07317575812339783, neg_mask = 0.5265243053436279
***********original test set **********
Accuracy: 99.13
***********sensitivity test set **********
Accuracy: 99.0
***********invariance test set **********
Accuracy: 91.5

Patience= 10, Time=25.24138, train_epoch_loss = 0.03533786337109322, test_epoch_acc = 91.5
                                                                                                    
Training @ epoch = 58, 0/235, loss = 0.03560, pos_mask = 0.06310918927192688, neg_mask = 0.533505916595459
Training @ epoch = 58, 60/235, loss = 0.03701, pos_mask = 0.07189197838306427, neg_mask = 0.510066032409668
Training @ epoch = 58, 120/235, loss = 0.03400, pos_mask = 0.05666476488113403, neg_mask = 0.5198814868927002
Training @ epoch = 58, 180/235, loss = 0.03373, pos_mask = 0.08340849727392197, neg_mask = 0.4644916355609894
***********original test set **********
Accuracy: 99.09
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 91.29

Patience= 9, Time=25.67592, train_epoch_loss = 0.0345847265200412, test_epoch_acc = 91.29
                                                                                                    
Training @ epoch = 59, 0/235, loss = 0.03355, pos_mask = 0.07537181675434113, neg_mask = 0.4865037798881531
Training @ epoch = 59, 60/235, loss = 0.03432, pos_mask = 0.06907854229211807, neg_mask = 0.5382496118545532
Training @ epoch = 59, 120/235, loss = 0.03513, pos_mask = 0.07558948546648026, neg_mask = 0.5169086456298828
Training @ epoch = 59, 180/235, loss = 0.03398, pos_mask = 0.0619596466422081, neg_mask = 0.5323789119720459
***********original test set **********
Accuracy: 99.12
***********sensitivity test set **********
Accuracy: 98.98
***********invariance test set **********
Accuracy: 91.4

Patience= 8, Time=26.10817, train_epoch_loss = 0.034258583616069024, test_epoch_acc = 91.4
                                                                                                    
Training @ epoch = 60, 0/235, loss = 0.03554, pos_mask = 0.056802913546562195, neg_mask = 0.5629251003265381
Training @ epoch = 60, 60/235, loss = 0.03327, pos_mask = 0.0726088210940361, neg_mask = 0.510080099105835
Training @ epoch = 60, 120/235, loss = 0.03242, pos_mask = 0.06554774940013885, neg_mask = 0.5278311967849731
Training @ epoch = 60, 180/235, loss = 0.03399, pos_mask = 0.05611243471503258, neg_mask = 0.5285102128982544
***********original test set **********
Accuracy: 98.58
***********sensitivity test set **********
Accuracy: 97.95
***********invariance test set **********
Accuracy: 88.69

Patience= 7, Time=26.54460, train_epoch_loss = 0.03683388855387556, test_epoch_acc = 88.69
                                                                                                    
Training @ epoch = 61, 0/235, loss = 0.06425, pos_mask = 0.12831518054008484, neg_mask = 0.409757137298584
Training @ epoch = 61, 60/235, loss = 0.07207, pos_mask = 0.15600815415382385, neg_mask = 0.4264431595802307
Training @ epoch = 61, 120/235, loss = 0.04818, pos_mask = 0.13136711716651917, neg_mask = 0.4497140645980835
Training @ epoch = 61, 180/235, loss = 0.03710, pos_mask = 0.07224688678979874, neg_mask = 0.49062108993530273
***********original test set **********
Accuracy: 99.07
***********sensitivity test set **********
Accuracy: 98.93
***********invariance test set **********
Accuracy: 90.03

Patience= 6, Time=26.97702, train_epoch_loss = 0.05633960857670358, test_epoch_acc = 90.03
                                                                                                    
Training @ epoch = 62, 0/235, loss = 0.03913, pos_mask = 0.10272274911403656, neg_mask = 0.49164944887161255
Training @ epoch = 62, 60/235, loss = 0.03352, pos_mask = 0.08832384645938873, neg_mask = 0.4802011549472809
Training @ epoch = 62, 120/235, loss = 0.03205, pos_mask = 0.08146417140960693, neg_mask = 0.48712119460105896
Training @ epoch = 62, 180/235, loss = 0.03340, pos_mask = 0.055961571633815765, neg_mask = 0.5598741769790649
***********original test set **********
Accuracy: 99.1
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 91.62

Patience= 5, Time=27.40891, train_epoch_loss = 0.03467048973320647, test_epoch_acc = 91.62
                                                                                                    
Training @ epoch = 63, 0/235, loss = 0.03159, pos_mask = 0.04904651641845703, neg_mask = 0.5272483825683594
Training @ epoch = 63, 60/235, loss = 0.03235, pos_mask = 0.09217070788145065, neg_mask = 0.523775577545166
Training @ epoch = 63, 120/235, loss = 0.03103, pos_mask = 0.0694146454334259, neg_mask = 0.498046338558197
Training @ epoch = 63, 180/235, loss = 0.03039, pos_mask = 0.07449787110090256, neg_mask = 0.5563036799430847
***********original test set **********
Accuracy: 99.11
***********sensitivity test set **********
Accuracy: 99.09
***********invariance test set **********
Accuracy: 91.27

Patience= 4, Time=27.83726, train_epoch_loss = 0.032108494346129134, test_epoch_acc = 91.27
                                                                                                    
Training @ epoch = 64, 0/235, loss = 0.03164, pos_mask = 0.045354969799518585, neg_mask = 0.549630343914032
Training @ epoch = 64, 60/235, loss = 0.03045, pos_mask = 0.06472086161375046, neg_mask = 0.5305811166763306
Training @ epoch = 64, 120/235, loss = 0.03196, pos_mask = 0.06583923101425171, neg_mask = 0.5197376012802124
Training @ epoch = 64, 180/235, loss = 0.03298, pos_mask = 0.05152849107980728, neg_mask = 0.5622797012329102
***********original test set **********
Accuracy: 99.12
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 91.22

Patience= 3, Time=28.26950, train_epoch_loss = 0.03123978318527658, test_epoch_acc = 91.22
                                                                                                    
Training @ epoch = 65, 0/235, loss = 0.02913, pos_mask = 0.062168482691049576, neg_mask = 0.5449320673942566
Training @ epoch = 65, 60/235, loss = 0.03089, pos_mask = 0.056466374546289444, neg_mask = 0.5300105810165405
Training @ epoch = 65, 120/235, loss = 0.03070, pos_mask = 0.04756481945514679, neg_mask = 0.5362496972084045
Training @ epoch = 65, 180/235, loss = 0.03028, pos_mask = 0.05623117834329605, neg_mask = 0.5345894694328308
***********original test set **********
Accuracy: 99.14
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 91.39

Patience= 2, Time=28.70210, train_epoch_loss = 0.030611641467251677, test_epoch_acc = 91.39
                                                                                                    
Training @ epoch = 66, 0/235, loss = 0.03034, pos_mask = 0.05742552876472473, neg_mask = 0.5262272357940674
Training @ epoch = 66, 60/235, loss = 0.02976, pos_mask = 0.07500113546848297, neg_mask = 0.5054354667663574
Training @ epoch = 66, 120/235, loss = 0.03025, pos_mask = 0.07037965953350067, neg_mask = 0.48096323013305664
Training @ epoch = 66, 180/235, loss = 0.02871, pos_mask = 0.05939871817827225, neg_mask = 0.5268903970718384
***********original test set **********
Accuracy: 99.14
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 91.17

Patience= 1, Time=29.13509, train_epoch_loss = 0.030119023630593687, test_epoch_acc = 91.17
                                                                                                    
Training @ epoch = 67, 0/235, loss = 0.02931, pos_mask = 0.0456969328224659, neg_mask = 0.5316560864448547
Training @ epoch = 67, 60/235, loss = 0.02887, pos_mask = 0.06755481660366058, neg_mask = 0.5207756757736206
Training @ epoch = 67, 120/235, loss = 0.02929, pos_mask = 0.05313052237033844, neg_mask = 0.5341531038284302
Training @ epoch = 67, 180/235, loss = 0.02898, pos_mask = 0.05716284364461899, neg_mask = 0.5032111406326294
***********original test set **********
Accuracy: 99.14
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 91.1

Patience= 0, Time=29.56973, train_epoch_loss = 0.029728383555057202, test_epoch_acc = 91.1
                                                                                                    
Training @ epoch = 68, 0/235, loss = 0.03051, pos_mask = 0.04618563503026962, neg_mask = 0.5390252470970154
Training @ epoch = 68, 60/235, loss = 0.03018, pos_mask = 0.058321356773376465, neg_mask = 0.5325164794921875
Training @ epoch = 68, 120/235, loss = 0.02988, pos_mask = 0.04671300947666168, neg_mask = 0.568600594997406
Training @ epoch = 68, 180/235, loss = 0.02988, pos_mask = 0.05120765417814255, neg_mask = 0.5528982877731323
***********original test set **********
Accuracy: 99.12
***********sensitivity test set **********
Accuracy: 99.12
***********invariance test set **********
Accuracy: 91.33

Patience= -1, Time=30.00437, train_epoch_loss = 0.02921093906810943, test_epoch_acc = 91.33
                                                                                                    
Training @ epoch = 69, 0/235, loss = 0.02773, pos_mask = 0.05206330865621567, neg_mask = 0.5405460596084595
Training @ epoch = 69, 60/235, loss = 0.02818, pos_mask = 0.06494423747062683, neg_mask = 0.5288479328155518
Training @ epoch = 69, 120/235, loss = 0.03004, pos_mask = 0.05041547119617462, neg_mask = 0.5404531955718994
Training @ epoch = 69, 180/235, loss = 0.02942, pos_mask = 0.057577166706323624, neg_mask = 0.560520589351654
***********original test set **********
Accuracy: 99.13
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 91.54

Patience= -2, Time=30.43942, train_epoch_loss = 0.028699867459053688, test_epoch_acc = 91.54
                                                                                                    
Training @ epoch = 70, 0/235, loss = 0.02869, pos_mask = 0.04737323522567749, neg_mask = 0.5586156845092773
Training @ epoch = 70, 60/235, loss = 0.02891, pos_mask = 0.04793853312730789, neg_mask = 0.5746738314628601
Training @ epoch = 70, 120/235, loss = 0.02808, pos_mask = 0.05735793709754944, neg_mask = 0.5674943923950195
Training @ epoch = 70, 180/235, loss = 0.02879, pos_mask = 0.0513741560280323, neg_mask = 0.5582237839698792
***********original test set **********
Accuracy: 99.12
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 91.54

Patience= -3, Time=30.87435, train_epoch_loss = 0.028234212544370203, test_epoch_acc = 91.54
                                                                                                    
Training @ epoch = 71, 0/235, loss = 0.02842, pos_mask = 0.07355109602212906, neg_mask = 0.5238156318664551
Training @ epoch = 71, 60/235, loss = 0.02785, pos_mask = 0.04730818420648575, neg_mask = 0.5364384651184082
Training @ epoch = 71, 120/235, loss = 0.02749, pos_mask = 0.048270996659994125, neg_mask = 0.5508142709732056
Training @ epoch = 71, 180/235, loss = 0.02866, pos_mask = 0.0503256618976593, neg_mask = 0.546775221824646
***********original test set **********
Accuracy: 99.14
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 91.48

Patience= -4, Time=31.30719, train_epoch_loss = 0.02773539182987619, test_epoch_acc = 91.48
                                                                                                    
Training @ epoch = 72, 0/235, loss = 0.02804, pos_mask = 0.06458903849124908, neg_mask = 0.5635921359062195
Training @ epoch = 72, 60/235, loss = 0.02849, pos_mask = 0.03947557136416435, neg_mask = 0.5647957921028137
Training @ epoch = 72, 120/235, loss = 0.02572, pos_mask = 0.046106696128845215, neg_mask = 0.5593386888504028
Training @ epoch = 72, 180/235, loss = 0.02674, pos_mask = 0.06517988443374634, neg_mask = 0.5054248571395874
***********original test set **********
Accuracy: 99.13
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 91.2

Patience= -5, Time=31.74031, train_epoch_loss = 0.027307113838639666, test_epoch_acc = 91.2
                                                                                                    
Training @ epoch = 73, 0/235, loss = 0.02582, pos_mask = 0.061069704592227936, neg_mask = 0.5329914093017578
Training @ epoch = 73, 60/235, loss = 0.02710, pos_mask = 0.0411384142935276, neg_mask = 0.5571305751800537
Training @ epoch = 73, 120/235, loss = 0.02743, pos_mask = 0.037083517760038376, neg_mask = 0.5830395221710205
Training @ epoch = 73, 180/235, loss = 0.02744, pos_mask = 0.04732273146510124, neg_mask = 0.5645530223846436
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.09
***********invariance test set **********
Accuracy: 91.35

Patience= -6, Time=32.17797, train_epoch_loss = 0.026769136835603002, test_epoch_acc = 91.35
                                                                                                    
Training @ epoch = 74, 0/235, loss = 0.02685, pos_mask = 0.052169036120176315, neg_mask = 0.5615600943565369
Training @ epoch = 74, 60/235, loss = 0.02822, pos_mask = 0.03875439614057541, neg_mask = 0.5708009004592896
Training @ epoch = 74, 120/235, loss = 0.02597, pos_mask = 0.04911710321903229, neg_mask = 0.5642479062080383
Training @ epoch = 74, 180/235, loss = 0.02719, pos_mask = 0.045676738023757935, neg_mask = 0.5712023377418518
***********original test set **********
Accuracy: 99.13
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 91.27

Patience= -7, Time=32.61399, train_epoch_loss = 0.02634962319218098, test_epoch_acc = 91.27
                                                                                                    
Training @ epoch = 75, 0/235, loss = 0.02632, pos_mask = 0.05679363012313843, neg_mask = 0.5543347001075745
Training @ epoch = 75, 60/235, loss = 0.02727, pos_mask = 0.043011099100112915, neg_mask = 0.579230546951294
Training @ epoch = 75, 120/235, loss = 0.02581, pos_mask = 0.041273899376392365, neg_mask = 0.5679988861083984
Training @ epoch = 75, 180/235, loss = 0.02666, pos_mask = 0.04174945503473282, neg_mask = 0.5826658010482788
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.11
***********invariance test set **********
Accuracy: 91.81

Patience= -7, Time=33.04730, train_epoch_loss = 0.02590600107102952, test_epoch_acc = 91.81
                                                                                                    
Training @ epoch = 76, 0/235, loss = 0.02615, pos_mask = 0.04838739335536957, neg_mask = 0.5621675252914429
Training @ epoch = 76, 60/235, loss = 0.02521, pos_mask = 0.04641038179397583, neg_mask = 0.5583915710449219
Training @ epoch = 76, 120/235, loss = 0.02509, pos_mask = 0.04714477062225342, neg_mask = 0.5489806532859802
Training @ epoch = 76, 180/235, loss = 0.02667, pos_mask = 0.055329713970422745, neg_mask = 0.5402941107749939
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 91.41

Patience= -8, Time=33.48397, train_epoch_loss = 0.025821154580471364, test_epoch_acc = 91.41
                                                                                                    
Training @ epoch = 77, 0/235, loss = 0.02765, pos_mask = 0.0368528813123703, neg_mask = 0.5786428451538086
Training @ epoch = 77, 60/235, loss = 0.04298, pos_mask = 0.12299858033657074, neg_mask = 0.4081369638442993
Training @ epoch = 77, 120/235, loss = 0.11633, pos_mask = 0.2541729509830475, neg_mask = 0.4461873173713684
Training @ epoch = 77, 180/235, loss = 0.03345, pos_mask = 0.12449879944324493, neg_mask = 0.4385386109352112
***********original test set **********
Accuracy: 98.92
***********sensitivity test set **********
Accuracy: 98.84
***********invariance test set **********
Accuracy: 89.16

Patience= -9, Time=33.91878, train_epoch_loss = 0.04676875984098049, test_epoch_acc = 89.16
                                                                                                    
Training @ epoch = 78, 0/235, loss = 0.02869, pos_mask = 0.05835004150867462, neg_mask = 0.5428273677825928
Training @ epoch = 78, 60/235, loss = 0.02872, pos_mask = 0.08377204835414886, neg_mask = 0.5022792220115662
Training @ epoch = 78, 120/235, loss = 0.02784, pos_mask = 0.07374735921621323, neg_mask = 0.50412917137146
Training @ epoch = 78, 180/235, loss = 0.02905, pos_mask = 0.06611630320549011, neg_mask = 0.5482786297798157
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 91.26

Patience= -10, Time=34.35279, train_epoch_loss = 0.03032955990985353, test_epoch_acc = 91.26
                                                                                                    
Training @ epoch = 79, 0/235, loss = 0.02615, pos_mask = 0.07169769704341888, neg_mask = 0.5020678043365479
Training @ epoch = 79, 60/235, loss = 0.02646, pos_mask = 0.0536809116601944, neg_mask = 0.5473247766494751
Training @ epoch = 79, 120/235, loss = 0.02633, pos_mask = 0.043338242918252945, neg_mask = 0.568447470664978
Training @ epoch = 79, 180/235, loss = 0.02517, pos_mask = 0.052982181310653687, neg_mask = 0.5459715127944946
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.91

Patience= -11, Time=34.78316, train_epoch_loss = 0.02590824583584958, test_epoch_acc = 90.91
                                                                                                    
Training @ epoch = 80, 0/235, loss = 0.02583, pos_mask = 0.05695480480790138, neg_mask = 0.5470394492149353
Training @ epoch = 80, 60/235, loss = 0.02520, pos_mask = 0.04683016240596771, neg_mask = 0.5323514938354492
Training @ epoch = 80, 120/235, loss = 0.02571, pos_mask = 0.052028052508831024, neg_mask = 0.5599572658538818
Training @ epoch = 80, 180/235, loss = 0.02439, pos_mask = 0.05460464581847191, neg_mask = 0.5540051460266113
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.12
***********invariance test set **********
Accuracy: 91.18

Patience= -12, Time=35.21693, train_epoch_loss = 0.02508328992160077, test_epoch_acc = 91.18
                                                                                                    
Training @ epoch = 81, 0/235, loss = 0.02486, pos_mask = 0.047372788190841675, neg_mask = 0.5714035630226135
Training @ epoch = 81, 60/235, loss = 0.02473, pos_mask = 0.04874537140130997, neg_mask = 0.5250908136367798
Training @ epoch = 81, 120/235, loss = 0.02435, pos_mask = 0.050760846585035324, neg_mask = 0.54459547996521
Training @ epoch = 81, 180/235, loss = 0.02403, pos_mask = 0.057777538895606995, neg_mask = 0.5261796116828918
***********original test set **********
Accuracy: 99.24
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 91.29

Patience= -13, Time=35.65262, train_epoch_loss = 0.024666717489983173, test_epoch_acc = 91.29
                                                                                                    
Training @ epoch = 82, 0/235, loss = 0.02390, pos_mask = 0.042891357094049454, neg_mask = 0.5592217445373535
Training @ epoch = 82, 60/235, loss = 0.02408, pos_mask = 0.04435562714934349, neg_mask = 0.5570884943008423
Training @ epoch = 82, 120/235, loss = 0.02438, pos_mask = 0.04178179055452347, neg_mask = 0.559123158454895
Training @ epoch = 82, 180/235, loss = 0.02409, pos_mask = 0.045206859707832336, neg_mask = 0.5623490810394287
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 91.2

Patience= -14, Time=36.08512, train_epoch_loss = 0.02431313397878028, test_epoch_acc = 91.2
                                                                                                    
Training @ epoch = 83, 0/235, loss = 0.02322, pos_mask = 0.06618361175060272, neg_mask = 0.5120448470115662
Training @ epoch = 83, 60/235, loss = 0.02427, pos_mask = 0.04479847848415375, neg_mask = 0.5595933794975281
Training @ epoch = 83, 120/235, loss = 0.02436, pos_mask = 0.046679407358169556, neg_mask = 0.5875464677810669
Training @ epoch = 83, 180/235, loss = 0.02459, pos_mask = 0.04163309186697006, neg_mask = 0.5817723274230957
***********original test set **********
Accuracy: 99.24
***********sensitivity test set **********
Accuracy: 99.11
***********invariance test set **********
Accuracy: 91.3

Patience= -15, Time=36.51577, train_epoch_loss = 0.02399273154900429, test_epoch_acc = 91.3
                                                                                                    
Training @ epoch = 84, 0/235, loss = 0.02354, pos_mask = 0.05271109193563461, neg_mask = 0.5583667755126953
Training @ epoch = 84, 60/235, loss = 0.02327, pos_mask = 0.06010602414608002, neg_mask = 0.5547707080841064
Training @ epoch = 84, 120/235, loss = 0.02430, pos_mask = 0.05310538783669472, neg_mask = 0.5652806162834167
Training @ epoch = 84, 180/235, loss = 0.02310, pos_mask = 0.06612548977136612, neg_mask = 0.5518448352813721
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.12
***********invariance test set **********
Accuracy: 91.31

Patience= -16, Time=36.95007, train_epoch_loss = 0.023713923610271293, test_epoch_acc = 91.31
                                                                                                    
Training @ epoch = 85, 0/235, loss = 0.02352, pos_mask = 0.04309392720460892, neg_mask = 0.5826096534729004
Training @ epoch = 85, 60/235, loss = 0.02329, pos_mask = 0.039916858077049255, neg_mask = 0.5791140198707581
Training @ epoch = 85, 120/235, loss = 0.02400, pos_mask = 0.04257570952177048, neg_mask = 0.5755041241645813
Training @ epoch = 85, 180/235, loss = 0.02344, pos_mask = 0.04274779558181763, neg_mask = 0.5855134725570679
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 91.18

Patience= -17, Time=37.38491, train_epoch_loss = 0.023440328898265007, test_epoch_acc = 91.18
                                                                                                    
Training @ epoch = 86, 0/235, loss = 0.02292, pos_mask = 0.044396333396434784, neg_mask = 0.56792151927948
Training @ epoch = 86, 60/235, loss = 0.02380, pos_mask = 0.04348530247807503, neg_mask = 0.5571833848953247
Training @ epoch = 86, 120/235, loss = 0.02324, pos_mask = 0.04853857681155205, neg_mask = 0.5665779709815979
Training @ epoch = 86, 180/235, loss = 0.02418, pos_mask = 0.03834466636180878, neg_mask = 0.5608679056167603
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.13
***********invariance test set **********
Accuracy: 91.15

Patience= -18, Time=37.82007, train_epoch_loss = 0.023089030060045264, test_epoch_acc = 91.15
                                                                                                    
Training @ epoch = 87, 0/235, loss = 0.02397, pos_mask = 0.03561476618051529, neg_mask = 0.5808371305465698
Training @ epoch = 87, 60/235, loss = 0.02307, pos_mask = 0.03896709159016609, neg_mask = 0.5907599925994873
Training @ epoch = 87, 120/235, loss = 0.02252, pos_mask = 0.046799760311841965, neg_mask = 0.5415648221969604
Training @ epoch = 87, 180/235, loss = 0.02232, pos_mask = 0.049685053527355194, neg_mask = 0.5480701327323914
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.11
***********invariance test set **********
Accuracy: 91.36

Patience= -19, Time=38.25363, train_epoch_loss = 0.022800594544474116, test_epoch_acc = 91.36
                                                                                                    
Training @ epoch = 88, 0/235, loss = 0.02227, pos_mask = 0.03909900411963463, neg_mask = 0.574334979057312
Training @ epoch = 88, 60/235, loss = 0.02309, pos_mask = 0.04431086406111717, neg_mask = 0.591754674911499
Training @ epoch = 88, 120/235, loss = 0.02168, pos_mask = 0.06104639172554016, neg_mask = 0.5333168506622314
Training @ epoch = 88, 180/235, loss = 0.02297, pos_mask = 0.04963567107915878, neg_mask = 0.5595356225967407
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 91.26

Patience= -20, Time=38.68812, train_epoch_loss = 0.022475893922308657, test_epoch_acc = 91.26
                                                                                                    
Training @ epoch = 89, 0/235, loss = 0.02217, pos_mask = 0.04351121559739113, neg_mask = 0.5780912637710571
Training @ epoch = 89, 60/235, loss = 0.02220, pos_mask = 0.04534173756837845, neg_mask = 0.5803927183151245
Training @ epoch = 89, 120/235, loss = 0.02266, pos_mask = 0.04054025560617447, neg_mask = 0.5848770141601562
Training @ epoch = 89, 180/235, loss = 0.02225, pos_mask = 0.04634631425142288, neg_mask = 0.5798259377479553
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 91.46

Patience= -21, Time=39.12653, train_epoch_loss = 0.022134527857316302, test_epoch_acc = 91.46
                                                                                                    
Training @ epoch = 90, 0/235, loss = 0.02112, pos_mask = 0.04459885507822037, neg_mask = 0.5655863881111145
Training @ epoch = 90, 60/235, loss = 0.02199, pos_mask = 0.05447353795170784, neg_mask = 0.5807492136955261
Training @ epoch = 90, 120/235, loss = 0.02135, pos_mask = 0.04931509494781494, neg_mask = 0.5352780818939209
Training @ epoch = 90, 180/235, loss = 0.02140, pos_mask = 0.03933558613061905, neg_mask = 0.5858721137046814
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 91.43

Patience= -22, Time=39.56009, train_epoch_loss = 0.02186448961654876, test_epoch_acc = 91.43
                                                                                                    
Training @ epoch = 91, 0/235, loss = 0.02268, pos_mask = 0.0342845693230629, neg_mask = 0.578183114528656
Training @ epoch = 91, 60/235, loss = 0.02165, pos_mask = 0.039508283138275146, neg_mask = 0.5574105978012085
Training @ epoch = 91, 120/235, loss = 0.02138, pos_mask = 0.0396326519548893, neg_mask = 0.5942142605781555
Training @ epoch = 91, 180/235, loss = 0.02139, pos_mask = 0.037641897797584534, neg_mask = 0.5727482438087463
***********original test set **********
Accuracy: 99.15
***********sensitivity test set **********
Accuracy: 99.12
***********invariance test set **********
Accuracy: 91.23

Patience= -23, Time=39.99308, train_epoch_loss = 0.02151873581745523, test_epoch_acc = 91.23
                                                                                                    
Training @ epoch = 92, 0/235, loss = 0.02092, pos_mask = 0.04515056684613228, neg_mask = 0.5555934906005859
Training @ epoch = 92, 60/235, loss = 0.02122, pos_mask = 0.044046223163604736, neg_mask = 0.5910089612007141
Training @ epoch = 92, 120/235, loss = 0.02033, pos_mask = 0.04208434745669365, neg_mask = 0.5448362827301025
Training @ epoch = 92, 180/235, loss = 0.02141, pos_mask = 0.04025403782725334, neg_mask = 0.5594830513000488
***********original test set **********
Accuracy: 99.11
***********sensitivity test set **********
Accuracy: 99.09
***********invariance test set **********
Accuracy: 91.36

Patience= -24, Time=40.42370, train_epoch_loss = 0.021249826014675992, test_epoch_acc = 91.36
                                                                                                    
Training @ epoch = 93, 0/235, loss = 0.02148, pos_mask = 0.03730102628469467, neg_mask = 0.5762988328933716
Training @ epoch = 93, 60/235, loss = 0.02164, pos_mask = 0.028386713936924934, neg_mask = 0.6028232574462891
Training @ epoch = 93, 120/235, loss = 0.02063, pos_mask = 0.05414963513612747, neg_mask = 0.5505046844482422
Training @ epoch = 93, 180/235, loss = 0.02170, pos_mask = 0.035190220922231674, neg_mask = 0.5933105945587158
***********original test set **********
Accuracy: 98.78
***********sensitivity test set **********
Accuracy: 98.74
***********invariance test set **********
Accuracy: 90.27

Patience= -25, Time=40.85584, train_epoch_loss = 0.022256969605037508, test_epoch_acc = 90.27
                                                                                                    
Training @ epoch = 94, 0/235, loss = 0.03217, pos_mask = 0.10526503622531891, neg_mask = 0.45652660727500916
Training @ epoch = 94, 60/235, loss = 0.10233, pos_mask = 0.18162566423416138, neg_mask = 0.4155668616294861
Training @ epoch = 94, 120/235, loss = 0.06962, pos_mask = 0.17015469074249268, neg_mask = 0.4495343565940857
Training @ epoch = 94, 180/235, loss = 0.07567, pos_mask = 0.1757311224937439, neg_mask = 0.36912456154823303
***********original test set **********
Accuracy: 99.06
***********sensitivity test set **********
Accuracy: 98.92
***********invariance test set **********
Accuracy: 89.6

Patience= -26, Time=41.29379, train_epoch_loss = 0.04262591261971504, test_epoch_acc = 89.6
                                                                                                    
Training @ epoch = 95, 0/235, loss = 0.02339, pos_mask = 0.07722475379705429, neg_mask = 0.5304319858551025
Training @ epoch = 95, 60/235, loss = 0.02922, pos_mask = 0.10321886837482452, neg_mask = 0.4863507151603699
Training @ epoch = 95, 120/235, loss = 0.02260, pos_mask = 0.06101038306951523, neg_mask = 0.5308468341827393
Training @ epoch = 95, 180/235, loss = 0.02811, pos_mask = 0.10670319944620132, neg_mask = 0.4966717064380646
***********original test set **********
Accuracy: 99.11
***********sensitivity test set **********
Accuracy: 99.01
***********invariance test set **********
Accuracy: 90.1

Patience= -27, Time=41.72849, train_epoch_loss = 0.025807839972858734, test_epoch_acc = 90.1
                                                                                                    
Training @ epoch = 96, 0/235, loss = 0.02231, pos_mask = 0.06525855511426926, neg_mask = 0.5416965484619141
Training @ epoch = 96, 60/235, loss = 0.02171, pos_mask = 0.046716898679733276, neg_mask = 0.5675309896469116
Training @ epoch = 96, 120/235, loss = 0.02169, pos_mask = 0.060759373009204865, neg_mask = 0.561053991317749
Training @ epoch = 96, 180/235, loss = 0.02036, pos_mask = 0.05852046608924866, neg_mask = 0.530742883682251
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 91.14

Patience= -28, Time=42.16195, train_epoch_loss = 0.021700074634653458, test_epoch_acc = 91.14
                                                                                                    
Training @ epoch = 97, 0/235, loss = 0.02056, pos_mask = 0.05331890285015106, neg_mask = 0.5656529664993286
Training @ epoch = 97, 60/235, loss = 0.02168, pos_mask = 0.03349263221025467, neg_mask = 0.5843788385391235
Training @ epoch = 97, 120/235, loss = 0.02095, pos_mask = 0.04215742647647858, neg_mask = 0.5604186654090881
Training @ epoch = 97, 180/235, loss = 0.02089, pos_mask = 0.037797048687934875, neg_mask = 0.5767421126365662
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.13
***********invariance test set **********
Accuracy: 90.85

Patience= -29, Time=42.59323, train_epoch_loss = 0.02089900201622476, test_epoch_acc = 90.85
                                                                                                    
Training @ epoch = 98, 0/235, loss = 0.02078, pos_mask = 0.05872517079114914, neg_mask = 0.5469095706939697
Training @ epoch = 98, 60/235, loss = 0.02149, pos_mask = 0.05299479141831398, neg_mask = 0.5829851627349854
Training @ epoch = 98, 120/235, loss = 0.01971, pos_mask = 0.05519699305295944, neg_mask = 0.5458662509918213
Training @ epoch = 98, 180/235, loss = 0.02130, pos_mask = 0.03795137256383896, neg_mask = 0.6044291853904724
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.12
***********invariance test set **********
Accuracy: 91.11

Patience= -30, Time=43.02137, train_epoch_loss = 0.02066145880900799, test_epoch_acc = 91.11
                                                                                                    
Training @ epoch = 99, 0/235, loss = 0.02077, pos_mask = 0.03429246321320534, neg_mask = 0.5736807584762573
Training @ epoch = 99, 60/235, loss = 0.02092, pos_mask = 0.03752777725458145, neg_mask = 0.5956345796585083
Training @ epoch = 99, 120/235, loss = 0.02058, pos_mask = 0.04520407319068909, neg_mask = 0.5730711221694946
Training @ epoch = 99, 180/235, loss = 0.02015, pos_mask = 0.0496816411614418, neg_mask = 0.5758719444274902
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.12
***********invariance test set **********
Accuracy: 91.24

Patience= -31, Time=43.45521, train_epoch_loss = 0.020405910140339364, test_epoch_acc = 91.24
                                                                                                    
Training @ epoch = 100, 0/235, loss = 0.02043, pos_mask = 0.041785892099142075, neg_mask = 0.5680102705955505
Training @ epoch = 100, 60/235, loss = 0.01935, pos_mask = 0.03891985863447189, neg_mask = 0.5941464900970459
Training @ epoch = 100, 120/235, loss = 0.02030, pos_mask = 0.04308982565999031, neg_mask = 0.5787307620048523
Training @ epoch = 100, 180/235, loss = 0.02019, pos_mask = 0.037684157490730286, neg_mask = 0.5816407203674316
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 91.07

Patience= -32, Time=43.88922, train_epoch_loss = 0.020132511053630647, test_epoch_acc = 91.07
                                                                                                    
Training @ epoch = 101, 0/235, loss = 0.02084, pos_mask = 0.03162575513124466, neg_mask = 0.5882744789123535
Training @ epoch = 101, 60/235, loss = 0.02008, pos_mask = 0.042894039303064346, neg_mask = 0.5968762636184692
Training @ epoch = 101, 120/235, loss = 0.01957, pos_mask = 0.04307851940393448, neg_mask = 0.5641579627990723
Training @ epoch = 101, 180/235, loss = 0.02005, pos_mask = 0.04667568951845169, neg_mask = 0.5504608750343323
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.15
***********invariance test set **********
Accuracy: 91.14

Patience= -33, Time=44.32024, train_epoch_loss = 0.019925499596494308, test_epoch_acc = 91.14
                                                                                                    
Training @ epoch = 102, 0/235, loss = 0.01865, pos_mask = 0.046203650534152985, neg_mask = 0.5825334191322327
Training @ epoch = 102, 60/235, loss = 0.01988, pos_mask = 0.037978120148181915, neg_mask = 0.5807970762252808
Training @ epoch = 102, 120/235, loss = 0.02018, pos_mask = 0.04667552560567856, neg_mask = 0.5775682330131531
Training @ epoch = 102, 180/235, loss = 0.01931, pos_mask = 0.04609168693423271, neg_mask = 0.5643173456192017
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.15
***********invariance test set **********
Accuracy: 91.01

Patience= -34, Time=44.75649, train_epoch_loss = 0.019773969720018672, test_epoch_acc = 91.01
                                                                                                    
Training @ epoch = 103, 0/235, loss = 0.01914, pos_mask = 0.049571000039577484, neg_mask = 0.5929050445556641
Training @ epoch = 103, 60/235, loss = 0.02011, pos_mask = 0.027567606419324875, neg_mask = 0.6048434376716614
Training @ epoch = 103, 120/235, loss = 0.02026, pos_mask = 0.03526033088564873, neg_mask = 0.5908316373825073
Training @ epoch = 103, 180/235, loss = 0.01971, pos_mask = 0.0383337140083313, neg_mask = 0.5923030376434326
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.16
***********invariance test set **********
Accuracy: 91.01

Patience= -35, Time=45.19003, train_epoch_loss = 0.01955212638416189, test_epoch_acc = 91.01
                                                                                                    
Training @ epoch = 104, 0/235, loss = 0.01947, pos_mask = 0.040398068726062775, neg_mask = 0.5656588077545166
Training @ epoch = 104, 60/235, loss = 0.01907, pos_mask = 0.04532269388437271, neg_mask = 0.5905592441558838
Training @ epoch = 104, 120/235, loss = 0.01922, pos_mask = 0.044986940920352936, neg_mask = 0.5759837031364441
Training @ epoch = 104, 180/235, loss = 0.01858, pos_mask = 0.058127664029598236, neg_mask = 0.5462131500244141
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.16
***********invariance test set **********
Accuracy: 91.17

Patience= -36, Time=45.62294, train_epoch_loss = 0.01929595948375286, test_epoch_acc = 91.17
                                                                                                    
Training @ epoch = 105, 0/235, loss = 0.02005, pos_mask = 0.025643695145845413, neg_mask = 0.6031259298324585
Training @ epoch = 105, 60/235, loss = 0.01901, pos_mask = 0.04385165870189667, neg_mask = 0.5766210556030273
Training @ epoch = 105, 120/235, loss = 0.01869, pos_mask = 0.045342616736888885, neg_mask = 0.582716703414917
Training @ epoch = 105, 180/235, loss = 0.01852, pos_mask = 0.04483170807361603, neg_mask = 0.5773627758026123
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.16
***********invariance test set **********
Accuracy: 90.91

Patience= -37, Time=46.05491, train_epoch_loss = 0.019108238047424782, test_epoch_acc = 90.91
                                                                                                    
Training @ epoch = 106, 0/235, loss = 0.01927, pos_mask = 0.038708172738552094, neg_mask = 0.5908761024475098
Training @ epoch = 106, 60/235, loss = 0.01918, pos_mask = 0.029507705941796303, neg_mask = 0.583878219127655
Training @ epoch = 106, 120/235, loss = 0.01886, pos_mask = 0.04069216176867485, neg_mask = 0.5726193189620972
Training @ epoch = 106, 180/235, loss = 0.01941, pos_mask = 0.03500380739569664, neg_mask = 0.5818190574645996
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 90.88

Patience= -38, Time=46.48944, train_epoch_loss = 0.018871216753378828, test_epoch_acc = 90.88
                                                                                                    
Training @ epoch = 107, 0/235, loss = 0.01793, pos_mask = 0.06210843473672867, neg_mask = 0.5804116725921631
Training @ epoch = 107, 60/235, loss = 0.01868, pos_mask = 0.04153023660182953, neg_mask = 0.5940753221511841
Training @ epoch = 107, 120/235, loss = 0.01836, pos_mask = 0.03647107630968094, neg_mask = 0.577536940574646
Training @ epoch = 107, 180/235, loss = 0.01940, pos_mask = 0.035465776920318604, neg_mask = 0.5992871522903442
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.17
***********invariance test set **********
Accuracy: 90.93

Patience= -39, Time=46.92538, train_epoch_loss = 0.018659782591969407, test_epoch_acc = 90.93
                                                                                                    
Training @ epoch = 108, 0/235, loss = 0.01787, pos_mask = 0.03623965010046959, neg_mask = 0.5849376916885376
Training @ epoch = 108, 60/235, loss = 0.01848, pos_mask = 0.035798270255327225, neg_mask = 0.5856616497039795
Training @ epoch = 108, 120/235, loss = 0.01856, pos_mask = 0.04257572814822197, neg_mask = 0.5786118507385254
Training @ epoch = 108, 180/235, loss = 0.01888, pos_mask = 0.036533601582050323, neg_mask = 0.6080244779586792
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.11
***********invariance test set **********
Accuracy: 90.91

Patience= -40, Time=47.36030, train_epoch_loss = 0.01842741257649787, test_epoch_acc = 90.91
                                                                                                    
Training @ epoch = 109, 0/235, loss = 0.01725, pos_mask = 0.04480133205652237, neg_mask = 0.5907778739929199
Training @ epoch = 109, 60/235, loss = 0.01841, pos_mask = 0.032946400344371796, neg_mask = 0.6140406131744385
Training @ epoch = 109, 120/235, loss = 0.01835, pos_mask = 0.03610638156533241, neg_mask = 0.6018974781036377
Training @ epoch = 109, 180/235, loss = 0.01871, pos_mask = 0.02772192284464836, neg_mask = 0.6034265756607056
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.19
***********invariance test set **********
Accuracy: 91.1

Patience= -41, Time=47.79612, train_epoch_loss = 0.01816530764261459, test_epoch_acc = 91.1
                                                                                                    
Training @ epoch = 110, 0/235, loss = 0.01849, pos_mask = 0.03461061418056488, neg_mask = 0.5734091997146606
Training @ epoch = 110, 60/235, loss = 0.01749, pos_mask = 0.03760400041937828, neg_mask = 0.597564697265625
Training @ epoch = 110, 120/235, loss = 0.01783, pos_mask = 0.043534055352211, neg_mask = 0.616188645362854
Training @ epoch = 110, 180/235, loss = 0.01770, pos_mask = 0.047488465905189514, neg_mask = 0.5671286582946777
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.16
***********invariance test set **********
Accuracy: 91.12

Patience= -42, Time=48.22618, train_epoch_loss = 0.017976878591357392, test_epoch_acc = 91.12
                                                                                                    
Training @ epoch = 111, 0/235, loss = 0.01786, pos_mask = 0.03903871402144432, neg_mask = 0.6000770330429077
Training @ epoch = 111, 60/235, loss = 0.01738, pos_mask = 0.041253890842199326, neg_mask = 0.5808507800102234
Training @ epoch = 111, 120/235, loss = 0.01742, pos_mask = 0.04391549527645111, neg_mask = 0.5641943216323853
Training @ epoch = 111, 180/235, loss = 0.01730, pos_mask = 0.03734485059976578, neg_mask = 0.5992907285690308
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.15
***********invariance test set **********
Accuracy: 91.11

Patience= -43, Time=48.65938, train_epoch_loss = 0.017747908854421148, test_epoch_acc = 91.11
                                                                                                    
Training @ epoch = 112, 0/235, loss = 0.01797, pos_mask = 0.0365050807595253, neg_mask = 0.6059517860412598
Training @ epoch = 112, 60/235, loss = 0.01741, pos_mask = 0.03353946655988693, neg_mask = 0.5904162526130676
Training @ epoch = 112, 120/235, loss = 0.01738, pos_mask = 0.042251504957675934, neg_mask = 0.591373860836029
Training @ epoch = 112, 180/235, loss = 0.01788, pos_mask = 0.035812973976135254, neg_mask = 0.595528244972229
***********original test set **********
Accuracy: 99.14
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 90.68

Patience= -44, Time=49.09381, train_epoch_loss = 0.017456447261762112, test_epoch_acc = 90.68
                                                                                                    
Training @ epoch = 113, 0/235, loss = 0.01814, pos_mask = 0.028379548341035843, neg_mask = 0.6098707318305969
Training @ epoch = 113, 60/235, loss = 0.01660, pos_mask = 0.05084266513586044, neg_mask = 0.5710982084274292
Training @ epoch = 113, 120/235, loss = 0.01762, pos_mask = 0.03402937203645706, neg_mask = 0.620002269744873
Training @ epoch = 113, 180/235, loss = 0.01752, pos_mask = 0.032383326441049576, neg_mask = 0.6007108092308044
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 90.87

Patience= -45, Time=49.52510, train_epoch_loss = 0.01722749026214823, test_epoch_acc = 90.87
                                                                                                    
Training @ epoch = 114, 0/235, loss = 0.01740, pos_mask = 0.03410112485289574, neg_mask = 0.5969810485839844
Training @ epoch = 114, 60/235, loss = 0.01649, pos_mask = 0.0353291779756546, neg_mask = 0.5851278305053711
Training @ epoch = 114, 120/235, loss = 0.01676, pos_mask = 0.044486768543720245, neg_mask = 0.5877167582511902
Training @ epoch = 114, 180/235, loss = 0.01681, pos_mask = 0.03436475247144699, neg_mask = 0.6259663701057434
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.12
***********invariance test set **********
Accuracy: 90.63

Patience= -46, Time=49.95831, train_epoch_loss = 0.01698562115272309, test_epoch_acc = 90.63
                                                                                                    
Training @ epoch = 115, 0/235, loss = 0.01663, pos_mask = 0.04086052626371384, neg_mask = 0.575316846370697
Training @ epoch = 115, 60/235, loss = 0.01655, pos_mask = 0.03327171504497528, neg_mask = 0.6084904670715332
Training @ epoch = 115, 120/235, loss = 0.01633, pos_mask = 0.036976832896471024, neg_mask = 0.5913043022155762
Training @ epoch = 115, 180/235, loss = 0.01607, pos_mask = 0.042669087648391724, neg_mask = 0.5788271427154541
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 91.24

Patience= -47, Time=50.39550, train_epoch_loss = 0.01677090931445994, test_epoch_acc = 91.24
                                                                                                    
Training @ epoch = 116, 0/235, loss = 0.01631, pos_mask = 0.03427056968212128, neg_mask = 0.5945855379104614
Training @ epoch = 116, 60/235, loss = 0.01661, pos_mask = 0.03340718895196915, neg_mask = 0.6034766435623169
Training @ epoch = 116, 120/235, loss = 0.01568, pos_mask = 0.05452284589409828, neg_mask = 0.590146005153656
Training @ epoch = 116, 180/235, loss = 0.01700, pos_mask = 0.030385233461856842, neg_mask = 0.6096527576446533
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 91.08

Patience= -48, Time=50.82405, train_epoch_loss = 0.016500950450117284, test_epoch_acc = 91.08
                                                                                                    
Training @ epoch = 117, 0/235, loss = 0.01706, pos_mask = 0.02714761346578598, neg_mask = 0.6122521162033081
Training @ epoch = 117, 60/235, loss = 0.01594, pos_mask = 0.04037145525217056, neg_mask = 0.5790967345237732
Training @ epoch = 117, 120/235, loss = 0.01653, pos_mask = 0.04706275463104248, neg_mask = 0.600749135017395
Training @ epoch = 117, 180/235, loss = 0.01616, pos_mask = 0.033817484974861145, neg_mask = 0.5807207226753235
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 91.15

Patience= -49, Time=51.25647, train_epoch_loss = 0.01627369624899423, test_epoch_acc = 91.15
                                                                                                    
Training @ epoch = 118, 0/235, loss = 0.01606, pos_mask = 0.031191140413284302, neg_mask = 0.6089843511581421
Training @ epoch = 118, 60/235, loss = 0.01554, pos_mask = 0.03365464508533478, neg_mask = 0.6114733219146729
Training @ epoch = 118, 120/235, loss = 0.01606, pos_mask = 0.027597486972808838, neg_mask = 0.6093827486038208
Training @ epoch = 118, 180/235, loss = 0.01641, pos_mask = 0.02865295298397541, neg_mask = 0.6151552796363831
***********original test set **********
Accuracy: 99.12
***********sensitivity test set **********
Accuracy: 99.11
***********invariance test set **********
Accuracy: 90.83

Patience= -50, Time=51.68717, train_epoch_loss = 0.016054302382659404, test_epoch_acc = 90.83
                                                                                                    
Training @ epoch = 119, 0/235, loss = 0.01615, pos_mask = 0.04523894190788269, neg_mask = 0.5995219945907593
Training @ epoch = 119, 60/235, loss = 0.01547, pos_mask = 0.02694535255432129, neg_mask = 0.6354699730873108
Training @ epoch = 119, 120/235, loss = 0.01572, pos_mask = 0.030492765828967094, neg_mask = 0.598966658115387
Training @ epoch = 119, 180/235, loss = 0.01577, pos_mask = 0.039087601006031036, neg_mask = 0.6056030988693237
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 90.99

Patience= -51, Time=52.11939, train_epoch_loss = 0.015844826546913767, test_epoch_acc = 90.99
                                                                                                    
Training @ epoch = 120, 0/235, loss = 0.01579, pos_mask = 0.03683624789118767, neg_mask = 0.6086657643318176
Training @ epoch = 120, 60/235, loss = 0.01640, pos_mask = 0.02354438602924347, neg_mask = 0.6212059259414673
Training @ epoch = 120, 120/235, loss = 0.01567, pos_mask = 0.03656556457281113, neg_mask = 0.6245186924934387
Training @ epoch = 120, 180/235, loss = 0.01589, pos_mask = 0.04424455016851425, neg_mask = 0.6030218601226807
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 90.79

Patience= -52, Time=52.54985, train_epoch_loss = 0.015685703894717896, test_epoch_acc = 90.79
                                                                                                    
Training @ epoch = 121, 0/235, loss = 0.01565, pos_mask = 0.023997459560632706, neg_mask = 0.622285008430481
Training @ epoch = 121, 60/235, loss = 0.01552, pos_mask = 0.03778834268450737, neg_mask = 0.6257583498954773
Training @ epoch = 121, 120/235, loss = 0.08073, pos_mask = 0.1683935821056366, neg_mask = 0.4018838107585907
Training @ epoch = 121, 180/235, loss = 0.03005, pos_mask = 0.10139501094818115, neg_mask = 0.4718567430973053
***********original test set **********
Accuracy: 99.01
***********sensitivity test set **********
Accuracy: 98.73
***********invariance test set **********
Accuracy: 88.53

Patience= -53, Time=52.98345, train_epoch_loss = 0.03342986348620121, test_epoch_acc = 88.53
                                                                                                    
Training @ epoch = 122, 0/235, loss = 0.01999, pos_mask = 0.09205254912376404, neg_mask = 0.49426746368408203
Training @ epoch = 122, 60/235, loss = 0.01855, pos_mask = 0.06312708556652069, neg_mask = 0.5645241737365723
Training @ epoch = 122, 120/235, loss = 0.01715, pos_mask = 0.06327200680971146, neg_mask = 0.5224077105522156
Training @ epoch = 122, 180/235, loss = 0.01940, pos_mask = 0.08930420875549316, neg_mask = 0.5493605136871338
***********original test set **********
Accuracy: 99.03
***********sensitivity test set **********
Accuracy: 98.93
***********invariance test set **********
Accuracy: 89.13

Patience= -54, Time=53.41708, train_epoch_loss = 0.0186031773844932, test_epoch_acc = 89.13
                                                                                                    
Training @ epoch = 123, 0/235, loss = 0.02059, pos_mask = 0.08022872358560562, neg_mask = 0.541906476020813
Training @ epoch = 123, 60/235, loss = 0.01592, pos_mask = 0.03814813494682312, neg_mask = 0.5944680571556091
Training @ epoch = 123, 120/235, loss = 0.01667, pos_mask = 0.0729912668466568, neg_mask = 0.5387415885925293
Training @ epoch = 123, 180/235, loss = 0.01644, pos_mask = 0.05169276148080826, neg_mask = 0.5622568130493164
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.5

Patience= -55, Time=53.85263, train_epoch_loss = 0.016680574623194146, test_epoch_acc = 90.5
                                                                                                    
Training @ epoch = 124, 0/235, loss = 0.01558, pos_mask = 0.05955156311392784, neg_mask = 0.5552471876144409
Training @ epoch = 124, 60/235, loss = 0.01646, pos_mask = 0.03619328886270523, neg_mask = 0.5706217288970947
Training @ epoch = 124, 120/235, loss = 0.01541, pos_mask = 0.0542609728872776, neg_mask = 0.5829579830169678
Training @ epoch = 124, 180/235, loss = 0.01571, pos_mask = 0.04260462522506714, neg_mask = 0.5963623523712158
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.0
***********invariance test set **********
Accuracy: 90.53

Patience= -56, Time=54.28811, train_epoch_loss = 0.015816450340950743, test_epoch_acc = 90.53
                                                                                                    
Training @ epoch = 125, 0/235, loss = 0.01552, pos_mask = 0.0510629341006279, neg_mask = 0.5736300945281982
Training @ epoch = 125, 60/235, loss = 0.01532, pos_mask = 0.05489561706781387, neg_mask = 0.5835436582565308
Training @ epoch = 125, 120/235, loss = 0.01574, pos_mask = 0.03847762569785118, neg_mask = 0.6018752455711365
Training @ epoch = 125, 180/235, loss = 0.01586, pos_mask = 0.033746689558029175, neg_mask = 0.5891490578651428
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 90.71

Patience= -57, Time=54.72292, train_epoch_loss = 0.015622137756423748, test_epoch_acc = 90.71
                                                                                                    
Training @ epoch = 126, 0/235, loss = 0.01563, pos_mask = 0.036640796810388565, neg_mask = 0.6082350015640259
Training @ epoch = 126, 60/235, loss = 0.01486, pos_mask = 0.047987617552280426, neg_mask = 0.5737181901931763
Training @ epoch = 126, 120/235, loss = 0.01529, pos_mask = 0.043413013219833374, neg_mask = 0.5825372338294983
Training @ epoch = 126, 180/235, loss = 0.01545, pos_mask = 0.040138162672519684, neg_mask = 0.6116383075714111
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 90.53

Patience= -58, Time=55.15763, train_epoch_loss = 0.015444101191105996, test_epoch_acc = 90.53
                                                                                                    
Training @ epoch = 127, 0/235, loss = 0.01522, pos_mask = 0.04886826127767563, neg_mask = 0.5954023599624634
Training @ epoch = 127, 60/235, loss = 0.01573, pos_mask = 0.04002921283245087, neg_mask = 0.6085107922554016
Training @ epoch = 127, 120/235, loss = 0.01568, pos_mask = 0.03726226091384888, neg_mask = 0.5926567912101746
Training @ epoch = 127, 180/235, loss = 0.01495, pos_mask = 0.02986580692231655, neg_mask = 0.600190281867981
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.52

Patience= -59, Time=55.59245, train_epoch_loss = 0.01532899002604028, test_epoch_acc = 90.52
                                                                                                    
Training @ epoch = 128, 0/235, loss = 0.01551, pos_mask = 0.037917234003543854, neg_mask = 0.6069167852401733
Training @ epoch = 128, 60/235, loss = 0.01539, pos_mask = 0.03885073959827423, neg_mask = 0.6040969491004944
Training @ epoch = 128, 120/235, loss = 0.01507, pos_mask = 0.04714060574769974, neg_mask = 0.6132887601852417
Training @ epoch = 128, 180/235, loss = 0.01584, pos_mask = 0.027707159519195557, neg_mask = 0.6255583763122559
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 90.4

Patience= -60, Time=56.02278, train_epoch_loss = 0.015181758116058847, test_epoch_acc = 90.4
                                                                                                    
Training @ epoch = 129, 0/235, loss = 0.01511, pos_mask = 0.03644691780209541, neg_mask = 0.6038384437561035
Training @ epoch = 129, 60/235, loss = 0.01422, pos_mask = 0.05304538458585739, neg_mask = 0.5864579081535339
Training @ epoch = 129, 120/235, loss = 0.01488, pos_mask = 0.0312909334897995, neg_mask = 0.5952185392379761
Training @ epoch = 129, 180/235, loss = 0.01488, pos_mask = 0.04726916924118996, neg_mask = 0.6006852388381958
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.72

Patience= -61, Time=56.45662, train_epoch_loss = 0.015077734076754844, test_epoch_acc = 90.72
                                                                                                    
Training @ epoch = 130, 0/235, loss = 0.01515, pos_mask = 0.0364990159869194, neg_mask = 0.5922937393188477
Training @ epoch = 130, 60/235, loss = 0.01483, pos_mask = 0.03304566442966461, neg_mask = 0.6037046909332275
Training @ epoch = 130, 120/235, loss = 0.01498, pos_mask = 0.03837946802377701, neg_mask = 0.5863922238349915
Training @ epoch = 130, 180/235, loss = 0.01491, pos_mask = 0.0442320853471756, neg_mask = 0.598024308681488
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.81

Patience= -62, Time=56.88949, train_epoch_loss = 0.01498377817742368, test_epoch_acc = 90.81
                                                                                                    
Training @ epoch = 131, 0/235, loss = 0.01499, pos_mask = 0.03250420093536377, neg_mask = 0.6187240481376648
Training @ epoch = 131, 60/235, loss = 0.01489, pos_mask = 0.030465058982372284, neg_mask = 0.6017535328865051
Training @ epoch = 131, 120/235, loss = 0.01536, pos_mask = 0.03909013047814369, neg_mask = 0.6164337992668152
Training @ epoch = 131, 180/235, loss = 0.01626, pos_mask = 0.026651859283447266, neg_mask = 0.645319938659668
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.67

Patience= -63, Time=57.32254, train_epoch_loss = 0.014861980350093638, test_epoch_acc = 90.67
                                                                                                    
Training @ epoch = 132, 0/235, loss = 0.01532, pos_mask = 0.025574728846549988, neg_mask = 0.607495903968811
Training @ epoch = 132, 60/235, loss = 0.01531, pos_mask = 0.030223293229937553, neg_mask = 0.6191180944442749
Training @ epoch = 132, 120/235, loss = 0.01439, pos_mask = 0.04363102465867996, neg_mask = 0.5776814222335815
Training @ epoch = 132, 180/235, loss = 0.01475, pos_mask = 0.02862226963043213, neg_mask = 0.6288855075836182
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 90.61

Patience= -64, Time=57.75535, train_epoch_loss = 0.014769325995857412, test_epoch_acc = 90.61
                                                                                                    
Training @ epoch = 133, 0/235, loss = 0.01429, pos_mask = 0.04245862737298012, neg_mask = 0.5734045505523682
Training @ epoch = 133, 60/235, loss = 0.01444, pos_mask = 0.03350221365690231, neg_mask = 0.6123345494270325
Training @ epoch = 133, 120/235, loss = 0.01405, pos_mask = 0.034817807376384735, neg_mask = 0.6002682447433472
Training @ epoch = 133, 180/235, loss = 0.01435, pos_mask = 0.029649335891008377, neg_mask = 0.6180089116096497
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.71

Patience= -65, Time=58.18747, train_epoch_loss = 0.014628007809849495, test_epoch_acc = 90.71
                                                                                                    
Training @ epoch = 134, 0/235, loss = 0.01453, pos_mask = 0.0346052348613739, neg_mask = 0.6039322018623352
Training @ epoch = 134, 60/235, loss = 0.01466, pos_mask = 0.03190705180168152, neg_mask = 0.6317877769470215
Training @ epoch = 134, 120/235, loss = 0.01420, pos_mask = 0.03460928797721863, neg_mask = 0.6045759320259094
Training @ epoch = 134, 180/235, loss = 0.01458, pos_mask = 0.03651777654886246, neg_mask = 0.5938971042633057
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 90.87

Patience= -66, Time=58.62148, train_epoch_loss = 0.01450093759501234, test_epoch_acc = 90.87
                                                                                                    
Training @ epoch = 135, 0/235, loss = 0.01544, pos_mask = 0.02457713708281517, neg_mask = 0.6372416615486145
Training @ epoch = 135, 60/235, loss = 0.01502, pos_mask = 0.019375018775463104, neg_mask = 0.6390554904937744
Training @ epoch = 135, 120/235, loss = 0.01445, pos_mask = 0.02635268121957779, neg_mask = 0.617438554763794
Training @ epoch = 135, 180/235, loss = 0.01473, pos_mask = 0.026892412453889847, neg_mask = 0.6155447959899902
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.56

Patience= -67, Time=59.05163, train_epoch_loss = 0.014388559976632291, test_epoch_acc = 90.56
                                                                                                    
Training @ epoch = 136, 0/235, loss = 0.01375, pos_mask = 0.04384644702076912, neg_mask = 0.596005380153656
Training @ epoch = 136, 60/235, loss = 0.01434, pos_mask = 0.029994435608386993, neg_mask = 0.6076340675354004
Training @ epoch = 136, 120/235, loss = 0.01473, pos_mask = 0.020666131749749184, neg_mask = 0.6294805407524109
Training @ epoch = 136, 180/235, loss = 0.01495, pos_mask = 0.025706717744469643, neg_mask = 0.6290592551231384
***********original test set **********
Accuracy: 99.24
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.74

Patience= -68, Time=59.48309, train_epoch_loss = 0.014241081860629803, test_epoch_acc = 90.74
                                                                                                    
Training @ epoch = 137, 0/235, loss = 0.01386, pos_mask = 0.03990912809967995, neg_mask = 0.6265599727630615
Training @ epoch = 137, 60/235, loss = 0.01373, pos_mask = 0.049038469791412354, neg_mask = 0.6053519248962402
Training @ epoch = 137, 120/235, loss = 0.01401, pos_mask = 0.025303978472948074, neg_mask = 0.6335490345954895
Training @ epoch = 137, 180/235, loss = 0.01417, pos_mask = 0.0321502611041069, neg_mask = 0.624052882194519
***********original test set **********
Accuracy: 99.25
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 90.75

Patience= -69, Time=59.91753, train_epoch_loss = 0.014107727215803684, test_epoch_acc = 90.75
                                                                                                    
Training @ epoch = 138, 0/235, loss = 0.01431, pos_mask = 0.02757633477449417, neg_mask = 0.608968198299408
Training @ epoch = 138, 60/235, loss = 0.01333, pos_mask = 0.034954894334077835, neg_mask = 0.6038105487823486
Training @ epoch = 138, 120/235, loss = 0.01392, pos_mask = 0.036632735282182693, neg_mask = 0.6315538883209229
Training @ epoch = 138, 180/235, loss = 0.01377, pos_mask = 0.03612479567527771, neg_mask = 0.6004428863525391
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.58

Patience= -70, Time=60.35145, train_epoch_loss = 0.01397377423783566, test_epoch_acc = 90.58
                                                                                                    
Training @ epoch = 139, 0/235, loss = 0.01392, pos_mask = 0.03137381747364998, neg_mask = 0.6227025985717773
Training @ epoch = 139, 60/235, loss = 0.01383, pos_mask = 0.03824963420629501, neg_mask = 0.6340721845626831
Training @ epoch = 139, 120/235, loss = 0.01435, pos_mask = 0.029830776154994965, neg_mask = 0.6381311416625977
Training @ epoch = 139, 180/235, loss = 0.01358, pos_mask = 0.032093167304992676, neg_mask = 0.614669680595398
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.44

Patience= -71, Time=60.78358, train_epoch_loss = 0.013820046642200745, test_epoch_acc = 90.44
                                                                                                    
Training @ epoch = 140, 0/235, loss = 0.01341, pos_mask = 0.031110068783164024, neg_mask = 0.6178390979766846
Training @ epoch = 140, 60/235, loss = 0.01313, pos_mask = 0.03961605206131935, neg_mask = 0.6155264973640442
Training @ epoch = 140, 120/235, loss = 0.01329, pos_mask = 0.029827585443854332, neg_mask = 0.6025803685188293
Training @ epoch = 140, 180/235, loss = 0.01420, pos_mask = 0.029204946011304855, neg_mask = 0.6304742097854614
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 90.57

Patience= -72, Time=61.21971, train_epoch_loss = 0.013685962605349562, test_epoch_acc = 90.57
                                                                                                    
Training @ epoch = 141, 0/235, loss = 0.01295, pos_mask = 0.034607239067554474, neg_mask = 0.6088348031044006
Training @ epoch = 141, 60/235, loss = 0.01306, pos_mask = 0.03117399290204048, neg_mask = 0.6403571367263794
Training @ epoch = 141, 120/235, loss = 0.01384, pos_mask = 0.02920730970799923, neg_mask = 0.6125473976135254
Training @ epoch = 141, 180/235, loss = 0.01307, pos_mask = 0.03107793629169464, neg_mask = 0.5914421677589417
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.11
***********invariance test set **********
Accuracy: 90.62

Patience= -73, Time=61.65294, train_epoch_loss = 0.01357986044455716, test_epoch_acc = 90.62
                                                                                                    
Training @ epoch = 142, 0/235, loss = 0.01322, pos_mask = 0.024628248065710068, neg_mask = 0.6211345791816711
Training @ epoch = 142, 60/235, loss = 0.01319, pos_mask = 0.037541016936302185, neg_mask = 0.6008983850479126
Training @ epoch = 142, 120/235, loss = 0.01392, pos_mask = 0.02594222128391266, neg_mask = 0.652052640914917
Training @ epoch = 142, 180/235, loss = 0.01258, pos_mask = 0.03989432007074356, neg_mask = 0.5945593118667603
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 91.05

Patience= -74, Time=62.08694, train_epoch_loss = 0.013406289261864855, test_epoch_acc = 91.05
                                                                                                    
Training @ epoch = 143, 0/235, loss = 0.01321, pos_mask = 0.03722183033823967, neg_mask = 0.6356445550918579
Training @ epoch = 143, 60/235, loss = 0.01303, pos_mask = 0.02819545939564705, neg_mask = 0.6061611175537109
Training @ epoch = 143, 120/235, loss = 0.01341, pos_mask = 0.0253292229026556, neg_mask = 0.6357399821281433
Training @ epoch = 143, 180/235, loss = 0.01277, pos_mask = 0.040096454322338104, neg_mask = 0.6009335517883301
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.77

Patience= -75, Time=62.52045, train_epoch_loss = 0.013272410543992164, test_epoch_acc = 90.77
                                                                                                    
Training @ epoch = 144, 0/235, loss = 0.01312, pos_mask = 0.031979747116565704, neg_mask = 0.6261942386627197
Training @ epoch = 144, 60/235, loss = 0.01385, pos_mask = 0.0249776728451252, neg_mask = 0.6220099329948425
Training @ epoch = 144, 120/235, loss = 0.01274, pos_mask = 0.03235853463411331, neg_mask = 0.6297268867492676
Training @ epoch = 144, 180/235, loss = 0.01338, pos_mask = 0.030136048793792725, neg_mask = 0.6387463808059692
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 90.91

Patience= -76, Time=62.95373, train_epoch_loss = 0.013143182637051064, test_epoch_acc = 90.91
                                                                                                    
Training @ epoch = 145, 0/235, loss = 0.01219, pos_mask = 0.036080315709114075, neg_mask = 0.6097313761711121
Training @ epoch = 145, 60/235, loss = 0.01297, pos_mask = 0.02861502766609192, neg_mask = 0.6224797964096069
Training @ epoch = 145, 120/235, loss = 0.01283, pos_mask = 0.02773071825504303, neg_mask = 0.6199720501899719
Training @ epoch = 145, 180/235, loss = 0.01271, pos_mask = 0.02657923474907875, neg_mask = 0.6400622129440308
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.5

Patience= -77, Time=63.38391, train_epoch_loss = 0.013001598005599163, test_epoch_acc = 90.5
                                                                                                    
Training @ epoch = 146, 0/235, loss = 0.01276, pos_mask = 0.028670256957411766, neg_mask = 0.626571774482727
Training @ epoch = 146, 60/235, loss = 0.01385, pos_mask = 0.04254163056612015, neg_mask = 0.5767277479171753
Training @ epoch = 146, 120/235, loss = 0.08278, pos_mask = 0.24298962950706482, neg_mask = 0.3754945397377014
Training @ epoch = 146, 180/235, loss = 0.02149, pos_mask = 0.08878069370985031, neg_mask = 0.519406795501709
***********original test set **********
Accuracy: 98.96
***********sensitivity test set **********
Accuracy: 98.76
***********invariance test set **********
Accuracy: 88.36

Patience= -78, Time=63.81959, train_epoch_loss = 0.03106170949783731, test_epoch_acc = 88.36
                                                                                                    
Training @ epoch = 147, 0/235, loss = 0.02005, pos_mask = 0.09643439948558807, neg_mask = 0.4525500535964966
Training @ epoch = 147, 60/235, loss = 0.01662, pos_mask = 0.10257087647914886, neg_mask = 0.5059494972229004
Training @ epoch = 147, 120/235, loss = 0.03141, pos_mask = 0.12102007865905762, neg_mask = 0.4723270535469055
Training @ epoch = 147, 180/235, loss = 0.01567, pos_mask = 0.0514519028365612, neg_mask = 0.5762079358100891
***********original test set **********
Accuracy: 99.12
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 90.33

Patience= -79, Time=64.25479, train_epoch_loss = 0.0193850959908772, test_epoch_acc = 90.33
                                                                                                    
Training @ epoch = 148, 0/235, loss = 0.01498, pos_mask = 0.06406031548976898, neg_mask = 0.5392047166824341
Training @ epoch = 148, 60/235, loss = 0.01366, pos_mask = 0.042684897780418396, neg_mask = 0.5602567195892334
Training @ epoch = 148, 120/235, loss = 0.01405, pos_mask = 0.03721504285931587, neg_mask = 0.6137024164199829
Training @ epoch = 148, 180/235, loss = 0.01456, pos_mask = 0.03686070442199707, neg_mask = 0.5999119281768799
***********original test set **********
Accuracy: 99.15
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 90.58

Patience= -80, Time=64.68732, train_epoch_loss = 0.014106630462598293, test_epoch_acc = 90.58
                                                                                                    
Training @ epoch = 149, 0/235, loss = 0.01373, pos_mask = 0.05075971037149429, neg_mask = 0.5598549246788025
Training @ epoch = 149, 60/235, loss = 0.01309, pos_mask = 0.053474776446819305, neg_mask = 0.5853778123855591
Training @ epoch = 149, 120/235, loss = 0.01364, pos_mask = 0.0463821217417717, neg_mask = 0.5729024410247803
Training @ epoch = 149, 180/235, loss = 0.01325, pos_mask = 0.04155086725950241, neg_mask = 0.5974688529968262
***********original test set **********
Accuracy: 99.15
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 90.58

Patience= -81, Time=65.12466, train_epoch_loss = 0.01362785083895668, test_epoch_acc = 90.58
                                                                                                    
Training @ epoch = 150, 0/235, loss = 0.01352, pos_mask = 0.048058103770017624, neg_mask = 0.5895113945007324
Training @ epoch = 150, 60/235, loss = 0.01395, pos_mask = 0.04846835136413574, neg_mask = 0.5972288846969604
Training @ epoch = 150, 120/235, loss = 0.01336, pos_mask = 0.04884261637926102, neg_mask = 0.5876997709274292
Training @ epoch = 150, 180/235, loss = 0.01355, pos_mask = 0.03270072117447853, neg_mask = 0.609674870967865
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 90.7

Patience= -82, Time=65.55855, train_epoch_loss = 0.013378793147808694, test_epoch_acc = 90.7
                                                                                                    
Training @ epoch = 151, 0/235, loss = 0.01360, pos_mask = 0.03457489609718323, neg_mask = 0.6066890358924866
Training @ epoch = 151, 60/235, loss = 0.01360, pos_mask = 0.032099559903144836, neg_mask = 0.6160826086997986
Training @ epoch = 151, 120/235, loss = 0.01319, pos_mask = 0.032509494572877884, neg_mask = 0.6132633090019226
Training @ epoch = 151, 180/235, loss = 0.01345, pos_mask = 0.04233860597014427, neg_mask = 0.6060717701911926
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.64

Patience= -83, Time=65.99236, train_epoch_loss = 0.013229139482087277, test_epoch_acc = 90.64
                                                                                                    
Training @ epoch = 152, 0/235, loss = 0.01264, pos_mask = 0.03766253590583801, neg_mask = 0.6117812395095825
Training @ epoch = 152, 60/235, loss = 0.01299, pos_mask = 0.03264125809073448, neg_mask = 0.5946154594421387
Training @ epoch = 152, 120/235, loss = 0.01371, pos_mask = 0.03414018452167511, neg_mask = 0.605979323387146
Training @ epoch = 152, 180/235, loss = 0.01335, pos_mask = 0.03946440666913986, neg_mask = 0.6176987886428833
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.59

Patience= -84, Time=66.42440, train_epoch_loss = 0.013083283753788217, test_epoch_acc = 90.59
                                                                                                    
Training @ epoch = 153, 0/235, loss = 0.01246, pos_mask = 0.0410224124789238, neg_mask = 0.6031979322433472
Training @ epoch = 153, 60/235, loss = 0.01296, pos_mask = 0.04071281850337982, neg_mask = 0.604139506816864
Training @ epoch = 153, 120/235, loss = 0.01270, pos_mask = 0.039570167660713196, neg_mask = 0.6002563238143921
Training @ epoch = 153, 180/235, loss = 0.01304, pos_mask = 0.034076984971761703, neg_mask = 0.5931361317634583
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.68

Patience= -85, Time=66.86232, train_epoch_loss = 0.013003501601200155, test_epoch_acc = 90.68
                                                                                                    
Training @ epoch = 154, 0/235, loss = 0.01375, pos_mask = 0.028482388705015182, neg_mask = 0.6154739260673523
Training @ epoch = 154, 60/235, loss = 0.01236, pos_mask = 0.042946603149175644, neg_mask = 0.5989793539047241
Training @ epoch = 154, 120/235, loss = 0.01300, pos_mask = 0.03197317570447922, neg_mask = 0.5987684726715088
Training @ epoch = 154, 180/235, loss = 0.01293, pos_mask = 0.04089357703924179, neg_mask = 0.6119179725646973
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.11
***********invariance test set **********
Accuracy: 90.79

Patience= -86, Time=67.30047, train_epoch_loss = 0.012865929828679307, test_epoch_acc = 90.79
                                                                                                    
Training @ epoch = 155, 0/235, loss = 0.01269, pos_mask = 0.04681377485394478, neg_mask = 0.5964136719703674
Training @ epoch = 155, 60/235, loss = 0.01279, pos_mask = 0.030057139694690704, neg_mask = 0.626973032951355
Training @ epoch = 155, 120/235, loss = 0.01248, pos_mask = 0.03555610775947571, neg_mask = 0.6043376922607422
Training @ epoch = 155, 180/235, loss = 0.01267, pos_mask = 0.033992428332567215, neg_mask = 0.6006898880004883
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.09
***********invariance test set **********
Accuracy: 90.81

Patience= -87, Time=67.73500, train_epoch_loss = 0.012779971854166782, test_epoch_acc = 90.81
                                                                                                    
Training @ epoch = 156, 0/235, loss = 0.01313, pos_mask = 0.03293341025710106, neg_mask = 0.6370728611946106
Training @ epoch = 156, 60/235, loss = 0.01270, pos_mask = 0.033304065465927124, neg_mask = 0.6198577880859375
Training @ epoch = 156, 120/235, loss = 0.01180, pos_mask = 0.05051039159297943, neg_mask = 0.5810460448265076
Training @ epoch = 156, 180/235, loss = 0.01281, pos_mask = 0.03128255903720856, neg_mask = 0.6320331692695618
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 90.69

Patience= -88, Time=68.16851, train_epoch_loss = 0.012684540747803577, test_epoch_acc = 90.69
                                                                                                    
Training @ epoch = 157, 0/235, loss = 0.01225, pos_mask = 0.04149328172206879, neg_mask = 0.6080942153930664
Training @ epoch = 157, 60/235, loss = 0.01307, pos_mask = 0.03184237331151962, neg_mask = 0.6214998364448547
Training @ epoch = 157, 120/235, loss = 0.01234, pos_mask = 0.029214326292276382, neg_mask = 0.5957654714584351
Training @ epoch = 157, 180/235, loss = 0.01285, pos_mask = 0.027933543547987938, neg_mask = 0.6294834613800049
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.11
***********invariance test set **********
Accuracy: 90.6

Patience= -89, Time=68.60263, train_epoch_loss = 0.012591395083260029, test_epoch_acc = 90.6
                                                                                                    
Training @ epoch = 158, 0/235, loss = 0.01258, pos_mask = 0.03037543036043644, neg_mask = 0.6101775169372559
Training @ epoch = 158, 60/235, loss = 0.01224, pos_mask = 0.03637314587831497, neg_mask = 0.6096926331520081
Training @ epoch = 158, 120/235, loss = 0.01279, pos_mask = 0.025050602853298187, neg_mask = 0.6239255666732788
Training @ epoch = 158, 180/235, loss = 0.01253, pos_mask = 0.023767082020640373, neg_mask = 0.6347013711929321
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.09
***********invariance test set **********
Accuracy: 90.79

Patience= -90, Time=69.03315, train_epoch_loss = 0.012495877780020237, test_epoch_acc = 90.79
                                                                                                    
Training @ epoch = 159, 0/235, loss = 0.01208, pos_mask = 0.025063101202249527, neg_mask = 0.6124221086502075
Training @ epoch = 159, 60/235, loss = 0.01277, pos_mask = 0.026901261880993843, neg_mask = 0.6322104930877686
Training @ epoch = 159, 120/235, loss = 0.01278, pos_mask = 0.025608200579881668, neg_mask = 0.6438028812408447
Training @ epoch = 159, 180/235, loss = 0.01343, pos_mask = 0.02093847095966339, neg_mask = 0.6421563625335693
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.09
***********invariance test set **********
Accuracy: 90.77

Patience= -91, Time=69.46366, train_epoch_loss = 0.01242899996961685, test_epoch_acc = 90.77
                                                                                                    
Training @ epoch = 160, 0/235, loss = 0.01269, pos_mask = 0.019281717017292976, neg_mask = 0.6472394466400146
Training @ epoch = 160, 60/235, loss = 0.01233, pos_mask = 0.02281942404806614, neg_mask = 0.6166048645973206
Training @ epoch = 160, 120/235, loss = 0.01190, pos_mask = 0.03527121990919113, neg_mask = 0.5998443365097046
Training @ epoch = 160, 180/235, loss = 0.01209, pos_mask = 0.028977010399103165, neg_mask = 0.6154808402061462
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.8

Patience= -92, Time=69.89978, train_epoch_loss = 0.012313307968384408, test_epoch_acc = 90.8
                                                                                                    
Training @ epoch = 161, 0/235, loss = 0.01211, pos_mask = 0.02460482344031334, neg_mask = 0.6400216817855835
Training @ epoch = 161, 60/235, loss = 0.01189, pos_mask = 0.027224648743867874, neg_mask = 0.6373950242996216
Training @ epoch = 161, 120/235, loss = 0.01237, pos_mask = 0.02965467981994152, neg_mask = 0.6317033767700195
Training @ epoch = 161, 180/235, loss = 0.01157, pos_mask = 0.03405648469924927, neg_mask = 0.6229950189590454
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.63

Patience= -93, Time=70.32707, train_epoch_loss = 0.012193068164460202, test_epoch_acc = 90.63
                                                                                                    
Training @ epoch = 162, 0/235, loss = 0.01227, pos_mask = 0.02523198351264, neg_mask = 0.6277651190757751
Training @ epoch = 162, 60/235, loss = 0.01227, pos_mask = 0.023034512996673584, neg_mask = 0.6282467842102051
Training @ epoch = 162, 120/235, loss = 0.01224, pos_mask = 0.02512339875102043, neg_mask = 0.626278817653656
Training @ epoch = 162, 180/235, loss = 0.01216, pos_mask = 0.026907002553343773, neg_mask = 0.6198326349258423
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 90.82

Patience= -94, Time=70.76293, train_epoch_loss = 0.012130022064802494, test_epoch_acc = 90.82
                                                                                                    
Training @ epoch = 163, 0/235, loss = 0.01219, pos_mask = 0.025725847110152245, neg_mask = 0.6180235743522644
Training @ epoch = 163, 60/235, loss = 0.01214, pos_mask = 0.03718008100986481, neg_mask = 0.6405113339424133
Training @ epoch = 163, 120/235, loss = 0.01218, pos_mask = 0.028584502637386322, neg_mask = 0.6407424211502075
Training @ epoch = 163, 180/235, loss = 0.01226, pos_mask = 0.025384891778230667, neg_mask = 0.6172457933425903
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.63

Patience= -95, Time=71.19704, train_epoch_loss = 0.0119993800059595, test_epoch_acc = 90.63
                                                                                                    
Training @ epoch = 164, 0/235, loss = 0.01171, pos_mask = 0.028545543551445007, neg_mask = 0.6409226059913635
Training @ epoch = 164, 60/235, loss = 0.01190, pos_mask = 0.02797270566225052, neg_mask = 0.6408246755599976
Training @ epoch = 164, 120/235, loss = 0.01186, pos_mask = 0.03747119382023811, neg_mask = 0.6187679767608643
Training @ epoch = 164, 180/235, loss = 0.01220, pos_mask = 0.03686053305864334, neg_mask = 0.6506800651550293
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.73

Patience= -96, Time=71.62829, train_epoch_loss = 0.011904288978969797, test_epoch_acc = 90.73
                                                                                                    
Training @ epoch = 165, 0/235, loss = 0.01157, pos_mask = 0.0369122177362442, neg_mask = 0.6351284980773926
Training @ epoch = 165, 60/235, loss = 0.01132, pos_mask = 0.03205391764640808, neg_mask = 0.622573733329773
Training @ epoch = 165, 120/235, loss = 0.01198, pos_mask = 0.02460801973938942, neg_mask = 0.6524850130081177
Training @ epoch = 165, 180/235, loss = 0.01142, pos_mask = 0.03172433376312256, neg_mask = 0.64149409532547
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.68

Patience= -97, Time=72.06253, train_epoch_loss = 0.011797558254701026, test_epoch_acc = 90.68
                                                                                                    
Training @ epoch = 166, 0/235, loss = 0.01146, pos_mask = 0.03183561563491821, neg_mask = 0.6068301200866699
Training @ epoch = 166, 60/235, loss = 0.01180, pos_mask = 0.023570936173200607, neg_mask = 0.6296345591545105
Training @ epoch = 166, 120/235, loss = 0.01089, pos_mask = 0.04063228517770767, neg_mask = 0.5954446792602539
Training @ epoch = 166, 180/235, loss = 0.01288, pos_mask = 0.012999022379517555, neg_mask = 0.6646868586540222
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 90.64

Patience= -98, Time=72.49475, train_epoch_loss = 0.0116814496114533, test_epoch_acc = 90.64
                                                                                                    
Training @ epoch = 167, 0/235, loss = 0.01204, pos_mask = 0.025235909968614578, neg_mask = 0.6500648856163025
Training @ epoch = 167, 60/235, loss = 0.01086, pos_mask = 0.031286291778087616, neg_mask = 0.609129786491394
Training @ epoch = 167, 120/235, loss = 0.01197, pos_mask = 0.026246722787618637, neg_mask = 0.6391823291778564
Training @ epoch = 167, 180/235, loss = 0.01117, pos_mask = 0.028779352083802223, neg_mask = 0.614591121673584
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 90.65

Patience= -99, Time=72.92608, train_epoch_loss = 0.011585917704282923, test_epoch_acc = 90.65
                                                                                                    
Training @ epoch = 168, 0/235, loss = 0.01201, pos_mask = 0.02342001348733902, neg_mask = 0.6510100960731506
Training @ epoch = 168, 60/235, loss = 0.01108, pos_mask = 0.026603803038597107, neg_mask = 0.6162067651748657
Training @ epoch = 168, 120/235, loss = 0.01092, pos_mask = 0.03146182745695114, neg_mask = 0.6348006129264832
Training @ epoch = 168, 180/235, loss = 0.01161, pos_mask = 0.01861056685447693, neg_mask = 0.6493182182312012
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 90.57

Patience= -100, Time=73.36054, train_epoch_loss = 0.011490841344633, test_epoch_acc = 90.57
                                                                                                    
Training @ epoch = 169, 0/235, loss = 0.01204, pos_mask = 0.015593092888593674, neg_mask = 0.652230978012085
Training @ epoch = 169, 60/235, loss = 0.01097, pos_mask = 0.0320378914475441, neg_mask = 0.6292628049850464
Training @ epoch = 169, 120/235, loss = 0.01170, pos_mask = 0.022249218076467514, neg_mask = 0.6640622019767761
Training @ epoch = 169, 180/235, loss = 0.01063, pos_mask = 0.02819211594760418, neg_mask = 0.6142215728759766
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.47

Patience= -101, Time=73.79421, train_epoch_loss = 0.011362649143693294, test_epoch_acc = 90.47
                                                                                                    
Training @ epoch = 170, 0/235, loss = 0.01164, pos_mask = 0.020582053810358047, neg_mask = 0.6395787000656128
Training @ epoch = 170, 60/235, loss = 0.01149, pos_mask = 0.019703708589076996, neg_mask = 0.6378983855247498
Training @ epoch = 170, 120/235, loss = 0.01171, pos_mask = 0.016362320631742477, neg_mask = 0.6504195928573608
Training @ epoch = 170, 180/235, loss = 0.01125, pos_mask = 0.029517116025090218, neg_mask = 0.6310219168663025
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 90.9

Patience= -102, Time=74.22968, train_epoch_loss = 0.011277508616764494, test_epoch_acc = 90.9
                                                                                                    
Training @ epoch = 171, 0/235, loss = 0.01171, pos_mask = 0.018506132066249847, neg_mask = 0.6529873609542847
Training @ epoch = 171, 60/235, loss = 0.01091, pos_mask = 0.02334989607334137, neg_mask = 0.6255455017089844
Training @ epoch = 171, 120/235, loss = 0.01135, pos_mask = 0.02297157421708107, neg_mask = 0.6447207927703857
Training @ epoch = 171, 180/235, loss = 0.01147, pos_mask = 0.022954775020480156, neg_mask = 0.6557471752166748
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 90.9

Patience= -103, Time=74.66290, train_epoch_loss = 0.011142597311830267, test_epoch_acc = 90.9
                                                                                                    
Training @ epoch = 172, 0/235, loss = 0.01089, pos_mask = 0.027122827246785164, neg_mask = 0.623442530632019
Training @ epoch = 172, 60/235, loss = 0.01139, pos_mask = 0.023749906569719315, neg_mask = 0.6672202348709106
Training @ epoch = 172, 120/235, loss = 0.01096, pos_mask = 0.02189590409398079, neg_mask = 0.6415754556655884
Training @ epoch = 172, 180/235, loss = 0.01095, pos_mask = 0.021474583074450493, neg_mask = 0.6477431058883667
***********original test set **********
Accuracy: 99.14
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 90.47

Patience= -104, Time=75.09740, train_epoch_loss = 0.011047651801020542, test_epoch_acc = 90.47
                                                                                                    
Training @ epoch = 173, 0/235, loss = 0.01047, pos_mask = 0.03271165117621422, neg_mask = 0.6137136220932007
Training @ epoch = 173, 60/235, loss = 0.01067, pos_mask = 0.029596539214253426, neg_mask = 0.6294857263565063
Training @ epoch = 173, 120/235, loss = 0.01092, pos_mask = 0.018498346209526062, neg_mask = 0.6459349393844604
Training @ epoch = 173, 180/235, loss = 0.01140, pos_mask = 0.01658320240676403, neg_mask = 0.6590245962142944
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 90.67

Patience= -105, Time=75.53579, train_epoch_loss = 0.010948136968022965, test_epoch_acc = 90.67
                                                                                                    
Training @ epoch = 174, 0/235, loss = 0.01060, pos_mask = 0.02632223255932331, neg_mask = 0.6394565105438232
Training @ epoch = 174, 60/235, loss = 0.01086, pos_mask = 0.020688820630311966, neg_mask = 0.646645188331604
Training @ epoch = 174, 120/235, loss = 0.01075, pos_mask = 0.018931910395622253, neg_mask = 0.6511822938919067
Training @ epoch = 174, 180/235, loss = 0.01071, pos_mask = 0.021971549838781357, neg_mask = 0.6296363472938538
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 90.68

Patience= -106, Time=75.97496, train_epoch_loss = 0.010841841381439503, test_epoch_acc = 90.68
                                                                                                    
Training @ epoch = 175, 0/235, loss = 0.01060, pos_mask = 0.0222523994743824, neg_mask = 0.6360145807266235
Training @ epoch = 175, 60/235, loss = 0.01095, pos_mask = 0.01890150085091591, neg_mask = 0.6504000425338745
Training @ epoch = 175, 120/235, loss = 0.01120, pos_mask = 0.018723957240581512, neg_mask = 0.666451632976532
Training @ epoch = 175, 180/235, loss = 0.01070, pos_mask = 0.01696842536330223, neg_mask = 0.649067759513855
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 90.35

Patience= -107, Time=76.41071, train_epoch_loss = 0.010736138920517679, test_epoch_acc = 90.35
                                                                                                    
Training @ epoch = 176, 0/235, loss = 0.01017, pos_mask = 0.02517988160252571, neg_mask = 0.6400146484375
Training @ epoch = 176, 60/235, loss = 0.01052, pos_mask = 0.020694594830274582, neg_mask = 0.6426218748092651
Training @ epoch = 176, 120/235, loss = 0.01065, pos_mask = 0.023244183510541916, neg_mask = 0.648057222366333
Training @ epoch = 176, 180/235, loss = 0.01110, pos_mask = 0.028436480090022087, neg_mask = 0.6369943618774414
***********original test set **********
Accuracy: 98.7
***********sensitivity test set **********
Accuracy: 98.77
***********invariance test set **********
Accuracy: 86.67

Patience= -108, Time=76.84591, train_epoch_loss = 0.012317026822649417, test_epoch_acc = 86.67
                                                                                                    
Training @ epoch = 177, 0/235, loss = 0.01603, pos_mask = 0.0734577551484108, neg_mask = 0.5102072358131409
Training @ epoch = 177, 60/235, loss = 0.02158, pos_mask = 0.10610038042068481, neg_mask = 0.5171611905097961
Training @ epoch = 177, 120/235, loss = 0.01546, pos_mask = 0.06675709784030914, neg_mask = 0.5190085768699646
Training @ epoch = 177, 180/235, loss = 0.01248, pos_mask = 0.04421330988407135, neg_mask = 0.5858174562454224
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 89.73

Patience= -109, Time=77.28249, train_epoch_loss = 0.02474414348760818, test_epoch_acc = 89.73
                                                                                                    
Training @ epoch = 178, 0/235, loss = 0.01205, pos_mask = 0.040954336524009705, neg_mask = 0.5951796770095825
Training @ epoch = 178, 60/235, loss = 0.01185, pos_mask = 0.04558844119310379, neg_mask = 0.577660083770752
Training @ epoch = 178, 120/235, loss = 0.01164, pos_mask = 0.05599362403154373, neg_mask = 0.5394089221954346
Training @ epoch = 178, 180/235, loss = 0.01117, pos_mask = 0.05230919271707535, neg_mask = 0.5712647438049316
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 90.02

Patience= -110, Time=77.71558, train_epoch_loss = 0.011891806113751645, test_epoch_acc = 90.02
                                                                                                    
Training @ epoch = 179, 0/235, loss = 0.01181, pos_mask = 0.0338650718331337, neg_mask = 0.6106535196304321
Training @ epoch = 179, 60/235, loss = 0.01143, pos_mask = 0.046624742448329926, neg_mask = 0.5814292430877686
Training @ epoch = 179, 120/235, loss = 0.01183, pos_mask = 0.029192321002483368, neg_mask = 0.6286813020706177
Training @ epoch = 179, 180/235, loss = 0.01117, pos_mask = 0.03171141818165779, neg_mask = 0.6319129467010498
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 90.37

Patience= -111, Time=78.15052, train_epoch_loss = 0.01129526556568577, test_epoch_acc = 90.37
                                                                                                    
Training @ epoch = 180, 0/235, loss = 0.01086, pos_mask = 0.0381387434899807, neg_mask = 0.5795401930809021
Training @ epoch = 180, 60/235, loss = 0.01106, pos_mask = 0.04319533333182335, neg_mask = 0.615729570388794
Training @ epoch = 180, 120/235, loss = 0.01130, pos_mask = 0.04746527224779129, neg_mask = 0.5665280818939209
Training @ epoch = 180, 180/235, loss = 0.01131, pos_mask = 0.030731217935681343, neg_mask = 0.6301291584968567
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 90.37

Patience= -112, Time=78.58529, train_epoch_loss = 0.011084093561673418, test_epoch_acc = 90.37
                                                                                                    
Training @ epoch = 181, 0/235, loss = 0.01075, pos_mask = 0.026991434395313263, neg_mask = 0.632591962814331
Training @ epoch = 181, 60/235, loss = 0.01115, pos_mask = 0.03268394619226456, neg_mask = 0.6178489923477173
Training @ epoch = 181, 120/235, loss = 0.01129, pos_mask = 0.0286861564964056, neg_mask = 0.6200403571128845
Training @ epoch = 181, 180/235, loss = 0.01120, pos_mask = 0.024875683709979057, neg_mask = 0.6286608576774597
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 90.4

Patience= -113, Time=79.01416, train_epoch_loss = 0.010962592778687781, test_epoch_acc = 90.4
                                                                                                    
Training @ epoch = 182, 0/235, loss = 0.01093, pos_mask = 0.040966302156448364, neg_mask = 0.6117331981658936
Training @ epoch = 182, 60/235, loss = 0.01036, pos_mask = 0.032962121069431305, neg_mask = 0.6185939311981201
Training @ epoch = 182, 120/235, loss = 0.01082, pos_mask = 0.0353083461523056, neg_mask = 0.5989459753036499
Training @ epoch = 182, 180/235, loss = 0.01070, pos_mask = 0.043901436030864716, neg_mask = 0.5847018957138062
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 90.6

Patience= -114, Time=79.44960, train_epoch_loss = 0.01082276850146182, test_epoch_acc = 90.6
                                                                                                    
Training @ epoch = 183, 0/235, loss = 0.01055, pos_mask = 0.04851542040705681, neg_mask = 0.594190776348114
Training @ epoch = 183, 60/235, loss = 0.01065, pos_mask = 0.03592802584171295, neg_mask = 0.6060507893562317
Training @ epoch = 183, 120/235, loss = 0.01072, pos_mask = 0.03587653115391731, neg_mask = 0.6256283521652222
Training @ epoch = 183, 180/235, loss = 0.01108, pos_mask = 0.027433231472969055, neg_mask = 0.6325339078903198
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 90.53

Patience= -115, Time=79.88068, train_epoch_loss = 0.010756036508432093, test_epoch_acc = 90.53
                                                                                                    
Training @ epoch = 184, 0/235, loss = 0.01104, pos_mask = 0.023949678987264633, neg_mask = 0.6393131017684937
Training @ epoch = 184, 60/235, loss = 0.01073, pos_mask = 0.03528228774666786, neg_mask = 0.6136958599090576
Training @ epoch = 184, 120/235, loss = 0.01114, pos_mask = 0.028454558923840523, neg_mask = 0.6196745038032532
Training @ epoch = 184, 180/235, loss = 0.01065, pos_mask = 0.036946557462215424, neg_mask = 0.6182788610458374
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.57

Patience= -116, Time=80.31453, train_epoch_loss = 0.010677379036837437, test_epoch_acc = 90.57
                                                                                                    
Training @ epoch = 185, 0/235, loss = 0.01061, pos_mask = 0.030576469376683235, neg_mask = 0.6173848509788513
Training @ epoch = 185, 60/235, loss = 0.01063, pos_mask = 0.03167260065674782, neg_mask = 0.6123505234718323
Training @ epoch = 185, 120/235, loss = 0.01111, pos_mask = 0.024038799107074738, neg_mask = 0.636892557144165
Training @ epoch = 185, 180/235, loss = 0.01019, pos_mask = 0.036143817007541656, neg_mask = 0.6096352934837341
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 90.72

Patience= -117, Time=80.75063, train_epoch_loss = 0.010582278637175865, test_epoch_acc = 90.72
                                                                                                    
Training @ epoch = 186, 0/235, loss = 0.01091, pos_mask = 0.02771334908902645, neg_mask = 0.639668345451355
Training @ epoch = 186, 60/235, loss = 0.01033, pos_mask = 0.027034539729356766, neg_mask = 0.63620924949646
Training @ epoch = 186, 120/235, loss = 0.01016, pos_mask = 0.03437328711152077, neg_mask = 0.5943149924278259
Training @ epoch = 186, 180/235, loss = 0.01011, pos_mask = 0.04186129570007324, neg_mask = 0.6098729372024536
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 90.57

Patience= -118, Time=81.18428, train_epoch_loss = 0.010521510306825028, test_epoch_acc = 90.57
                                                                                                    
Training @ epoch = 187, 0/235, loss = 0.01026, pos_mask = 0.04288665950298309, neg_mask = 0.6077554821968079
Training @ epoch = 187, 60/235, loss = 0.01057, pos_mask = 0.03151770681142807, neg_mask = 0.6399915218353271
Training @ epoch = 187, 120/235, loss = 0.01055, pos_mask = 0.026134034618735313, neg_mask = 0.6296818256378174
Training @ epoch = 187, 180/235, loss = 0.01051, pos_mask = 0.031127771362662315, neg_mask = 0.6322866678237915
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 90.66

Patience= -119, Time=81.61903, train_epoch_loss = 0.010447950280727224, test_epoch_acc = 90.66
                                                                                                    
Training @ epoch = 188, 0/235, loss = 0.01031, pos_mask = 0.02760377898812294, neg_mask = 0.6410781145095825
Training @ epoch = 188, 60/235, loss = 0.00997, pos_mask = 0.03074982389807701, neg_mask = 0.6260131597518921
Training @ epoch = 188, 120/235, loss = 0.01038, pos_mask = 0.028522085398435593, neg_mask = 0.642460823059082
Training @ epoch = 188, 180/235, loss = 0.01019, pos_mask = 0.028993630781769753, neg_mask = 0.6256767511367798
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 90.64

Patience= -120, Time=82.05425, train_epoch_loss = 0.010386730944539638, test_epoch_acc = 90.64
                                                                                                    
Training @ epoch = 189, 0/235, loss = 0.00995, pos_mask = 0.03502633795142174, neg_mask = 0.5945966243743896
Training @ epoch = 189, 60/235, loss = 0.01010, pos_mask = 0.029840432107448578, neg_mask = 0.5969693660736084
Training @ epoch = 189, 120/235, loss = 0.00991, pos_mask = 0.033946920186281204, neg_mask = 0.6275494694709778
Training @ epoch = 189, 180/235, loss = 0.01005, pos_mask = 0.024365615099668503, neg_mask = 0.6354212760925293
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 90.48

Patience= -121, Time=82.48950, train_epoch_loss = 0.010314458989082499, test_epoch_acc = 90.48
                                                                                                    
Training @ epoch = 190, 0/235, loss = 0.00970, pos_mask = 0.03467630594968796, neg_mask = 0.5963841676712036
Training @ epoch = 190, 60/235, loss = 0.01050, pos_mask = 0.02310025319457054, neg_mask = 0.6380612850189209
Training @ epoch = 190, 120/235, loss = 0.00995, pos_mask = 0.04024968296289444, neg_mask = 0.6098191142082214
Training @ epoch = 190, 180/235, loss = 0.01005, pos_mask = 0.02942221239209175, neg_mask = 0.6275758743286133
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 90.46

Patience= -122, Time=82.92235, train_epoch_loss = 0.010240363111679859, test_epoch_acc = 90.46
                                                                                                    
Training @ epoch = 191, 0/235, loss = 0.00998, pos_mask = 0.03207506984472275, neg_mask = 0.6141423583030701
Training @ epoch = 191, 60/235, loss = 0.01057, pos_mask = 0.020779337733983994, neg_mask = 0.6515378355979919
Training @ epoch = 191, 120/235, loss = 0.01001, pos_mask = 0.024409914389252663, neg_mask = 0.6333703398704529
Training @ epoch = 191, 180/235, loss = 0.01003, pos_mask = 0.029097789898514748, neg_mask = 0.6124057769775391
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 90.49

Patience= -123, Time=83.35742, train_epoch_loss = 0.010182248103491803, test_epoch_acc = 90.49
                                                                                                    
Training @ epoch = 192, 0/235, loss = 0.01023, pos_mask = 0.0215796809643507, neg_mask = 0.6370629668235779
Training @ epoch = 192, 60/235, loss = 0.01072, pos_mask = 0.022563565522432327, neg_mask = 0.6414209604263306
Training @ epoch = 192, 120/235, loss = 0.01001, pos_mask = 0.02689232863485813, neg_mask = 0.6195486187934875
Training @ epoch = 192, 180/235, loss = 0.00988, pos_mask = 0.020145338028669357, neg_mask = 0.6353051662445068
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 90.33

Patience= -124, Time=83.79220, train_epoch_loss = 0.010131741287384895, test_epoch_acc = 90.33
                                                                                                    
Training @ epoch = 193, 0/235, loss = 0.01052, pos_mask = 0.018021579831838608, neg_mask = 0.6569770574569702
Training @ epoch = 193, 60/235, loss = 0.00981, pos_mask = 0.031122781336307526, neg_mask = 0.6402935981750488
Training @ epoch = 193, 120/235, loss = 0.01006, pos_mask = 0.032366931438446045, neg_mask = 0.648937463760376
Training @ epoch = 193, 180/235, loss = 0.01012, pos_mask = 0.028076354414224625, neg_mask = 0.6239521503448486
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 90.39

Patience= -125, Time=84.22655, train_epoch_loss = 0.010062888038760804, test_epoch_acc = 90.39
                                                                                                    
Training @ epoch = 194, 0/235, loss = 0.00936, pos_mask = 0.030666545033454895, neg_mask = 0.6245549321174622
Training @ epoch = 194, 60/235, loss = 0.00952, pos_mask = 0.03157027065753937, neg_mask = 0.6334004402160645
Training @ epoch = 194, 120/235, loss = 0.00959, pos_mask = 0.035216860473155975, neg_mask = 0.6301000118255615
Training @ epoch = 194, 180/235, loss = 0.00969, pos_mask = 0.024908971041440964, neg_mask = 0.6321386098861694
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 90.41

Patience= -126, Time=84.66295, train_epoch_loss = 0.00998819942804093, test_epoch_acc = 90.41
                                                                                                    
Training @ epoch = 195, 0/235, loss = 0.00975, pos_mask = 0.027797916904091835, neg_mask = 0.637618899345398
Training @ epoch = 195, 60/235, loss = 0.00958, pos_mask = 0.03289534151554108, neg_mask = 0.6154013872146606
Training @ epoch = 195, 120/235, loss = 0.01008, pos_mask = 0.020834309980273247, neg_mask = 0.6320734620094299
Training @ epoch = 195, 180/235, loss = 0.01001, pos_mask = 0.02294207736849785, neg_mask = 0.6377270221710205
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 90.35

Patience= -127, Time=85.09443, train_epoch_loss = 0.009929450101991918, test_epoch_acc = 90.35
                                                                                                    
Training @ epoch = 196, 0/235, loss = 0.01029, pos_mask = 0.017438404262065887, neg_mask = 0.6742836236953735
Training @ epoch = 196, 60/235, loss = 0.00985, pos_mask = 0.019041139632463455, neg_mask = 0.6509515047073364
Training @ epoch = 196, 120/235, loss = 0.00958, pos_mask = 0.02438374236226082, neg_mask = 0.6437014937400818
Training @ epoch = 196, 180/235, loss = 0.00943, pos_mask = 0.028955742716789246, neg_mask = 0.6223430037498474
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 90.38

Patience= -128, Time=85.52942, train_epoch_loss = 0.009848069110290802, test_epoch_acc = 90.38
                                                                                                    
Training @ epoch = 197, 0/235, loss = 0.00923, pos_mask = 0.030466346070170403, neg_mask = 0.6213157176971436
Training @ epoch = 197, 60/235, loss = 0.01001, pos_mask = 0.0165642648935318, neg_mask = 0.664503812789917
Training @ epoch = 197, 120/235, loss = 0.00975, pos_mask = 0.0206927303224802, neg_mask = 0.6580883264541626
Training @ epoch = 197, 180/235, loss = 0.00964, pos_mask = 0.02609720639884472, neg_mask = 0.6369355320930481
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 90.41

Patience= -129, Time=85.96052, train_epoch_loss = 0.009780616899754138, test_epoch_acc = 90.41
                                                                                                    
Training @ epoch = 198, 0/235, loss = 0.00929, pos_mask = 0.026639888063073158, neg_mask = 0.6233546733856201
Training @ epoch = 198, 60/235, loss = 0.00978, pos_mask = 0.018554460257291794, neg_mask = 0.6518428921699524
Training @ epoch = 198, 120/235, loss = 0.01013, pos_mask = 0.017586417496204376, neg_mask = 0.6680561900138855
Training @ epoch = 198, 180/235, loss = 0.00990, pos_mask = 0.018331382423639297, neg_mask = 0.654617190361023
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 90.56

Patience= -130, Time=86.39019, train_epoch_loss = 0.009696677838392714, test_epoch_acc = 90.56
                                                                                                    
Training @ epoch = 199, 0/235, loss = 0.00958, pos_mask = 0.024127911776304245, neg_mask = 0.6347520351409912
Training @ epoch = 199, 60/235, loss = 0.00956, pos_mask = 0.024805758148431778, neg_mask = 0.6496777534484863
Training @ epoch = 199, 120/235, loss = 0.00976, pos_mask = 0.017366977408528328, neg_mask = 0.6559022665023804
Training @ epoch = 199, 180/235, loss = 0.00920, pos_mask = 0.029438674449920654, neg_mask = 0.6207845211029053
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 90.52

Patience= -131, Time=86.82378, train_epoch_loss = 0.009630007697071168, test_epoch_acc = 90.52
                                                                                                    
*****Plotting embeddings at iter: 100****
Finished Training in: 86.85705!!
