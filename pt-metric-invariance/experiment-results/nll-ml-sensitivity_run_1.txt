args: Namespace(config='./configs/nll_ml_invariance.ini', device=0, reset=False)
*****Plotting embeddings at iter: 0****
Training @ epoch = 0, 0/235, loss = 2.61034, pos_mask = 0.7950112819671631, neg_mask = 0.2997789680957794
Training @ epoch = 0, 60/235, loss = 2.31724, pos_mask = 0.0796971470117569, neg_mask = 0.01860416680574417
Training @ epoch = 0, 120/235, loss = 2.17950, pos_mask = 0.6556355953216553, neg_mask = 0.03815804049372673
Training @ epoch = 0, 180/235, loss = 1.78974, pos_mask = 0.8681104183197021, neg_mask = 0.04954763501882553
***********original test set **********
Accuracy: 83.81
***********sensitivity test set **********
Accuracy: 78.63
***********invariance test set **********
Accuracy: 49.84

Patience= 50, Time=0.50848, train_epoch_loss = 2.0214132765506174, test_epoch_acc = 49.84
                                                                                                    
Training @ epoch = 1, 0/235, loss = 1.33262, pos_mask = 0.788187563419342, neg_mask = 0.0852850005030632
Training @ epoch = 1, 60/235, loss = 1.03927, pos_mask = 0.6011072397232056, neg_mask = 0.08890511095523834
Training @ epoch = 1, 120/235, loss = 0.78947, pos_mask = 0.5095149278640747, neg_mask = 0.12323270738124847
Training @ epoch = 1, 180/235, loss = 0.79715, pos_mask = 0.599926233291626, neg_mask = 0.10838165879249573
***********original test set **********
Accuracy: 91.87
***********sensitivity test set **********
Accuracy: 90.47
***********invariance test set **********
Accuracy: 68.41

Patience= 50, Time=0.93976, train_epoch_loss = 0.9863673834090537, test_epoch_acc = 68.41
                                                                                                    
Training @ epoch = 2, 0/235, loss = 0.73227, pos_mask = 0.5798608064651489, neg_mask = 0.13171075284481049
Training @ epoch = 2, 60/235, loss = 0.60017, pos_mask = 0.4935237169265747, neg_mask = 0.1324000060558319
Training @ epoch = 2, 120/235, loss = 0.75634, pos_mask = 0.6610803604125977, neg_mask = 0.10502893477678299
Training @ epoch = 2, 180/235, loss = 0.59315, pos_mask = 0.5060378313064575, neg_mask = 0.1338750422000885
***********original test set **********
Accuracy: 94.65
***********sensitivity test set **********
Accuracy: 93.86
***********invariance test set **********
Accuracy: 70.97

Patience= 50, Time=1.37268, train_epoch_loss = 0.6730685890989101, test_epoch_acc = 70.97
                                                                                                    
Training @ epoch = 3, 0/235, loss = 0.79390, pos_mask = 0.8383113145828247, neg_mask = 0.14224058389663696
Training @ epoch = 3, 60/235, loss = 0.62086, pos_mask = 0.585580587387085, neg_mask = 0.16163139045238495
Training @ epoch = 3, 120/235, loss = 0.53651, pos_mask = 0.5243584513664246, neg_mask = 0.14855273067951202
Training @ epoch = 3, 180/235, loss = 0.34505, pos_mask = 0.38671165704727173, neg_mask = 0.2441817820072174
***********original test set **********
Accuracy: 95.62
***********sensitivity test set **********
Accuracy: 94.68
***********invariance test set **********
Accuracy: 68.65

Patience= 49, Time=1.80351, train_epoch_loss = 0.5396802055074813, test_epoch_acc = 68.65
                                                                                                    
Training @ epoch = 4, 0/235, loss = 0.47877, pos_mask = 0.44538265466690063, neg_mask = 0.20617201924324036
Training @ epoch = 4, 60/235, loss = 0.41948, pos_mask = 0.3902014195919037, neg_mask = 0.14228203892707825
Training @ epoch = 4, 120/235, loss = 0.39916, pos_mask = 0.42114540934562683, neg_mask = 0.22805097699165344
Training @ epoch = 4, 180/235, loss = 0.49544, pos_mask = 0.528488039970398, neg_mask = 0.2050083875656128
***********original test set **********
Accuracy: 96.32
***********sensitivity test set **********
Accuracy: 95.67
***********invariance test set **********
Accuracy: 77.1

Patience= 49, Time=2.23587, train_epoch_loss = 0.4604959451137705, test_epoch_acc = 77.1
                                                                                                    
Training @ epoch = 5, 0/235, loss = 0.45895, pos_mask = 0.48942744731903076, neg_mask = 0.18434107303619385
Training @ epoch = 5, 60/235, loss = 0.43385, pos_mask = 0.4581988751888275, neg_mask = 0.17318619787693024
Training @ epoch = 5, 120/235, loss = 0.41662, pos_mask = 0.4083532989025116, neg_mask = 0.16598594188690186
Training @ epoch = 5, 180/235, loss = 0.37990, pos_mask = 0.4419375956058502, neg_mask = 0.2107035219669342
***********original test set **********
Accuracy: 96.85
***********sensitivity test set **********
Accuracy: 96.42
***********invariance test set **********
Accuracy: 77.91

Patience= 49, Time=2.67027, train_epoch_loss = 0.4041610775475806, test_epoch_acc = 77.91
                                                                                                    
Training @ epoch = 6, 0/235, loss = 0.29004, pos_mask = 0.3392603397369385, neg_mask = 0.23578685522079468
Training @ epoch = 6, 60/235, loss = 0.40984, pos_mask = 0.4659796357154846, neg_mask = 0.25308799743652344
Training @ epoch = 6, 120/235, loss = 0.25617, pos_mask = 0.2836889624595642, neg_mask = 0.2282949984073639
Training @ epoch = 6, 180/235, loss = 0.36251, pos_mask = 0.3922818601131439, neg_mask = 0.20886337757110596
***********original test set **********
Accuracy: 97.18
***********sensitivity test set **********
Accuracy: 96.6
***********invariance test set **********
Accuracy: 75.92

Patience= 48, Time=3.10588, train_epoch_loss = 0.35752961857521787, test_epoch_acc = 75.92
                                                                                                    
Training @ epoch = 7, 0/235, loss = 0.31546, pos_mask = 0.3750233054161072, neg_mask = 0.22999748587608337
Training @ epoch = 7, 60/235, loss = 0.27592, pos_mask = 0.34117233753204346, neg_mask = 0.23820871114730835
Training @ epoch = 7, 120/235, loss = 0.31104, pos_mask = 0.37206903100013733, neg_mask = 0.23461531102657318
Training @ epoch = 7, 180/235, loss = 0.27356, pos_mask = 0.352439284324646, neg_mask = 0.23890408873558044
***********original test set **********
Accuracy: 97.43
***********sensitivity test set **********
Accuracy: 97.08
***********invariance test set **********
Accuracy: 75.6

Patience= 47, Time=3.53998, train_epoch_loss = 0.3221927348603594, test_epoch_acc = 75.6
                                                                                                    
Training @ epoch = 8, 0/235, loss = 0.32489, pos_mask = 0.3897193968296051, neg_mask = 0.20297864079475403
Training @ epoch = 8, 60/235, loss = 0.31664, pos_mask = 0.3961367607116699, neg_mask = 0.21442849934101105
Training @ epoch = 8, 120/235, loss = 0.23104, pos_mask = 0.26047375798225403, neg_mask = 0.24021363258361816
Training @ epoch = 8, 180/235, loss = 0.30384, pos_mask = 0.4057794511318207, neg_mask = 0.25328773260116577
***********original test set **********
Accuracy: 97.76
***********sensitivity test set **********
Accuracy: 97.45
***********invariance test set **********
Accuracy: 75.71

Patience= 46, Time=3.97420, train_epoch_loss = 0.29286192718972553, test_epoch_acc = 75.71
                                                                                                    
Training @ epoch = 9, 0/235, loss = 0.27286, pos_mask = 0.35042431950569153, neg_mask = 0.2838584780693054
Training @ epoch = 9, 60/235, loss = 0.36176, pos_mask = 0.42563775181770325, neg_mask = 0.18459635972976685
Training @ epoch = 9, 120/235, loss = 0.18839, pos_mask = 0.2898034155368805, neg_mask = 0.3284863233566284
Training @ epoch = 9, 180/235, loss = 0.19332, pos_mask = 0.28878456354141235, neg_mask = 0.28534555435180664
***********original test set **********
Accuracy: 97.46
***********sensitivity test set **********
Accuracy: 96.98
***********invariance test set **********
Accuracy: 68.83

Patience= 45, Time=4.40570, train_epoch_loss = 0.2677287528489498, test_epoch_acc = 68.83
                                                                                                    
Training @ epoch = 10, 0/235, loss = 0.20105, pos_mask = 0.3022668957710266, neg_mask = 0.28712213039398193
Training @ epoch = 10, 60/235, loss = 0.19367, pos_mask = 0.23967860639095306, neg_mask = 0.2654314637184143
Training @ epoch = 10, 120/235, loss = 0.21582, pos_mask = 0.29113122820854187, neg_mask = 0.307028591632843
Training @ epoch = 10, 180/235, loss = 0.24758, pos_mask = 0.32161325216293335, neg_mask = 0.23353993892669678
***********original test set **********
Accuracy: 97.94
***********sensitivity test set **********
Accuracy: 97.7
***********invariance test set **********
Accuracy: 81.19

Patience= 45, Time=4.83728, train_epoch_loss = 0.24561925000966864, test_epoch_acc = 81.19
                                                                                                    
Training @ epoch = 11, 0/235, loss = 0.28728, pos_mask = 0.3479621410369873, neg_mask = 0.24684564769268036
Training @ epoch = 11, 60/235, loss = 0.19059, pos_mask = 0.2606755495071411, neg_mask = 0.32865962386131287
Training @ epoch = 11, 120/235, loss = 0.18533, pos_mask = 0.2749287188053131, neg_mask = 0.27192187309265137
Training @ epoch = 11, 180/235, loss = 0.20053, pos_mask = 0.2970191240310669, neg_mask = 0.2801027297973633
***********original test set **********
Accuracy: 97.97
***********sensitivity test set **********
Accuracy: 97.81
***********invariance test set **********
Accuracy: 75.33

Patience= 44, Time=5.27136, train_epoch_loss = 0.22563756866023896, test_epoch_acc = 75.33
                                                                                                    
Training @ epoch = 12, 0/235, loss = 0.17128, pos_mask = 0.2612171173095703, neg_mask = 0.30884265899658203
Training @ epoch = 12, 60/235, loss = 0.15186, pos_mask = 0.2689087390899658, neg_mask = 0.307390034198761
Training @ epoch = 12, 120/235, loss = 0.15315, pos_mask = 0.23027360439300537, neg_mask = 0.29767906665802
Training @ epoch = 12, 180/235, loss = 0.13881, pos_mask = 0.23306682705879211, neg_mask = 0.30636027455329895
***********original test set **********
Accuracy: 98.01
***********sensitivity test set **********
Accuracy: 97.89
***********invariance test set **********
Accuracy: 76.49

Patience= 43, Time=5.70270, train_epoch_loss = 0.20693468736841322, test_epoch_acc = 76.49
                                                                                                    
Training @ epoch = 13, 0/235, loss = 0.22071, pos_mask = 0.2970305383205414, neg_mask = 0.2671106457710266
Training @ epoch = 13, 60/235, loss = 0.38148, pos_mask = 0.596210777759552, neg_mask = 0.25814729928970337
Training @ epoch = 13, 120/235, loss = 0.21085, pos_mask = 0.2659473121166229, neg_mask = 0.2524206042289734
Training @ epoch = 13, 180/235, loss = 0.26288, pos_mask = 0.414839506149292, neg_mask = 0.28206902742385864
***********original test set **********
Accuracy: 98.45
***********sensitivity test set **********
Accuracy: 98.1
***********invariance test set **********
Accuracy: 78.59

Patience= 42, Time=6.13575, train_epoch_loss = 0.19390037078806693, test_epoch_acc = 78.59
                                                                                                    
Training @ epoch = 14, 0/235, loss = 0.15073, pos_mask = 0.21539494395256042, neg_mask = 0.2929646372795105
Training @ epoch = 14, 60/235, loss = 0.22130, pos_mask = 0.3232485055923462, neg_mask = 0.2942403256893158
Training @ epoch = 14, 120/235, loss = 0.18548, pos_mask = 0.3154725432395935, neg_mask = 0.3058739900588989
Training @ epoch = 14, 180/235, loss = 0.14160, pos_mask = 0.2710060179233551, neg_mask = 0.31581372022628784
***********original test set **********
Accuracy: 98.51
***********sensitivity test set **********
Accuracy: 98.36
***********invariance test set **********
Accuracy: 79.71

Patience= 41, Time=6.56928, train_epoch_loss = 0.1771570824562235, test_epoch_acc = 79.71
                                                                                                    
Training @ epoch = 15, 0/235, loss = 0.16211, pos_mask = 0.25775277614593506, neg_mask = 0.33673956990242004
Training @ epoch = 15, 60/235, loss = 0.18431, pos_mask = 0.26433831453323364, neg_mask = 0.30821692943573
Training @ epoch = 15, 120/235, loss = 0.12922, pos_mask = 0.2260381132364273, neg_mask = 0.30288344621658325
Training @ epoch = 15, 180/235, loss = 0.15440, pos_mask = 0.23534417152404785, neg_mask = 0.3454922139644623
***********original test set **********
Accuracy: 98.57
***********sensitivity test set **********
Accuracy: 98.34
***********invariance test set **********
Accuracy: 75.29

Patience= 40, Time=7.00273, train_epoch_loss = 0.16623359832991946, test_epoch_acc = 75.29
                                                                                                    
Training @ epoch = 16, 0/235, loss = 0.12198, pos_mask = 0.2058674395084381, neg_mask = 0.31492918729782104
Training @ epoch = 16, 60/235, loss = 0.12182, pos_mask = 0.20949286222457886, neg_mask = 0.3125385046005249
Training @ epoch = 16, 120/235, loss = 0.14791, pos_mask = 0.2651124894618988, neg_mask = 0.3274833559989929
Training @ epoch = 16, 180/235, loss = 0.14178, pos_mask = 0.22809907793998718, neg_mask = 0.33355712890625
***********original test set **********
Accuracy: 98.51
***********sensitivity test set **********
Accuracy: 98.24
***********invariance test set **********
Accuracy: 78.16

Patience= 39, Time=7.43496, train_epoch_loss = 0.1521342692540047, test_epoch_acc = 78.16
                                                                                                    
Training @ epoch = 17, 0/235, loss = 0.15829, pos_mask = 0.24799801409244537, neg_mask = 0.291341632604599
Training @ epoch = 17, 60/235, loss = 0.10876, pos_mask = 0.17496249079704285, neg_mask = 0.3653174936771393
Training @ epoch = 17, 120/235, loss = 0.14512, pos_mask = 0.2924221158027649, neg_mask = 0.35737377405166626
Training @ epoch = 17, 180/235, loss = 0.17344, pos_mask = 0.27064597606658936, neg_mask = 0.3037913739681244
***********original test set **********
Accuracy: 98.71
***********sensitivity test set **********
Accuracy: 98.45
***********invariance test set **********
Accuracy: 77.32

Patience= 38, Time=7.86951, train_epoch_loss = 0.14226895789516733, test_epoch_acc = 77.32
                                                                                                    
Training @ epoch = 18, 0/235, loss = 0.09774, pos_mask = 0.16436778008937836, neg_mask = 0.3657962679862976
Training @ epoch = 18, 60/235, loss = 0.23890, pos_mask = 0.3446962833404541, neg_mask = 0.2598855495452881
Training @ epoch = 18, 120/235, loss = 0.12062, pos_mask = 0.2298872321844101, neg_mask = 0.31707820296287537
Training @ epoch = 18, 180/235, loss = 0.10218, pos_mask = 0.21309500932693481, neg_mask = 0.3804892599582672
***********original test set **********
Accuracy: 98.8
***********sensitivity test set **********
Accuracy: 98.57
***********invariance test set **********
Accuracy: 84.0

Patience= 38, Time=8.30240, train_epoch_loss = 0.1346246284056217, test_epoch_acc = 84.0
                                                                                                    
Training @ epoch = 19, 0/235, loss = 0.13630, pos_mask = 0.19156299531459808, neg_mask = 0.33498895168304443
Training @ epoch = 19, 60/235, loss = 0.19174, pos_mask = 0.3373545706272125, neg_mask = 0.28392332792282104
Training @ epoch = 19, 120/235, loss = 0.09172, pos_mask = 0.19074805080890656, neg_mask = 0.3696492314338684
Training @ epoch = 19, 180/235, loss = 0.12884, pos_mask = 0.21455952525138855, neg_mask = 0.33321577310562134
***********original test set **********
Accuracy: 98.87
***********sensitivity test set **********
Accuracy: 98.6
***********invariance test set **********
Accuracy: 78.36

Patience= 37, Time=8.73256, train_epoch_loss = 0.12663556613186572, test_epoch_acc = 78.36
                                                                                                    
Training @ epoch = 20, 0/235, loss = 0.11787, pos_mask = 0.19225282967090607, neg_mask = 0.34665241837501526
Training @ epoch = 20, 60/235, loss = 0.10708, pos_mask = 0.21476322412490845, neg_mask = 0.3863608241081238
Training @ epoch = 20, 120/235, loss = 0.18357, pos_mask = 0.3113935887813568, neg_mask = 0.29214543104171753
Training @ epoch = 20, 180/235, loss = 0.12237, pos_mask = 0.22415661811828613, neg_mask = 0.33350974321365356
***********original test set **********
Accuracy: 98.87
***********sensitivity test set **********
Accuracy: 98.63
***********invariance test set **********
Accuracy: 81.73

Patience= 36, Time=9.16424, train_epoch_loss = 0.11585553890847146, test_epoch_acc = 81.73
                                                                                                    
Training @ epoch = 21, 0/235, loss = 0.11638, pos_mask = 0.2323068380355835, neg_mask = 0.30622369050979614
Training @ epoch = 21, 60/235, loss = 0.09030, pos_mask = 0.17592096328735352, neg_mask = 0.35589152574539185
Training @ epoch = 21, 120/235, loss = 0.09251, pos_mask = 0.17007222771644592, neg_mask = 0.3949994444847107
Training @ epoch = 21, 180/235, loss = 0.10883, pos_mask = 0.18798698484897614, neg_mask = 0.36403241753578186
***********original test set **********
Accuracy: 98.82
***********sensitivity test set **********
Accuracy: 98.61
***********invariance test set **********
Accuracy: 84.91

Patience= 36, Time=9.59961, train_epoch_loss = 0.10985448049738052, test_epoch_acc = 84.91
                                                                                                    
Training @ epoch = 22, 0/235, loss = 0.22820, pos_mask = 0.3439650535583496, neg_mask = 0.2755771279335022
Training @ epoch = 22, 60/235, loss = 0.11624, pos_mask = 0.18713060021400452, neg_mask = 0.38701391220092773
Training @ epoch = 22, 120/235, loss = 0.10057, pos_mask = 0.19799870252609253, neg_mask = 0.3217823803424835
Training @ epoch = 22, 180/235, loss = 0.12890, pos_mask = 0.27087557315826416, neg_mask = 0.3380378484725952
***********original test set **********
Accuracy: 98.97
***********sensitivity test set **********
Accuracy: 98.67
***********invariance test set **********
Accuracy: 80.94

Patience= 35, Time=10.03322, train_epoch_loss = 0.10339835587334126, test_epoch_acc = 80.94
                                                                                                    
Training @ epoch = 23, 0/235, loss = 0.07137, pos_mask = 0.14767009019851685, neg_mask = 0.38900458812713623
Training @ epoch = 23, 60/235, loss = 0.07160, pos_mask = 0.14753518998622894, neg_mask = 0.4171282947063446
Training @ epoch = 23, 120/235, loss = 0.09394, pos_mask = 0.17716428637504578, neg_mask = 0.3990936279296875
Training @ epoch = 23, 180/235, loss = 0.19323, pos_mask = 0.288944274187088, neg_mask = 0.3343474268913269
***********original test set **********
Accuracy: 99.01
***********sensitivity test set **********
Accuracy: 98.75
***********invariance test set **********
Accuracy: 76.87

Patience= 34, Time=10.46235, train_epoch_loss = 0.0971964420631845, test_epoch_acc = 76.87
                                                                                                    
Training @ epoch = 24, 0/235, loss = 0.14199, pos_mask = 0.2462928146123886, neg_mask = 0.3195491433143616
Training @ epoch = 24, 60/235, loss = 0.08130, pos_mask = 0.16231128573417664, neg_mask = 0.4028991758823395
Training @ epoch = 24, 120/235, loss = 0.06980, pos_mask = 0.15043491125106812, neg_mask = 0.40916815400123596
Training @ epoch = 24, 180/235, loss = 0.08807, pos_mask = 0.21416154503822327, neg_mask = 0.3766307830810547
***********original test set **********
Accuracy: 98.99
***********sensitivity test set **********
Accuracy: 98.67
***********invariance test set **********
Accuracy: 79.43

Patience= 33, Time=10.89613, train_epoch_loss = 0.0921457678396651, test_epoch_acc = 79.43
                                                                                                    
Training @ epoch = 25, 0/235, loss = 0.07870, pos_mask = 0.19001176953315735, neg_mask = 0.4032365679740906
Training @ epoch = 25, 60/235, loss = 0.07303, pos_mask = 0.1775819957256317, neg_mask = 0.40734320878982544
Training @ epoch = 25, 120/235, loss = 0.12043, pos_mask = 0.2273474931716919, neg_mask = 0.3133382499217987
Training @ epoch = 25, 180/235, loss = 0.06433, pos_mask = 0.13437804579734802, neg_mask = 0.3920113742351532
***********original test set **********
Accuracy: 98.98
***********sensitivity test set **********
Accuracy: 98.72
***********invariance test set **********
Accuracy: 78.77

Patience= 32, Time=11.33086, train_epoch_loss = 0.08543539969845021, test_epoch_acc = 78.77
                                                                                                    
Training @ epoch = 26, 0/235, loss = 0.06848, pos_mask = 0.09360421448945999, neg_mask = 0.4319893419742584
Training @ epoch = 26, 60/235, loss = 0.09104, pos_mask = 0.1422978937625885, neg_mask = 0.3748686909675598
Training @ epoch = 26, 120/235, loss = 0.13067, pos_mask = 0.21738910675048828, neg_mask = 0.3210773169994354
Training @ epoch = 26, 180/235, loss = 0.06324, pos_mask = 0.11418579518795013, neg_mask = 0.4153691530227661
***********original test set **********
Accuracy: 98.87
***********sensitivity test set **********
Accuracy: 98.71
***********invariance test set **********
Accuracy: 82.8

Patience= 31, Time=11.76093, train_epoch_loss = 0.08139247412377215, test_epoch_acc = 82.8
                                                                                                    
Training @ epoch = 27, 0/235, loss = 0.07945, pos_mask = 0.15362688899040222, neg_mask = 0.39478057622909546
Training @ epoch = 27, 60/235, loss = 0.09326, pos_mask = 0.2204284965991974, neg_mask = 0.3608592450618744
Training @ epoch = 27, 120/235, loss = 0.07396, pos_mask = 0.15647095441818237, neg_mask = 0.35742324590682983
Training @ epoch = 27, 180/235, loss = 0.06139, pos_mask = 0.12096668779850006, neg_mask = 0.43543103337287903
***********original test set **********
Accuracy: 99.05
***********sensitivity test set **********
Accuracy: 98.79
***********invariance test set **********
Accuracy: 81.45

Patience= 30, Time=12.19168, train_epoch_loss = 0.08268789162344121, test_epoch_acc = 81.45
                                                                                                    
Training @ epoch = 28, 0/235, loss = 0.07605, pos_mask = 0.18844303488731384, neg_mask = 0.3949543833732605
Training @ epoch = 28, 60/235, loss = 0.06391, pos_mask = 0.14490719139575958, neg_mask = 0.4158307611942291
Training @ epoch = 28, 120/235, loss = 0.06279, pos_mask = 0.1349896639585495, neg_mask = 0.4233499765396118
Training @ epoch = 28, 180/235, loss = 0.08538, pos_mask = 0.17460551857948303, neg_mask = 0.40289461612701416
***********original test set **********
Accuracy: 99.03
***********sensitivity test set **********
Accuracy: 98.75
***********invariance test set **********
Accuracy: 80.05

Patience= 29, Time=12.62658, train_epoch_loss = 0.07507625651803422, test_epoch_acc = 80.05
                                                                                                    
Training @ epoch = 29, 0/235, loss = 0.05678, pos_mask = 0.11136960983276367, neg_mask = 0.4381992220878601
Training @ epoch = 29, 60/235, loss = 0.07163, pos_mask = 0.15263286232948303, neg_mask = 0.35428762435913086
Training @ epoch = 29, 120/235, loss = 0.07644, pos_mask = 0.18470853567123413, neg_mask = 0.3915955424308777
Training @ epoch = 29, 180/235, loss = 0.07672, pos_mask = 0.1440458595752716, neg_mask = 0.41566744446754456
***********original test set **********
Accuracy: 99.03
***********sensitivity test set **********
Accuracy: 98.85
***********invariance test set **********
Accuracy: 81.36

Patience= 28, Time=13.05805, train_epoch_loss = 0.07036593933688834, test_epoch_acc = 81.36
                                                                                                    
Training @ epoch = 30, 0/235, loss = 0.06033, pos_mask = 0.11531685292720795, neg_mask = 0.43392813205718994
Training @ epoch = 30, 60/235, loss = 0.06385, pos_mask = 0.14812515676021576, neg_mask = 0.4188346266746521
Training @ epoch = 30, 120/235, loss = 0.05503, pos_mask = 0.10836680233478546, neg_mask = 0.44487786293029785
Training @ epoch = 30, 180/235, loss = 0.05558, pos_mask = 0.09383487701416016, neg_mask = 0.46823474764823914
***********original test set **********
Accuracy: 99.1
***********sensitivity test set **********
Accuracy: 98.89
***********invariance test set **********
Accuracy: 82.98

Patience= 27, Time=13.49168, train_epoch_loss = 0.06704841704761728, test_epoch_acc = 82.98
                                                                                                    
Training @ epoch = 31, 0/235, loss = 0.05284, pos_mask = 0.08709854632616043, neg_mask = 0.4850795269012451
Training @ epoch = 31, 60/235, loss = 0.09962, pos_mask = 0.22292624413967133, neg_mask = 0.3707875907421112
Training @ epoch = 31, 120/235, loss = 0.05687, pos_mask = 0.194905623793602, neg_mask = 0.4058127701282501
Training @ epoch = 31, 180/235, loss = 0.06490, pos_mask = 0.11662527918815613, neg_mask = 0.41745394468307495
***********original test set **********
Accuracy: 99.1
***********sensitivity test set **********
Accuracy: 98.82
***********invariance test set **********
Accuracy: 79.36

Patience= 26, Time=13.92569, train_epoch_loss = 0.06544845403825983, test_epoch_acc = 79.36
                                                                                                    
Training @ epoch = 32, 0/235, loss = 0.05053, pos_mask = 0.12202140688896179, neg_mask = 0.41906028985977173
Training @ epoch = 32, 60/235, loss = 0.05223, pos_mask = 0.1185249537229538, neg_mask = 0.45974433422088623
Training @ epoch = 32, 120/235, loss = 0.14124, pos_mask = 0.2670082747936249, neg_mask = 0.3417900502681732
Training @ epoch = 32, 180/235, loss = 0.05391, pos_mask = 0.12479033321142197, neg_mask = 0.46939828991889954
***********original test set **********
Accuracy: 99.02
***********sensitivity test set **********
Accuracy: 98.8
***********invariance test set **********
Accuracy: 81.16

Patience= 25, Time=14.35490, train_epoch_loss = 0.06264286321845461, test_epoch_acc = 81.16
                                                                                                    
Training @ epoch = 33, 0/235, loss = 0.05031, pos_mask = 0.11760376393795013, neg_mask = 0.42695343494415283
Training @ epoch = 33, 60/235, loss = 0.05369, pos_mask = 0.11468768119812012, neg_mask = 0.43850094079971313
Training @ epoch = 33, 120/235, loss = 0.05268, pos_mask = 0.11625111103057861, neg_mask = 0.4239039123058319
Training @ epoch = 33, 180/235, loss = 0.05804, pos_mask = 0.10980184376239777, neg_mask = 0.4617253839969635
***********original test set **********
Accuracy: 99.0
***********sensitivity test set **********
Accuracy: 98.72
***********invariance test set **********
Accuracy: 82.58

Patience= 24, Time=14.78383, train_epoch_loss = 0.06002102001233304, test_epoch_acc = 82.58
                                                                                                    
Training @ epoch = 34, 0/235, loss = 0.05342, pos_mask = 0.11936342716217041, neg_mask = 0.4486767053604126
Training @ epoch = 34, 60/235, loss = 0.05555, pos_mask = 0.1209922805428505, neg_mask = 0.41957372426986694
Training @ epoch = 34, 120/235, loss = 0.04893, pos_mask = 0.11428225040435791, neg_mask = 0.42600953578948975
Training @ epoch = 34, 180/235, loss = 0.05322, pos_mask = 0.15495774149894714, neg_mask = 0.40046119689941406
***********original test set **********
Accuracy: 99.08
***********sensitivity test set **********
Accuracy: 98.8
***********invariance test set **********
Accuracy: 77.8

Patience= 23, Time=15.21807, train_epoch_loss = 0.05755064993145618, test_epoch_acc = 77.8
                                                                                                    
Training @ epoch = 35, 0/235, loss = 0.05952, pos_mask = 0.16824889183044434, neg_mask = 0.42490094900131226
Training @ epoch = 35, 60/235, loss = 0.05392, pos_mask = 0.11719969660043716, neg_mask = 0.4473484754562378
Training @ epoch = 35, 120/235, loss = 0.05036, pos_mask = 0.12149529904127121, neg_mask = 0.4085155129432678
Training @ epoch = 35, 180/235, loss = 0.04977, pos_mask = 0.12372829020023346, neg_mask = 0.45759111642837524
***********original test set **********
Accuracy: 98.97
***********sensitivity test set **********
Accuracy: 98.74
***********invariance test set **********
Accuracy: 78.09

Patience= 22, Time=15.64807, train_epoch_loss = 0.054458747756607986, test_epoch_acc = 78.09
                                                                                                    
Training @ epoch = 36, 0/235, loss = 0.05511, pos_mask = 0.1263727843761444, neg_mask = 0.3913545608520508
Training @ epoch = 36, 60/235, loss = 0.05403, pos_mask = 0.11372160911560059, neg_mask = 0.4532584547996521
Training @ epoch = 36, 120/235, loss = 0.05755, pos_mask = 0.13501423597335815, neg_mask = 0.38535815477371216
Training @ epoch = 36, 180/235, loss = 0.05097, pos_mask = 0.12234555929899216, neg_mask = 0.46124348044395447
***********original test set **********
Accuracy: 98.96
***********sensitivity test set **********
Accuracy: 98.91
***********invariance test set **********
Accuracy: 83.03

Patience= 21, Time=16.08222, train_epoch_loss = 0.055782181753757154, test_epoch_acc = 83.03
                                                                                                    
Training @ epoch = 37, 0/235, loss = 0.05328, pos_mask = 0.13060294091701508, neg_mask = 0.44603633880615234
Training @ epoch = 37, 60/235, loss = 0.05177, pos_mask = 0.10542715340852737, neg_mask = 0.3990359902381897
Training @ epoch = 37, 120/235, loss = 0.04855, pos_mask = 0.10520976781845093, neg_mask = 0.4277913570404053
Training @ epoch = 37, 180/235, loss = 0.04946, pos_mask = 0.121026411652565, neg_mask = 0.46591559052467346
***********original test set **********
Accuracy: 98.96
***********sensitivity test set **********
Accuracy: 98.74
***********invariance test set **********
Accuracy: 80.69

Patience= 20, Time=16.51528, train_epoch_loss = 0.05127015641712128, test_epoch_acc = 80.69
                                                                                                    
Training @ epoch = 38, 0/235, loss = 0.04451, pos_mask = 0.09440823644399643, neg_mask = 0.4443412721157074
Training @ epoch = 38, 60/235, loss = 0.04992, pos_mask = 0.15232722461223602, neg_mask = 0.4529426693916321
Training @ epoch = 38, 120/235, loss = 0.04511, pos_mask = 0.09393446147441864, neg_mask = 0.5060140490531921
Training @ epoch = 38, 180/235, loss = 0.05058, pos_mask = 0.11657467484474182, neg_mask = 0.4426281750202179
***********original test set **********
Accuracy: 99.09
***********sensitivity test set **********
Accuracy: 98.93
***********invariance test set **********
Accuracy: 85.04

Patience= 20, Time=16.94529, train_epoch_loss = 0.052196749141241644, test_epoch_acc = 85.04
                                                                                                    
Training @ epoch = 39, 0/235, loss = 0.04785, pos_mask = 0.11743197590112686, neg_mask = 0.45757943391799927
Training @ epoch = 39, 60/235, loss = 0.04769, pos_mask = 0.09238173067569733, neg_mask = 0.4976835548877716
Training @ epoch = 39, 120/235, loss = 0.05788, pos_mask = 0.1447421908378601, neg_mask = 0.4468146562576294
Training @ epoch = 39, 180/235, loss = 0.04786, pos_mask = 0.10274644196033478, neg_mask = 0.4778226315975189
***********original test set **********
Accuracy: 98.94
***********sensitivity test set **********
Accuracy: 98.78
***********invariance test set **********
Accuracy: 78.4

Patience= 19, Time=17.37708, train_epoch_loss = 0.04830222608561211, test_epoch_acc = 78.4
                                                                                                    
Training @ epoch = 40, 0/235, loss = 0.04639, pos_mask = 0.103248730301857, neg_mask = 0.46203136444091797
Training @ epoch = 40, 60/235, loss = 0.04343, pos_mask = 0.09349459409713745, neg_mask = 0.47137969732284546
Training @ epoch = 40, 120/235, loss = 0.04565, pos_mask = 0.1189742237329483, neg_mask = 0.45037615299224854
Training @ epoch = 40, 180/235, loss = 0.04327, pos_mask = 0.11361974477767944, neg_mask = 0.4844864308834076
***********original test set **********
Accuracy: 99.13
***********sensitivity test set **********
Accuracy: 98.94
***********invariance test set **********
Accuracy: 79.74

Patience= 18, Time=17.81148, train_epoch_loss = 0.04648757871795208, test_epoch_acc = 79.74
                                                                                                    
Training @ epoch = 41, 0/235, loss = 0.04450, pos_mask = 0.09367910772562027, neg_mask = 0.4758757948875427
Training @ epoch = 41, 60/235, loss = 0.04294, pos_mask = 0.09879882633686066, neg_mask = 0.4722822606563568
Training @ epoch = 41, 120/235, loss = 0.06274, pos_mask = 0.15491555631160736, neg_mask = 0.41644808650016785
Training @ epoch = 41, 180/235, loss = 0.04230, pos_mask = 0.10212904214859009, neg_mask = 0.48851463198661804
***********original test set **********
Accuracy: 99.09
***********sensitivity test set **********
Accuracy: 98.92
***********invariance test set **********
Accuracy: 82.1

Patience= 17, Time=18.24309, train_epoch_loss = 0.04556590813271543, test_epoch_acc = 82.1
                                                                                                    
Training @ epoch = 42, 0/235, loss = 0.04098, pos_mask = 0.09917637705802917, neg_mask = 0.4738684892654419
Training @ epoch = 42, 60/235, loss = 0.04143, pos_mask = 0.08400864899158478, neg_mask = 0.530838131904602
Training @ epoch = 42, 120/235, loss = 0.04573, pos_mask = 0.10524224489927292, neg_mask = 0.4808899462223053
Training @ epoch = 42, 180/235, loss = 0.04175, pos_mask = 0.10489760339260101, neg_mask = 0.49742406606674194
***********original test set **********
Accuracy: 99.02
***********sensitivity test set **********
Accuracy: 98.95
***********invariance test set **********
Accuracy: 81.16

Patience= 16, Time=18.67763, train_epoch_loss = 0.0438870019576651, test_epoch_acc = 81.16
                                                                                                    
Training @ epoch = 43, 0/235, loss = 0.03896, pos_mask = 0.08244097232818604, neg_mask = 0.48957327008247375
Training @ epoch = 43, 60/235, loss = 0.04198, pos_mask = 0.07733431458473206, neg_mask = 0.49349477887153625
Training @ epoch = 43, 120/235, loss = 0.04272, pos_mask = 0.12104040384292603, neg_mask = 0.4583642780780792
Training @ epoch = 43, 180/235, loss = 0.04100, pos_mask = 0.08288714289665222, neg_mask = 0.494502454996109
***********original test set **********
Accuracy: 99.08
***********sensitivity test set **********
Accuracy: 98.87
***********invariance test set **********
Accuracy: 79.62

Patience= 15, Time=19.11057, train_epoch_loss = 0.042434221157368196, test_epoch_acc = 79.62
                                                                                                    
Training @ epoch = 44, 0/235, loss = 0.04259, pos_mask = 0.09579358994960785, neg_mask = 0.48406216502189636
Training @ epoch = 44, 60/235, loss = 0.04058, pos_mask = 0.08382910490036011, neg_mask = 0.4911007881164551
Training @ epoch = 44, 120/235, loss = 0.04017, pos_mask = 0.07355372607707977, neg_mask = 0.47365787625312805
Training @ epoch = 44, 180/235, loss = 0.03905, pos_mask = 0.09586133062839508, neg_mask = 0.49236559867858887
***********original test set **********
Accuracy: 98.95
***********sensitivity test set **********
Accuracy: 98.59
***********invariance test set **********
Accuracy: 81.86

Patience= 14, Time=19.54335, train_epoch_loss = 0.04140144542176673, test_epoch_acc = 81.86
                                                                                                    
Training @ epoch = 45, 0/235, loss = 0.05392, pos_mask = 0.12410987913608551, neg_mask = 0.46335622668266296
Training @ epoch = 45, 60/235, loss = 0.06112, pos_mask = 0.16316676139831543, neg_mask = 0.42905375361442566
Training @ epoch = 45, 120/235, loss = 0.05581, pos_mask = 0.11396702378988266, neg_mask = 0.4605174660682678
Training @ epoch = 45, 180/235, loss = 0.04578, pos_mask = 0.12932735681533813, neg_mask = 0.5049676895141602
***********original test set **********
Accuracy: 98.89
***********sensitivity test set **********
Accuracy: 98.7
***********invariance test set **********
Accuracy: 77.6

Patience= 13, Time=19.98091, train_epoch_loss = 0.049773719684874755, test_epoch_acc = 77.6
                                                                                                    
Training @ epoch = 46, 0/235, loss = 0.04267, pos_mask = 0.08946139365434647, neg_mask = 0.5087127089500427
Training @ epoch = 46, 60/235, loss = 0.03841, pos_mask = 0.06956253200769424, neg_mask = 0.5040574073791504
Training @ epoch = 46, 120/235, loss = 0.04155, pos_mask = 0.10056127607822418, neg_mask = 0.49293339252471924
Training @ epoch = 46, 180/235, loss = 0.03687, pos_mask = 0.08558376878499985, neg_mask = 0.502027153968811
***********original test set **********
Accuracy: 99.08
***********sensitivity test set **********
Accuracy: 98.91
***********invariance test set **********
Accuracy: 80.54

Patience= 12, Time=20.41269, train_epoch_loss = 0.04038754818921394, test_epoch_acc = 80.54
                                                                                                    
Training @ epoch = 47, 0/235, loss = 0.03716, pos_mask = 0.07802444696426392, neg_mask = 0.5364537835121155
Training @ epoch = 47, 60/235, loss = 0.03615, pos_mask = 0.08617406338453293, neg_mask = 0.5192738771438599
Training @ epoch = 47, 120/235, loss = 0.03752, pos_mask = 0.06286807358264923, neg_mask = 0.503454864025116
Training @ epoch = 47, 180/235, loss = 0.03904, pos_mask = 0.08231863379478455, neg_mask = 0.4897996783256531
***********original test set **********
Accuracy: 99.07
***********sensitivity test set **********
Accuracy: 98.92
***********invariance test set **********
Accuracy: 81.19

Patience= 11, Time=20.83860, train_epoch_loss = 0.0382404698811947, test_epoch_acc = 81.19
                                                                                                    
Training @ epoch = 48, 0/235, loss = 0.03609, pos_mask = 0.09010744094848633, neg_mask = 0.4929143786430359
Training @ epoch = 48, 60/235, loss = 0.03803, pos_mask = 0.08306130766868591, neg_mask = 0.4921729266643524
Training @ epoch = 48, 120/235, loss = 0.03728, pos_mask = 0.12145227938890457, neg_mask = 0.457078754901886
Training @ epoch = 48, 180/235, loss = 0.03689, pos_mask = 0.09652592241764069, neg_mask = 0.5023075938224792
***********original test set **********
Accuracy: 99.1
***********sensitivity test set **********
Accuracy: 98.93
***********invariance test set **********
Accuracy: 82.49

Patience= 10, Time=21.27287, train_epoch_loss = 0.03712816588739131, test_epoch_acc = 82.49
                                                                                                    
Training @ epoch = 49, 0/235, loss = 0.03546, pos_mask = 0.06804069876670837, neg_mask = 0.5178119540214539
Training @ epoch = 49, 60/235, loss = 0.03850, pos_mask = 0.08998288959264755, neg_mask = 0.4970167279243469
Training @ epoch = 49, 120/235, loss = 0.03551, pos_mask = 0.07468698918819427, neg_mask = 0.5146634578704834
Training @ epoch = 49, 180/235, loss = 0.03719, pos_mask = 0.08229909092187881, neg_mask = 0.5251877903938293
***********original test set **********
Accuracy: 99.09
***********sensitivity test set **********
Accuracy: 98.93
***********invariance test set **********
Accuracy: 81.66

Patience= 9, Time=21.70777, train_epoch_loss = 0.036313810611658906, test_epoch_acc = 81.66
                                                                                                    
Training @ epoch = 50, 0/235, loss = 0.03760, pos_mask = 0.08683552592992783, neg_mask = 0.5272458791732788
Training @ epoch = 50, 60/235, loss = 0.04204, pos_mask = 0.13521039485931396, neg_mask = 0.4652790427207947
Training @ epoch = 50, 120/235, loss = 0.03422, pos_mask = 0.07224071025848389, neg_mask = 0.5204838514328003
Training @ epoch = 50, 180/235, loss = 0.03604, pos_mask = 0.11050619184970856, neg_mask = 0.46632319688796997
***********original test set **********
Accuracy: 99.06
***********sensitivity test set **********
Accuracy: 98.91
***********invariance test set **********
Accuracy: 80.7

Patience= 8, Time=22.14107, train_epoch_loss = 0.03579692384029957, test_epoch_acc = 80.7
                                                                                                    
Training @ epoch = 51, 0/235, loss = 0.03486, pos_mask = 0.055137403309345245, neg_mask = 0.5335631370544434
Training @ epoch = 51, 60/235, loss = 0.03295, pos_mask = 0.08374282717704773, neg_mask = 0.5084130764007568
Training @ epoch = 51, 120/235, loss = 0.03705, pos_mask = 0.09827475249767303, neg_mask = 0.4618995189666748
Training @ epoch = 51, 180/235, loss = 0.03486, pos_mask = 0.10801826417446136, neg_mask = 0.4673640727996826
***********original test set **********
Accuracy: 99.05
***********sensitivity test set **********
Accuracy: 98.9
***********invariance test set **********
Accuracy: 80.37

Patience= 7, Time=22.57009, train_epoch_loss = 0.03497391885265391, test_epoch_acc = 80.37
                                                                                                    
Training @ epoch = 52, 0/235, loss = 0.03523, pos_mask = 0.08474797010421753, neg_mask = 0.4993847906589508
Training @ epoch = 52, 60/235, loss = 0.03385, pos_mask = 0.06511590629816055, neg_mask = 0.5380793213844299
Training @ epoch = 52, 120/235, loss = 0.03313, pos_mask = 0.08429435640573502, neg_mask = 0.5148261189460754
Training @ epoch = 52, 180/235, loss = 0.03434, pos_mask = 0.081411212682724, neg_mask = 0.4901934862136841
***********original test set **********
Accuracy: 99.09
***********sensitivity test set **********
Accuracy: 98.92
***********invariance test set **********
Accuracy: 79.9

Patience= 6, Time=23.00038, train_epoch_loss = 0.03427225803124144, test_epoch_acc = 79.9
                                                                                                    
Training @ epoch = 53, 0/235, loss = 0.03456, pos_mask = 0.06900894641876221, neg_mask = 0.5108965635299683
Training @ epoch = 53, 60/235, loss = 0.03292, pos_mask = 0.09186102449893951, neg_mask = 0.48975133895874023
Training @ epoch = 53, 120/235, loss = 0.03419, pos_mask = 0.06270547211170197, neg_mask = 0.5325506925582886
Training @ epoch = 53, 180/235, loss = 0.03331, pos_mask = 0.052093297243118286, neg_mask = 0.5469555854797363
***********original test set **********
Accuracy: 99.04
***********sensitivity test set **********
Accuracy: 98.9
***********invariance test set **********
Accuracy: 80.32

Patience= 5, Time=23.43406, train_epoch_loss = 0.03341147104634883, test_epoch_acc = 80.32
                                                                                                    
Training @ epoch = 54, 0/235, loss = 0.03237, pos_mask = 0.0731499120593071, neg_mask = 0.5149627923965454
Training @ epoch = 54, 60/235, loss = 0.03343, pos_mask = 0.08270514011383057, neg_mask = 0.5089713335037231
Training @ epoch = 54, 120/235, loss = 0.03674, pos_mask = 0.09765240550041199, neg_mask = 0.4790424108505249
Training @ epoch = 54, 180/235, loss = 0.03112, pos_mask = 0.07448530197143555, neg_mask = 0.5083591341972351
***********original test set **********
Accuracy: 99.05
***********sensitivity test set **********
Accuracy: 98.95
***********invariance test set **********
Accuracy: 83.49

Patience= 4, Time=23.86627, train_epoch_loss = 0.03375780773448183, test_epoch_acc = 83.49
                                                                                                    
Training @ epoch = 55, 0/235, loss = 0.03284, pos_mask = 0.08451099693775177, neg_mask = 0.4796866178512573
Training @ epoch = 55, 60/235, loss = 0.03304, pos_mask = 0.08653116971254349, neg_mask = 0.464626669883728
Training @ epoch = 55, 120/235, loss = 0.03203, pos_mask = 0.07700005173683167, neg_mask = 0.5185943841934204
Training @ epoch = 55, 180/235, loss = 0.03189, pos_mask = 0.08679170906543732, neg_mask = 0.50881028175354
***********original test set **********
Accuracy: 99.09
***********sensitivity test set **********
Accuracy: 98.98
***********invariance test set **********
Accuracy: 81.26

Patience= 3, Time=24.29805, train_epoch_loss = 0.03247592342185213, test_epoch_acc = 81.26
                                                                                                    
Training @ epoch = 56, 0/235, loss = 0.03361, pos_mask = 0.06121671572327614, neg_mask = 0.5488343238830566
Training @ epoch = 56, 60/235, loss = 0.03053, pos_mask = 0.07420683652162552, neg_mask = 0.5189023613929749
Training @ epoch = 56, 120/235, loss = 0.03150, pos_mask = 0.06416253745555878, neg_mask = 0.543216347694397
Training @ epoch = 56, 180/235, loss = 0.03170, pos_mask = 0.06199119985103607, neg_mask = 0.541999876499176
***********original test set **********
Accuracy: 99.07
***********sensitivity test set **********
Accuracy: 98.89
***********invariance test set **********
Accuracy: 82.23

Patience= 2, Time=24.73480, train_epoch_loss = 0.03157788418391918, test_epoch_acc = 82.23
                                                                                                    
Training @ epoch = 57, 0/235, loss = 0.03132, pos_mask = 0.07888337224721909, neg_mask = 0.5273091197013855
Training @ epoch = 57, 60/235, loss = 0.03062, pos_mask = 0.054964978247880936, neg_mask = 0.5090533494949341
Training @ epoch = 57, 120/235, loss = 0.03271, pos_mask = 0.0690232515335083, neg_mask = 0.5347009897232056
Training @ epoch = 57, 180/235, loss = 0.03067, pos_mask = 0.09049272537231445, neg_mask = 0.4802643060684204
***********original test set **********
Accuracy: 99.0
***********sensitivity test set **********
Accuracy: 98.87
***********invariance test set **********
Accuracy: 79.43

Patience= 1, Time=25.16781, train_epoch_loss = 0.03095723033902493, test_epoch_acc = 79.43
                                                                                                    
Training @ epoch = 58, 0/235, loss = 0.03239, pos_mask = 0.05930815264582634, neg_mask = 0.5536665916442871
Training @ epoch = 58, 60/235, loss = 0.02931, pos_mask = 0.08606955409049988, neg_mask = 0.5205674171447754
Training @ epoch = 58, 120/235, loss = 0.03149, pos_mask = 0.06285658478736877, neg_mask = 0.5221580266952515
Training @ epoch = 58, 180/235, loss = 0.03050, pos_mask = 0.0706263929605484, neg_mask = 0.5467920303344727
***********original test set **********
Accuracy: 99.03
***********sensitivity test set **********
Accuracy: 98.98
***********invariance test set **********
Accuracy: 81.34

Patience= 0, Time=25.59929, train_epoch_loss = 0.030708213832150114, test_epoch_acc = 81.34
                                                                                                    
Training @ epoch = 59, 0/235, loss = 0.03323, pos_mask = 0.07720355689525604, neg_mask = 0.4981982111930847
Training @ epoch = 59, 60/235, loss = 0.02888, pos_mask = 0.06812695413827896, neg_mask = 0.5333801507949829
Training @ epoch = 59, 120/235, loss = 0.04014, pos_mask = 0.0936700776219368, neg_mask = 0.4588510990142822
Training @ epoch = 59, 180/235, loss = 0.07516, pos_mask = 0.17796571552753448, neg_mask = 0.4109027683734894
***********original test set **********
Accuracy: 98.95
***********sensitivity test set **********
Accuracy: 98.81
***********invariance test set **********
Accuracy: 76.0

Patience= -1, Time=26.03381, train_epoch_loss = 0.04284273601592855, test_epoch_acc = 76.0
                                                                                                    
Training @ epoch = 60, 0/235, loss = 0.03677, pos_mask = 0.07383264601230621, neg_mask = 0.4798581600189209
Training @ epoch = 60, 60/235, loss = 0.03433, pos_mask = 0.0985615998506546, neg_mask = 0.524268627166748
Training @ epoch = 60, 120/235, loss = 0.03650, pos_mask = 0.10191158205270767, neg_mask = 0.482992559671402
Training @ epoch = 60, 180/235, loss = 0.03966, pos_mask = 0.12127572298049927, neg_mask = 0.439739465713501
***********original test set **********
Accuracy: 98.79
***********sensitivity test set **********
Accuracy: 98.57
***********invariance test set **********
Accuracy: 77.56

Patience= -2, Time=26.46479, train_epoch_loss = 0.03861622483013792, test_epoch_acc = 77.56
                                                                                                    
Training @ epoch = 61, 0/235, loss = 0.05967, pos_mask = 0.1417628973722458, neg_mask = 0.44939494132995605
Training @ epoch = 61, 60/235, loss = 0.03108, pos_mask = 0.06762860715389252, neg_mask = 0.4927724599838257
Training @ epoch = 61, 120/235, loss = 0.02999, pos_mask = 0.0883784145116806, neg_mask = 0.5006507039070129
Training @ epoch = 61, 180/235, loss = 0.03032, pos_mask = 0.09141722321510315, neg_mask = 0.5403160452842712
***********original test set **********
Accuracy: 99.03
***********sensitivity test set **********
Accuracy: 98.93
***********invariance test set **********
Accuracy: 80.89

Patience= -3, Time=26.89656, train_epoch_loss = 0.032034204266172775, test_epoch_acc = 80.89
                                                                                                    
Training @ epoch = 62, 0/235, loss = 0.03118, pos_mask = 0.08284937590360641, neg_mask = 0.5203666090965271
Training @ epoch = 62, 60/235, loss = 0.03008, pos_mask = 0.06121036410331726, neg_mask = 0.5485135316848755
Training @ epoch = 62, 120/235, loss = 0.02781, pos_mask = 0.06961648166179657, neg_mask = 0.5359362363815308
Training @ epoch = 62, 180/235, loss = 0.02823, pos_mask = 0.06996449828147888, neg_mask = 0.5509203672409058
***********original test set **********
Accuracy: 99.09
***********sensitivity test set **********
Accuracy: 98.98
***********invariance test set **********
Accuracy: 82.29

Patience= -4, Time=27.32782, train_epoch_loss = 0.0291263295932019, test_epoch_acc = 82.29
                                                                                                    
Training @ epoch = 63, 0/235, loss = 0.02793, pos_mask = 0.057971373200416565, neg_mask = 0.548923134803772
Training @ epoch = 63, 60/235, loss = 0.02724, pos_mask = 0.08191926777362823, neg_mask = 0.5354981422424316
Training @ epoch = 63, 120/235, loss = 0.02888, pos_mask = 0.07380504906177521, neg_mask = 0.5355637669563293
Training @ epoch = 63, 180/235, loss = 0.02832, pos_mask = 0.04739861190319061, neg_mask = 0.5525757074356079
***********original test set **********
Accuracy: 99.1
***********sensitivity test set **********
Accuracy: 99.01
***********invariance test set **********
Accuracy: 81.49

Patience= -5, Time=27.75833, train_epoch_loss = 0.028406720117051552, test_epoch_acc = 81.49
                                                                                                    
Training @ epoch = 64, 0/235, loss = 0.02827, pos_mask = 0.06456201523542404, neg_mask = 0.5383760929107666
Training @ epoch = 64, 60/235, loss = 0.02867, pos_mask = 0.07732951641082764, neg_mask = 0.5307450294494629
Training @ epoch = 64, 120/235, loss = 0.02842, pos_mask = 0.05148690193891525, neg_mask = 0.5511664152145386
Training @ epoch = 64, 180/235, loss = 0.02717, pos_mask = 0.05151597410440445, neg_mask = 0.5454798936843872
***********original test set **********
Accuracy: 99.1
***********sensitivity test set **********
Accuracy: 99.0
***********invariance test set **********
Accuracy: 83.64

Patience= -6, Time=28.19023, train_epoch_loss = 0.027958745319158474, test_epoch_acc = 83.64
                                                                                                    
Training @ epoch = 65, 0/235, loss = 0.02837, pos_mask = 0.04552016034722328, neg_mask = 0.5458561182022095
Training @ epoch = 65, 60/235, loss = 0.02710, pos_mask = 0.06021854281425476, neg_mask = 0.5513267517089844
Training @ epoch = 65, 120/235, loss = 0.02727, pos_mask = 0.05026747286319733, neg_mask = 0.5901346206665039
Training @ epoch = 65, 180/235, loss = 0.02587, pos_mask = 0.06106080487370491, neg_mask = 0.5321856737136841
***********original test set **********
Accuracy: 99.08
***********sensitivity test set **********
Accuracy: 98.98
***********invariance test set **********
Accuracy: 82.75

Patience= -7, Time=28.62757, train_epoch_loss = 0.02750770369584256, test_epoch_acc = 82.75
                                                                                                    
Training @ epoch = 66, 0/235, loss = 0.02837, pos_mask = 0.062346428632736206, neg_mask = 0.5662795901298523
Training @ epoch = 66, 60/235, loss = 0.02713, pos_mask = 0.04808622971177101, neg_mask = 0.561302661895752
Training @ epoch = 66, 120/235, loss = 0.02810, pos_mask = 0.05678848922252655, neg_mask = 0.5176420211791992
Training @ epoch = 66, 180/235, loss = 0.02721, pos_mask = 0.06395699083805084, neg_mask = 0.5529443025588989
***********original test set **********
Accuracy: 99.11
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 82.39

Patience= -8, Time=29.06304, train_epoch_loss = 0.027111148097096607, test_epoch_acc = 82.39
                                                                                                    
Training @ epoch = 67, 0/235, loss = 0.02627, pos_mask = 0.06097107753157616, neg_mask = 0.5625661611557007
Training @ epoch = 67, 60/235, loss = 0.02653, pos_mask = 0.047569818794727325, neg_mask = 0.5601438283920288
Training @ epoch = 67, 120/235, loss = 0.02659, pos_mask = 0.05527206137776375, neg_mask = 0.5311574935913086
Training @ epoch = 67, 180/235, loss = 0.02622, pos_mask = 0.05279155075550079, neg_mask = 0.5770623087882996
***********original test set **********
Accuracy: 99.08
***********sensitivity test set **********
Accuracy: 99.01
***********invariance test set **********
Accuracy: 83.1

Patience= -9, Time=29.49683, train_epoch_loss = 0.02668320502531021, test_epoch_acc = 83.1
                                                                                                    
Training @ epoch = 68, 0/235, loss = 0.02695, pos_mask = 0.05700545012950897, neg_mask = 0.5292679667472839
Training @ epoch = 68, 60/235, loss = 0.02701, pos_mask = 0.04787128418684006, neg_mask = 0.5780612230300903
Training @ epoch = 68, 120/235, loss = 0.02768, pos_mask = 0.0351300984621048, neg_mask = 0.5853330492973328
Training @ epoch = 68, 180/235, loss = 0.02626, pos_mask = 0.05192917585372925, neg_mask = 0.563782811164856
***********original test set **********
Accuracy: 99.1
***********sensitivity test set **********
Accuracy: 99.0
***********invariance test set **********
Accuracy: 83.44

Patience= -10, Time=29.93222, train_epoch_loss = 0.02628381020845251, test_epoch_acc = 83.44
                                                                                                    
Training @ epoch = 69, 0/235, loss = 0.02627, pos_mask = 0.046002499759197235, neg_mask = 0.532664954662323
Training @ epoch = 69, 60/235, loss = 0.02470, pos_mask = 0.05481201410293579, neg_mask = 0.5375120639801025
Training @ epoch = 69, 120/235, loss = 0.02656, pos_mask = 0.051747050136327744, neg_mask = 0.5575071573257446
Training @ epoch = 69, 180/235, loss = 0.02515, pos_mask = 0.05504636839032173, neg_mask = 0.5181986689567566
***********original test set **********
Accuracy: 99.05
***********sensitivity test set **********
Accuracy: 98.97
***********invariance test set **********
Accuracy: 82.77

Patience= -11, Time=30.36357, train_epoch_loss = 0.02588977942124326, test_epoch_acc = 82.77
                                                                                                    
Training @ epoch = 70, 0/235, loss = 0.02566, pos_mask = 0.05981435999274254, neg_mask = 0.5279895067214966
Training @ epoch = 70, 60/235, loss = 0.02556, pos_mask = 0.051209572702646255, neg_mask = 0.5428808927536011
Training @ epoch = 70, 120/235, loss = 0.02579, pos_mask = 0.04704315960407257, neg_mask = 0.5384230613708496
Training @ epoch = 70, 180/235, loss = 0.02457, pos_mask = 0.06769754737615585, neg_mask = 0.5441642999649048
***********original test set **********
Accuracy: 99.08
***********sensitivity test set **********
Accuracy: 98.98
***********invariance test set **********
Accuracy: 82.54

Patience= -12, Time=30.79775, train_epoch_loss = 0.02543878804971563, test_epoch_acc = 82.54
                                                                                                    
Training @ epoch = 71, 0/235, loss = 0.02555, pos_mask = 0.05349445715546608, neg_mask = 0.5549717545509338
Training @ epoch = 71, 60/235, loss = 0.02553, pos_mask = 0.050963833928108215, neg_mask = 0.5337766408920288
Training @ epoch = 71, 120/235, loss = 0.02475, pos_mask = 0.047499388456344604, neg_mask = 0.5707111358642578
Training @ epoch = 71, 180/235, loss = 0.02439, pos_mask = 0.06966280937194824, neg_mask = 0.5203976035118103
***********original test set **********
Accuracy: 99.09
***********sensitivity test set **********
Accuracy: 98.93
***********invariance test set **********
Accuracy: 81.41

Patience= -13, Time=31.23089, train_epoch_loss = 0.025038331675719706, test_epoch_acc = 81.41
                                                                                                    
Training @ epoch = 72, 0/235, loss = 0.02488, pos_mask = 0.05765751376748085, neg_mask = 0.5672258138656616
Training @ epoch = 72, 60/235, loss = 0.02494, pos_mask = 0.04491414129734039, neg_mask = 0.5595207810401917
Training @ epoch = 72, 120/235, loss = 0.02406, pos_mask = 0.07638850808143616, neg_mask = 0.5409541130065918
Training @ epoch = 72, 180/235, loss = 0.02529, pos_mask = 0.054235342890024185, neg_mask = 0.5459965467453003
***********original test set **********
Accuracy: 99.12
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 84.03

Patience= -14, Time=31.66527, train_epoch_loss = 0.024672536020900342, test_epoch_acc = 84.03
                                                                                                    
Training @ epoch = 73, 0/235, loss = 0.02469, pos_mask = 0.05789612606167793, neg_mask = 0.5463600158691406
Training @ epoch = 73, 60/235, loss = 0.02368, pos_mask = 0.05550467222929001, neg_mask = 0.5443993806838989
Training @ epoch = 73, 120/235, loss = 0.02409, pos_mask = 0.05571122094988823, neg_mask = 0.5631768703460693
Training @ epoch = 73, 180/235, loss = 0.02327, pos_mask = 0.049090106040239334, neg_mask = 0.5490130186080933
***********original test set **********
Accuracy: 99.11
***********sensitivity test set **********
Accuracy: 99.01
***********invariance test set **********
Accuracy: 83.93

Patience= -15, Time=32.10072, train_epoch_loss = 0.02426018015025778, test_epoch_acc = 83.93
                                                                                                    
Training @ epoch = 74, 0/235, loss = 0.02524, pos_mask = 0.04869740828871727, neg_mask = 0.5512676239013672
Training @ epoch = 74, 60/235, loss = 0.02407, pos_mask = 0.05666092410683632, neg_mask = 0.558617353439331
Training @ epoch = 74, 120/235, loss = 0.02385, pos_mask = 0.04818122461438179, neg_mask = 0.584572434425354
Training @ epoch = 74, 180/235, loss = 0.02354, pos_mask = 0.04669983312487602, neg_mask = 0.5578464269638062
***********original test set **********
Accuracy: 99.11
***********sensitivity test set **********
Accuracy: 99.01
***********invariance test set **********
Accuracy: 82.56

Patience= -16, Time=32.53125, train_epoch_loss = 0.02389554150719592, test_epoch_acc = 82.56
                                                                                                    
Training @ epoch = 75, 0/235, loss = 0.02269, pos_mask = 0.05202801525592804, neg_mask = 0.5604365468025208
Training @ epoch = 75, 60/235, loss = 0.02371, pos_mask = 0.045679956674575806, neg_mask = 0.5690501928329468
Training @ epoch = 75, 120/235, loss = 0.02388, pos_mask = 0.04936942458152771, neg_mask = 0.5767790079116821
Training @ epoch = 75, 180/235, loss = 0.02293, pos_mask = 0.06674187630414963, neg_mask = 0.5285062193870544
***********original test set **********
Accuracy: 99.04
***********sensitivity test set **********
Accuracy: 98.94
***********invariance test set **********
Accuracy: 80.13

Patience= -17, Time=32.96427, train_epoch_loss = 0.023466339810414516, test_epoch_acc = 80.13
                                                                                                    
Training @ epoch = 76, 0/235, loss = 0.02351, pos_mask = 0.07105471193790436, neg_mask = 0.5722543001174927
Training @ epoch = 76, 60/235, loss = 0.02265, pos_mask = 0.05205628648400307, neg_mask = 0.5584588646888733
Training @ epoch = 76, 120/235, loss = 0.02315, pos_mask = 0.0518806129693985, neg_mask = 0.5795449614524841
Training @ epoch = 76, 180/235, loss = 0.02334, pos_mask = 0.05349133908748627, neg_mask = 0.5721942782402039
***********original test set **********
Accuracy: 99.07
***********sensitivity test set **********
Accuracy: 98.96
***********invariance test set **********
Accuracy: 83.86

Patience= -18, Time=33.39691, train_epoch_loss = 0.02328302650217046, test_epoch_acc = 83.86
                                                                                                    
Training @ epoch = 77, 0/235, loss = 0.02421, pos_mask = 0.06267121434211731, neg_mask = 0.5649420619010925
Training @ epoch = 77, 60/235, loss = 0.10458, pos_mask = 0.19517782330513, neg_mask = 0.4127081632614136
Training @ epoch = 77, 120/235, loss = 0.02930, pos_mask = 0.06768787652254105, neg_mask = 0.5032987594604492
Training @ epoch = 77, 180/235, loss = 0.02898, pos_mask = 0.06592267751693726, neg_mask = 0.5280249714851379
***********original test set **********
Accuracy: 99.02
***********sensitivity test set **********
Accuracy: 98.89
***********invariance test set **********
Accuracy: 85.06

Patience= -18, Time=33.82946, train_epoch_loss = 0.04285998546538201, test_epoch_acc = 85.06
                                                                                                    
Training @ epoch = 78, 0/235, loss = 0.02631, pos_mask = 0.06721577793359756, neg_mask = 0.5213927030563354
Training @ epoch = 78, 60/235, loss = 0.02817, pos_mask = 0.09513979405164719, neg_mask = 0.4873049259185791
Training @ epoch = 78, 120/235, loss = 0.02384, pos_mask = 0.07472017407417297, neg_mask = 0.5437194108963013
Training @ epoch = 78, 180/235, loss = 0.02568, pos_mask = 0.09942688047885895, neg_mask = 0.5413062572479248
***********original test set **********
Accuracy: 99.13
***********sensitivity test set **********
Accuracy: 98.98
***********invariance test set **********
Accuracy: 83.06

Patience= -19, Time=34.26225, train_epoch_loss = 0.02656037077466224, test_epoch_acc = 83.06
                                                                                                    
Training @ epoch = 79, 0/235, loss = 0.02302, pos_mask = 0.06330008804798126, neg_mask = 0.5262975692749023
Training @ epoch = 79, 60/235, loss = 0.02481, pos_mask = 0.04320097714662552, neg_mask = 0.5672026872634888
Training @ epoch = 79, 120/235, loss = 0.02402, pos_mask = 0.05434764549136162, neg_mask = 0.5467432737350464
Training @ epoch = 79, 180/235, loss = 0.02278, pos_mask = 0.05356134474277496, neg_mask = 0.5557156801223755
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.0
***********invariance test set **********
Accuracy: 84.31

Patience= -20, Time=34.69710, train_epoch_loss = 0.02383755256045372, test_epoch_acc = 84.31
                                                                                                    
Training @ epoch = 80, 0/235, loss = 0.02336, pos_mask = 0.03890145197510719, neg_mask = 0.566523551940918
Training @ epoch = 80, 60/235, loss = 0.02307, pos_mask = 0.0569794699549675, neg_mask = 0.5587416887283325
Training @ epoch = 80, 120/235, loss = 0.02233, pos_mask = 0.06747381389141083, neg_mask = 0.5473949909210205
Training @ epoch = 80, 180/235, loss = 0.02210, pos_mask = 0.0626620352268219, neg_mask = 0.5403420925140381
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 84.64

Patience= -21, Time=35.13285, train_epoch_loss = 0.022888964279852014, test_epoch_acc = 84.64
                                                                                                    
Training @ epoch = 81, 0/235, loss = 0.02250, pos_mask = 0.050681792199611664, neg_mask = 0.5829763412475586
Training @ epoch = 81, 60/235, loss = 0.02295, pos_mask = 0.03785444423556328, neg_mask = 0.5663535594940186
Training @ epoch = 81, 120/235, loss = 0.02310, pos_mask = 0.04451917111873627, neg_mask = 0.5665372610092163
Training @ epoch = 81, 180/235, loss = 0.02207, pos_mask = 0.05042615905404091, neg_mask = 0.5639361143112183
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 83.89

Patience= -22, Time=35.56042, train_epoch_loss = 0.02249792567751509, test_epoch_acc = 83.89
                                                                                                    
Training @ epoch = 82, 0/235, loss = 0.02241, pos_mask = 0.0629289448261261, neg_mask = 0.5615116953849792
Training @ epoch = 82, 60/235, loss = 0.02207, pos_mask = 0.046522125601768494, neg_mask = 0.583522617816925
Training @ epoch = 82, 120/235, loss = 0.02170, pos_mask = 0.05320131406188011, neg_mask = 0.576380729675293
Training @ epoch = 82, 180/235, loss = 0.02155, pos_mask = 0.07198874652385712, neg_mask = 0.5126367807388306
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 83.42

Patience= -23, Time=35.99372, train_epoch_loss = 0.022302521733527488, test_epoch_acc = 83.42
                                                                                                    
Training @ epoch = 83, 0/235, loss = 0.02231, pos_mask = 0.036344610154628754, neg_mask = 0.5648071765899658
Training @ epoch = 83, 60/235, loss = 0.02175, pos_mask = 0.04276294261217117, neg_mask = 0.5898907780647278
Training @ epoch = 83, 120/235, loss = 0.02171, pos_mask = 0.0499146468937397, neg_mask = 0.558296799659729
Training @ epoch = 83, 180/235, loss = 0.02223, pos_mask = 0.04521113634109497, neg_mask = 0.5587063431739807
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.09
***********invariance test set **********
Accuracy: 83.57

Patience= -24, Time=36.42422, train_epoch_loss = 0.02199906919230806, test_epoch_acc = 83.57
                                                                                                    
Training @ epoch = 84, 0/235, loss = 0.02192, pos_mask = 0.047657936811447144, neg_mask = 0.5781044363975525
Training @ epoch = 84, 60/235, loss = 0.02051, pos_mask = 0.054281555116176605, neg_mask = 0.5420535206794739
Training @ epoch = 84, 120/235, loss = 0.02062, pos_mask = 0.05520806461572647, neg_mask = 0.5538943409919739
Training @ epoch = 84, 180/235, loss = 0.02243, pos_mask = 0.03376901149749756, neg_mask = 0.5846353769302368
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 83.51

Patience= -25, Time=36.85771, train_epoch_loss = 0.021757183556861067, test_epoch_acc = 83.51
                                                                                                    
Training @ epoch = 85, 0/235, loss = 0.02167, pos_mask = 0.06022649630904198, neg_mask = 0.5627556443214417
Training @ epoch = 85, 60/235, loss = 0.02122, pos_mask = 0.04135000705718994, neg_mask = 0.5913817286491394
Training @ epoch = 85, 120/235, loss = 0.02143, pos_mask = 0.03473339229822159, neg_mask = 0.5841575860977173
Training @ epoch = 85, 180/235, loss = 0.02079, pos_mask = 0.057189300656318665, neg_mask = 0.5432878732681274
***********original test set **********
Accuracy: 99.15
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 82.81

Patience= -26, Time=37.28934, train_epoch_loss = 0.021527169359491227, test_epoch_acc = 82.81
                                                                                                    
Training @ epoch = 86, 0/235, loss = 0.02215, pos_mask = 0.04620691388845444, neg_mask = 0.5785760879516602
Training @ epoch = 86, 60/235, loss = 0.02054, pos_mask = 0.055889468640089035, neg_mask = 0.5680770874023438
Training @ epoch = 86, 120/235, loss = 0.02167, pos_mask = 0.038132183253765106, neg_mask = 0.5730980038642883
Training @ epoch = 86, 180/235, loss = 0.02063, pos_mask = 0.03606634587049484, neg_mask = 0.5826148986816406
***********original test set **********
Accuracy: 99.13
***********sensitivity test set **********
Accuracy: 99.0
***********invariance test set **********
Accuracy: 83.53

Patience= -27, Time=37.72518, train_epoch_loss = 0.02126544584777761, test_epoch_acc = 83.53
                                                                                                    
Training @ epoch = 87, 0/235, loss = 0.02152, pos_mask = 0.039283208549022675, neg_mask = 0.58079993724823
Training @ epoch = 87, 60/235, loss = 0.02085, pos_mask = 0.039724111557006836, neg_mask = 0.5488793849945068
Training @ epoch = 87, 120/235, loss = 0.02134, pos_mask = 0.0483916774392128, neg_mask = 0.5641405582427979
Training @ epoch = 87, 180/235, loss = 0.02040, pos_mask = 0.049858953803777695, neg_mask = 0.5610674619674683
***********original test set **********
Accuracy: 99.14
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 83.62

Patience= -28, Time=38.16014, train_epoch_loss = 0.021041807151855305, test_epoch_acc = 83.62
                                                                                                    
Training @ epoch = 88, 0/235, loss = 0.02028, pos_mask = 0.04360094666481018, neg_mask = 0.5634446740150452
Training @ epoch = 88, 60/235, loss = 0.02101, pos_mask = 0.04033908247947693, neg_mask = 0.5790113806724548
Training @ epoch = 88, 120/235, loss = 0.01981, pos_mask = 0.05939394235610962, neg_mask = 0.5491458177566528
Training @ epoch = 88, 180/235, loss = 0.01962, pos_mask = 0.049302924424409866, neg_mask = 0.5521993637084961
***********original test set **********
Accuracy: 99.14
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 83.73

Patience= -29, Time=38.59177, train_epoch_loss = 0.020792051063890152, test_epoch_acc = 83.73
                                                                                                    
Training @ epoch = 89, 0/235, loss = 0.02070, pos_mask = 0.03718745708465576, neg_mask = 0.6021459102630615
Training @ epoch = 89, 60/235, loss = 0.02029, pos_mask = 0.04564497619867325, neg_mask = 0.6003668308258057
Training @ epoch = 89, 120/235, loss = 0.02120, pos_mask = 0.03438880294561386, neg_mask = 0.6033949851989746
Training @ epoch = 89, 180/235, loss = 0.02066, pos_mask = 0.039301708340644836, neg_mask = 0.5824105739593506
***********original test set **********
Accuracy: 99.12
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 83.5

Patience= -30, Time=39.02127, train_epoch_loss = 0.020523899872886373, test_epoch_acc = 83.5
                                                                                                    
Training @ epoch = 90, 0/235, loss = 0.02165, pos_mask = 0.027018040418624878, neg_mask = 0.6263256669044495
Training @ epoch = 90, 60/235, loss = 0.02017, pos_mask = 0.03873457759618759, neg_mask = 0.5956928730010986
Training @ epoch = 90, 120/235, loss = 0.02016, pos_mask = 0.039497010409832, neg_mask = 0.583931565284729
Training @ epoch = 90, 180/235, loss = 0.02153, pos_mask = 0.030565088614821434, neg_mask = 0.6090208292007446
***********original test set **********
Accuracy: 99.13
***********sensitivity test set **********
Accuracy: 99.0
***********invariance test set **********
Accuracy: 82.51

Patience= -31, Time=39.45383, train_epoch_loss = 0.02029328427891782, test_epoch_acc = 82.51
                                                                                                    
Training @ epoch = 91, 0/235, loss = 0.02046, pos_mask = 0.03236645832657814, neg_mask = 0.609078586101532
Training @ epoch = 91, 60/235, loss = 0.01972, pos_mask = 0.03410883992910385, neg_mask = 0.5960431694984436
Training @ epoch = 91, 120/235, loss = 0.02030, pos_mask = 0.036419086158275604, neg_mask = 0.6170675754547119
Training @ epoch = 91, 180/235, loss = 0.02002, pos_mask = 0.043902039527893066, neg_mask = 0.5657103061676025
***********original test set **********
Accuracy: 99.15
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 82.82

Patience= -32, Time=39.88867, train_epoch_loss = 0.019988471467761282, test_epoch_acc = 82.82
                                                                                                    
Training @ epoch = 92, 0/235, loss = 0.01956, pos_mask = 0.04037156701087952, neg_mask = 0.569436252117157
Training @ epoch = 92, 60/235, loss = 0.01990, pos_mask = 0.037265174090862274, neg_mask = 0.5978952646255493
Training @ epoch = 92, 120/235, loss = 0.01889, pos_mask = 0.06462638080120087, neg_mask = 0.5725951790809631
Training @ epoch = 92, 180/235, loss = 0.02021, pos_mask = 0.03499407693743706, neg_mask = 0.5980345010757446
***********original test set **********
Accuracy: 99.13
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 82.82

Patience= -33, Time=40.32207, train_epoch_loss = 0.01970383697684775, test_epoch_acc = 82.82
                                                                                                    
Training @ epoch = 93, 0/235, loss = 0.02060, pos_mask = 0.031214050948619843, neg_mask = 0.5932531952857971
Training @ epoch = 93, 60/235, loss = 0.01913, pos_mask = 0.040527962148189545, neg_mask = 0.5806239247322083
Training @ epoch = 93, 120/235, loss = 0.02013, pos_mask = 0.027354370802640915, neg_mask = 0.6208786368370056
Training @ epoch = 93, 180/235, loss = 0.01909, pos_mask = 0.033803731203079224, neg_mask = 0.5823360681533813
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 82.78

Patience= -34, Time=40.75455, train_epoch_loss = 0.019468254865484036, test_epoch_acc = 82.78
                                                                                                    
Training @ epoch = 94, 0/235, loss = 0.01983, pos_mask = 0.027902618050575256, neg_mask = 0.6301611661911011
Training @ epoch = 94, 60/235, loss = 0.01954, pos_mask = 0.03635358065366745, neg_mask = 0.5935871601104736
Training @ epoch = 94, 120/235, loss = 0.01942, pos_mask = 0.03309579938650131, neg_mask = 0.5766279697418213
Training @ epoch = 94, 180/235, loss = 0.01883, pos_mask = 0.04085259139537811, neg_mask = 0.5641641616821289
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 82.08

Patience= -35, Time=41.18813, train_epoch_loss = 0.01919934240744469, test_epoch_acc = 82.08
                                                                                                    
Training @ epoch = 95, 0/235, loss = 0.01979, pos_mask = 0.03777717798948288, neg_mask = 0.6143072843551636
Training @ epoch = 95, 60/235, loss = 0.01890, pos_mask = 0.04257556051015854, neg_mask = 0.5888808965682983
Training @ epoch = 95, 120/235, loss = 0.01819, pos_mask = 0.04263484850525856, neg_mask = 0.5774316191673279
Training @ epoch = 95, 180/235, loss = 0.01901, pos_mask = 0.03666901960968971, neg_mask = 0.5989304780960083
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 82.87

Patience= -36, Time=41.62241, train_epoch_loss = 0.018918174521086063, test_epoch_acc = 82.87
                                                                                                    
Training @ epoch = 96, 0/235, loss = 0.01834, pos_mask = 0.038584351539611816, neg_mask = 0.5925323367118835
Training @ epoch = 96, 60/235, loss = 0.01875, pos_mask = 0.038546886295080185, neg_mask = 0.5970245003700256
Training @ epoch = 96, 120/235, loss = 0.01858, pos_mask = 0.035812024027109146, neg_mask = 0.6045948266983032
Training @ epoch = 96, 180/235, loss = 0.01871, pos_mask = 0.03560355305671692, neg_mask = 0.5912467241287231
***********original test set **********
Accuracy: 99.15
***********sensitivity test set **********
Accuracy: 99.01
***********invariance test set **********
Accuracy: 82.27

Patience= -37, Time=42.05440, train_epoch_loss = 0.01863142121186916, test_epoch_acc = 82.27
                                                                                                    
Training @ epoch = 97, 0/235, loss = 0.01885, pos_mask = 0.04333648085594177, neg_mask = 0.5770255327224731
Training @ epoch = 97, 60/235, loss = 0.01766, pos_mask = 0.03883669897913933, neg_mask = 0.5787968635559082
Training @ epoch = 97, 120/235, loss = 0.01811, pos_mask = 0.046728216111660004, neg_mask = 0.5856649875640869
Training @ epoch = 97, 180/235, loss = 0.01792, pos_mask = 0.04443908855319023, neg_mask = 0.5701719522476196
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 82.61

Patience= -38, Time=42.48681, train_epoch_loss = 0.018392718567493114, test_epoch_acc = 82.61
                                                                                                    
Training @ epoch = 98, 0/235, loss = 0.01762, pos_mask = 0.05404757708311081, neg_mask = 0.5712031126022339
Training @ epoch = 98, 60/235, loss = 0.01830, pos_mask = 0.04401551932096481, neg_mask = 0.6137304902076721
Training @ epoch = 98, 120/235, loss = 0.01808, pos_mask = 0.03772902861237526, neg_mask = 0.5921874642372131
Training @ epoch = 98, 180/235, loss = 0.01773, pos_mask = 0.03974171355366707, neg_mask = 0.5855278968811035
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.01
***********invariance test set **********
Accuracy: 82.45

Patience= -39, Time=42.92030, train_epoch_loss = 0.01808524526497151, test_epoch_acc = 82.45
                                                                                                    
Training @ epoch = 99, 0/235, loss = 0.01698, pos_mask = 0.03473201394081116, neg_mask = 0.5921241044998169
Training @ epoch = 99, 60/235, loss = 0.01746, pos_mask = 0.03923071548342705, neg_mask = 0.5768862962722778
Training @ epoch = 99, 120/235, loss = 0.01733, pos_mask = 0.03794074058532715, neg_mask = 0.5777996182441711
Training @ epoch = 99, 180/235, loss = 0.01822, pos_mask = 0.02421257458627224, neg_mask = 0.6202188730239868
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.0
***********invariance test set **********
Accuracy: 82.34

Patience= -40, Time=43.35386, train_epoch_loss = 0.017848579807484402, test_epoch_acc = 82.34
                                                                                                    
Training @ epoch = 100, 0/235, loss = 0.01766, pos_mask = 0.031602296978235245, neg_mask = 0.5958072543144226
Training @ epoch = 100, 60/235, loss = 0.01794, pos_mask = 0.034143634140491486, neg_mask = 0.590124785900116
Training @ epoch = 100, 120/235, loss = 0.01646, pos_mask = 0.050537995994091034, neg_mask = 0.5622082352638245
Training @ epoch = 100, 180/235, loss = 0.01686, pos_mask = 0.03769434615969658, neg_mask = 0.5938026905059814
***********original test set **********
Accuracy: 99.12
***********sensitivity test set **********
Accuracy: 98.95
***********invariance test set **********
Accuracy: 83.06

Patience= -41, Time=43.78442, train_epoch_loss = 0.017587774199374177, test_epoch_acc = 83.06
                                                                                                    
Training @ epoch = 101, 0/235, loss = 0.01760, pos_mask = 0.035164181143045425, neg_mask = 0.5894753932952881
Training @ epoch = 101, 60/235, loss = 0.01729, pos_mask = 0.0375259593129158, neg_mask = 0.5843182802200317
Training @ epoch = 101, 120/235, loss = 0.01649, pos_mask = 0.04307824373245239, neg_mask = 0.6012894511222839
Training @ epoch = 101, 180/235, loss = 0.01695, pos_mask = 0.03858431428670883, neg_mask = 0.5825430154800415
***********original test set **********
Accuracy: 99.15
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 81.82

Patience= -42, Time=44.21704, train_epoch_loss = 0.01734575779831156, test_epoch_acc = 81.82
                                                                                                    
Training @ epoch = 102, 0/235, loss = 0.01683, pos_mask = 0.031860094517469406, neg_mask = 0.61690354347229
Training @ epoch = 102, 60/235, loss = 0.01682, pos_mask = 0.04412681236863136, neg_mask = 0.5924937725067139
Training @ epoch = 102, 120/235, loss = 0.01775, pos_mask = 0.027110200375318527, neg_mask = 0.6081970930099487
Training @ epoch = 102, 180/235, loss = 0.01700, pos_mask = 0.03843078762292862, neg_mask = 0.5920102596282959
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 98.99
***********invariance test set **********
Accuracy: 77.16

Patience= -43, Time=44.64888, train_epoch_loss = 0.0170966783181784, test_epoch_acc = 77.16
                                                                                                    
Training @ epoch = 103, 0/235, loss = 0.01801, pos_mask = 0.0723264068365097, neg_mask = 0.5730198621749878
Training @ epoch = 103, 60/235, loss = 0.04367, pos_mask = 0.1662449836730957, neg_mask = 0.4027063250541687
Training @ epoch = 103, 120/235, loss = 0.06337, pos_mask = 0.14352266490459442, neg_mask = 0.3968879282474518
Training @ epoch = 103, 180/235, loss = 0.02139, pos_mask = 0.06353265792131424, neg_mask = 0.5025151968002319
***********original test set **********
Accuracy: 99.12
***********sensitivity test set **********
Accuracy: 98.96
***********invariance test set **********
Accuracy: 81.41

Patience= -44, Time=45.08182, train_epoch_loss = 0.04139092572508974, test_epoch_acc = 81.41
                                                                                                    
Training @ epoch = 104, 0/235, loss = 0.02505, pos_mask = 0.08792160451412201, neg_mask = 0.48913174867630005
Training @ epoch = 104, 60/235, loss = 0.02120, pos_mask = 0.07275454699993134, neg_mask = 0.5288785099983215
Training @ epoch = 104, 120/235, loss = 0.01791, pos_mask = 0.06282627582550049, neg_mask = 0.538140594959259
Training @ epoch = 104, 180/235, loss = 0.01782, pos_mask = 0.06041882932186127, neg_mask = 0.577387809753418
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 98.95
***********invariance test set **********
Accuracy: 81.92

Patience= -45, Time=45.51454, train_epoch_loss = 0.020058356463275057, test_epoch_acc = 81.92
                                                                                                    
Training @ epoch = 105, 0/235, loss = 0.01777, pos_mask = 0.07571685314178467, neg_mask = 0.5489864349365234
Training @ epoch = 105, 60/235, loss = 0.01791, pos_mask = 0.03692714124917984, neg_mask = 0.5857935547828674
Training @ epoch = 105, 120/235, loss = 0.01770, pos_mask = 0.04680735617876053, neg_mask = 0.574324369430542
Training @ epoch = 105, 180/235, loss = 0.01707, pos_mask = 0.05543564260005951, neg_mask = 0.5412466526031494
***********original test set **********
Accuracy: 99.15
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 81.83

Patience= -46, Time=45.94567, train_epoch_loss = 0.017762927782345325, test_epoch_acc = 81.83
                                                                                                    
Training @ epoch = 106, 0/235, loss = 0.01667, pos_mask = 0.05383282154798508, neg_mask = 0.5426478385925293
Training @ epoch = 106, 60/235, loss = 0.01811, pos_mask = 0.04439041018486023, neg_mask = 0.5830718874931335
Training @ epoch = 106, 120/235, loss = 0.01693, pos_mask = 0.07033005356788635, neg_mask = 0.5409136414527893
Training @ epoch = 106, 180/235, loss = 0.01691, pos_mask = 0.039748117327690125, neg_mask = 0.5989775657653809
***********original test set **********
Accuracy: 99.14
***********sensitivity test set **********
Accuracy: 99.01
***********invariance test set **********
Accuracy: 81.11

Patience= -47, Time=46.37620, train_epoch_loss = 0.017402938095496055, test_epoch_acc = 81.11
                                                                                                    
Training @ epoch = 107, 0/235, loss = 0.01684, pos_mask = 0.057763904333114624, neg_mask = 0.5668755173683167
Training @ epoch = 107, 60/235, loss = 0.01652, pos_mask = 0.05845370516180992, neg_mask = 0.5505068302154541
Training @ epoch = 107, 120/235, loss = 0.01689, pos_mask = 0.0415998175740242, neg_mask = 0.5658811330795288
Training @ epoch = 107, 180/235, loss = 0.01818, pos_mask = 0.046482279896736145, neg_mask = 0.5985866785049438
***********original test set **********
Accuracy: 99.14
***********sensitivity test set **********
Accuracy: 98.98
***********invariance test set **********
Accuracy: 82.2

Patience= -48, Time=46.81244, train_epoch_loss = 0.017174500623281966, test_epoch_acc = 82.2
                                                                                                    
Training @ epoch = 108, 0/235, loss = 0.01665, pos_mask = 0.04202054440975189, neg_mask = 0.5742833018302917
Training @ epoch = 108, 60/235, loss = 0.01611, pos_mask = 0.039913177490234375, neg_mask = 0.5937337279319763
Training @ epoch = 108, 120/235, loss = 0.01681, pos_mask = 0.0440622940659523, neg_mask = 0.5928088426589966
Training @ epoch = 108, 180/235, loss = 0.01738, pos_mask = 0.033852577209472656, neg_mask = 0.5996526479721069
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.02
***********invariance test set **********
Accuracy: 81.88

Patience= -49, Time=47.24516, train_epoch_loss = 0.01697979046309248, test_epoch_acc = 81.88
                                                                                                    
Training @ epoch = 109, 0/235, loss = 0.01645, pos_mask = 0.050734907388687134, neg_mask = 0.5865423679351807
Training @ epoch = 109, 60/235, loss = 0.01673, pos_mask = 0.0355708934366703, neg_mask = 0.5950354337692261
Training @ epoch = 109, 120/235, loss = 0.01633, pos_mask = 0.038780421018600464, neg_mask = 0.5722486972808838
Training @ epoch = 109, 180/235, loss = 0.01661, pos_mask = 0.04059320688247681, neg_mask = 0.5968362092971802
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 98.99
***********invariance test set **********
Accuracy: 82.35

Patience= -50, Time=47.67807, train_epoch_loss = 0.01683156588213875, test_epoch_acc = 82.35
                                                                                                    
Training @ epoch = 110, 0/235, loss = 0.01659, pos_mask = 0.03952256217598915, neg_mask = 0.5601187944412231
Training @ epoch = 110, 60/235, loss = 0.01649, pos_mask = 0.040002740919589996, neg_mask = 0.5776083469390869
Training @ epoch = 110, 120/235, loss = 0.01619, pos_mask = 0.03552359715104103, neg_mask = 0.5729889869689941
Training @ epoch = 110, 180/235, loss = 0.01627, pos_mask = 0.03184850513935089, neg_mask = 0.5825910568237305
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 81.83

Patience= -51, Time=48.11366, train_epoch_loss = 0.016635902840247813, test_epoch_acc = 81.83
                                                                                                    
Training @ epoch = 111, 0/235, loss = 0.01572, pos_mask = 0.03996305912733078, neg_mask = 0.5963852405548096
Training @ epoch = 111, 60/235, loss = 0.01672, pos_mask = 0.028463274240493774, neg_mask = 0.6128035187721252
Training @ epoch = 111, 120/235, loss = 0.01645, pos_mask = 0.029421145096421242, neg_mask = 0.6092238426208496
Training @ epoch = 111, 180/235, loss = 0.01659, pos_mask = 0.033588211983442307, neg_mask = 0.5914822816848755
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 81.96

Patience= -52, Time=48.54474, train_epoch_loss = 0.016524007417103078, test_epoch_acc = 81.96
                                                                                                    
Training @ epoch = 112, 0/235, loss = 0.01601, pos_mask = 0.04434586316347122, neg_mask = 0.5754737854003906
Training @ epoch = 112, 60/235, loss = 0.01678, pos_mask = 0.033971719443798065, neg_mask = 0.5978637933731079
Training @ epoch = 112, 120/235, loss = 0.01684, pos_mask = 0.03336356207728386, neg_mask = 0.6065326929092407
Training @ epoch = 112, 180/235, loss = 0.01692, pos_mask = 0.0267162062227726, neg_mask = 0.6324278712272644
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 81.96

Patience= -53, Time=48.97967, train_epoch_loss = 0.016378192155760654, test_epoch_acc = 81.96
                                                                                                    
Training @ epoch = 113, 0/235, loss = 0.01686, pos_mask = 0.03244948387145996, neg_mask = 0.6117775440216064
Training @ epoch = 113, 60/235, loss = 0.01639, pos_mask = 0.0311722569167614, neg_mask = 0.5986428260803223
Training @ epoch = 113, 120/235, loss = 0.01589, pos_mask = 0.037519801408052444, neg_mask = 0.6134563684463501
Training @ epoch = 113, 180/235, loss = 0.01656, pos_mask = 0.03839784488081932, neg_mask = 0.6016821265220642
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 82.21

Patience= -54, Time=49.41434, train_epoch_loss = 0.016240347374943977, test_epoch_acc = 82.21
                                                                                                    
Training @ epoch = 114, 0/235, loss = 0.01600, pos_mask = 0.04196469485759735, neg_mask = 0.5946263074874878
Training @ epoch = 114, 60/235, loss = 0.01711, pos_mask = 0.03494323045015335, neg_mask = 0.6282672882080078
Training @ epoch = 114, 120/235, loss = 0.01662, pos_mask = 0.03381273150444031, neg_mask = 0.6048285961151123
Training @ epoch = 114, 180/235, loss = 0.01592, pos_mask = 0.045127443969249725, neg_mask = 0.6024625897407532
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 82.16

Patience= -55, Time=49.84685, train_epoch_loss = 0.016147306236497898, test_epoch_acc = 82.16
                                                                                                    
Training @ epoch = 115, 0/235, loss = 0.01562, pos_mask = 0.0468919575214386, neg_mask = 0.5879364013671875
Training @ epoch = 115, 60/235, loss = 0.01604, pos_mask = 0.04103653132915497, neg_mask = 0.6000989079475403
Training @ epoch = 115, 120/235, loss = 0.01612, pos_mask = 0.035533271729946136, neg_mask = 0.6211526989936829
Training @ epoch = 115, 180/235, loss = 0.01744, pos_mask = 0.021306011825799942, neg_mask = 0.6377081871032715
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 81.8

Patience= -56, Time=50.28228, train_epoch_loss = 0.01598713733652171, test_epoch_acc = 81.8
                                                                                                    
Training @ epoch = 116, 0/235, loss = 0.01596, pos_mask = 0.039211440831422806, neg_mask = 0.5817519426345825
Training @ epoch = 116, 60/235, loss = 0.01610, pos_mask = 0.03560124337673187, neg_mask = 0.6105534434318542
Training @ epoch = 116, 120/235, loss = 0.01599, pos_mask = 0.026528244838118553, neg_mask = 0.6064575910568237
Training @ epoch = 116, 180/235, loss = 0.01677, pos_mask = 0.025588084012269974, neg_mask = 0.6152028441429138
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 82.46

Patience= -57, Time=50.71485, train_epoch_loss = 0.015838615283211496, test_epoch_acc = 82.46
                                                                                                    
Training @ epoch = 117, 0/235, loss = 0.01568, pos_mask = 0.03253826126456261, neg_mask = 0.6197468042373657
Training @ epoch = 117, 60/235, loss = 0.01602, pos_mask = 0.04182446002960205, neg_mask = 0.6115353107452393
Training @ epoch = 117, 120/235, loss = 0.01497, pos_mask = 0.0330808162689209, neg_mask = 0.5998150110244751
Training @ epoch = 117, 180/235, loss = 0.01532, pos_mask = 0.0323534831404686, neg_mask = 0.6062134504318237
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 81.48

Patience= -58, Time=51.14630, train_epoch_loss = 0.015681174187425602, test_epoch_acc = 81.48
                                                                                                    
Training @ epoch = 118, 0/235, loss = 0.01628, pos_mask = 0.019788384437561035, neg_mask = 0.6250132322311401
Training @ epoch = 118, 60/235, loss = 0.01515, pos_mask = 0.03126022592186928, neg_mask = 0.6313146948814392
Training @ epoch = 118, 120/235, loss = 0.01593, pos_mask = 0.029623880982398987, neg_mask = 0.6158453226089478
Training @ epoch = 118, 180/235, loss = 0.01553, pos_mask = 0.032197315245866776, neg_mask = 0.6269354820251465
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 81.14

Patience= -59, Time=51.58076, train_epoch_loss = 0.015505660955417664, test_epoch_acc = 81.14
                                                                                                    
Training @ epoch = 119, 0/235, loss = 0.01464, pos_mask = 0.04125845432281494, neg_mask = 0.580708920955658
Training @ epoch = 119, 60/235, loss = 0.01565, pos_mask = 0.0305369570851326, neg_mask = 0.6190787553787231
Training @ epoch = 119, 120/235, loss = 0.01576, pos_mask = 0.02461058273911476, neg_mask = 0.6367669701576233
Training @ epoch = 119, 180/235, loss = 0.01584, pos_mask = 0.03604207560420036, neg_mask = 0.61318039894104
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 81.71

Patience= -60, Time=52.01209, train_epoch_loss = 0.015346570610207446, test_epoch_acc = 81.71
                                                                                                    
Training @ epoch = 120, 0/235, loss = 0.01532, pos_mask = 0.02912907302379608, neg_mask = 0.6285543441772461
Training @ epoch = 120, 60/235, loss = 0.01548, pos_mask = 0.02511526644229889, neg_mask = 0.6163375973701477
Training @ epoch = 120, 120/235, loss = 0.01521, pos_mask = 0.0324154756963253, neg_mask = 0.5979856252670288
Training @ epoch = 120, 180/235, loss = 0.01602, pos_mask = 0.02913040481507778, neg_mask = 0.6358324289321899
***********original test set **********
Accuracy: 99.25
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 81.34

Patience= -61, Time=52.44597, train_epoch_loss = 0.015208404760887015, test_epoch_acc = 81.34
                                                                                                    
Training @ epoch = 121, 0/235, loss = 0.01492, pos_mask = 0.0337231308221817, neg_mask = 0.608633279800415
Training @ epoch = 121, 60/235, loss = 0.01445, pos_mask = 0.031524866819381714, neg_mask = 0.6131715774536133
Training @ epoch = 121, 120/235, loss = 0.01479, pos_mask = 0.03307506814599037, neg_mask = 0.604977548122406
Training @ epoch = 121, 180/235, loss = 0.01465, pos_mask = 0.04425404220819473, neg_mask = 0.5964069366455078
***********original test set **********
Accuracy: 99.26
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 82.47

Patience= -62, Time=52.88208, train_epoch_loss = 0.015049012159889049, test_epoch_acc = 82.47
                                                                                                    
Training @ epoch = 122, 0/235, loss = 0.01446, pos_mask = 0.03864022344350815, neg_mask = 0.596755862236023
Training @ epoch = 122, 60/235, loss = 0.01483, pos_mask = 0.02525247260928154, neg_mask = 0.6169309020042419
Training @ epoch = 122, 120/235, loss = 0.01440, pos_mask = 0.030313707888126373, neg_mask = 0.6091969013214111
Training @ epoch = 122, 180/235, loss = 0.01469, pos_mask = 0.03004174306988716, neg_mask = 0.622864305973053
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 81.83

Patience= -63, Time=53.31486, train_epoch_loss = 0.014885817539501698, test_epoch_acc = 81.83
                                                                                                    
Training @ epoch = 123, 0/235, loss = 0.01555, pos_mask = 0.023573659360408783, neg_mask = 0.6310930252075195
Training @ epoch = 123, 60/235, loss = 0.01480, pos_mask = 0.029951658099889755, neg_mask = 0.6147680878639221
Training @ epoch = 123, 120/235, loss = 0.01397, pos_mask = 0.030950650572776794, neg_mask = 0.6019068360328674
Training @ epoch = 123, 180/235, loss = 0.01458, pos_mask = 0.022334080189466476, neg_mask = 0.629389762878418
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 81.39

Patience= -64, Time=53.74895, train_epoch_loss = 0.014693713184208312, test_epoch_acc = 81.39
                                                                                                    
Training @ epoch = 124, 0/235, loss = 0.01441, pos_mask = 0.03021116927266121, neg_mask = 0.6225221157073975
Training @ epoch = 124, 60/235, loss = 0.01469, pos_mask = 0.025741077959537506, neg_mask = 0.6317895650863647
Training @ epoch = 124, 120/235, loss = 0.01423, pos_mask = 0.0334823913872242, neg_mask = 0.6044169068336487
Training @ epoch = 124, 180/235, loss = 0.01409, pos_mask = 0.027640268206596375, neg_mask = 0.6188366413116455
***********original test set **********
Accuracy: 99.24
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 81.21

Patience= -65, Time=54.18039, train_epoch_loss = 0.014550736974528496, test_epoch_acc = 81.21
                                                                                                    
Training @ epoch = 125, 0/235, loss = 0.01493, pos_mask = 0.020740289241075516, neg_mask = 0.6069596409797668
Training @ epoch = 125, 60/235, loss = 0.01434, pos_mask = 0.031028401106595993, neg_mask = 0.6043962240219116
Training @ epoch = 125, 120/235, loss = 0.01451, pos_mask = 0.025034822523593903, neg_mask = 0.6304455399513245
Training @ epoch = 125, 180/235, loss = 0.01464, pos_mask = 0.028932424262166023, neg_mask = 0.6344772577285767
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 80.49

Patience= -66, Time=54.61430, train_epoch_loss = 0.014384432002267938, test_epoch_acc = 80.49
                                                                                                    
Training @ epoch = 126, 0/235, loss = 0.01425, pos_mask = 0.030414247885346413, neg_mask = 0.6276935338973999
Training @ epoch = 126, 60/235, loss = 0.01366, pos_mask = 0.0323980376124382, neg_mask = 0.6132799386978149
Training @ epoch = 126, 120/235, loss = 0.01359, pos_mask = 0.031038586050271988, neg_mask = 0.6110318899154663
Training @ epoch = 126, 180/235, loss = 0.01472, pos_mask = 0.024129126220941544, neg_mask = 0.6258257031440735
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 80.06

Patience= -67, Time=55.04827, train_epoch_loss = 0.014212728660315909, test_epoch_acc = 80.06
                                                                                                    
Training @ epoch = 127, 0/235, loss = 0.01393, pos_mask = 0.02503841370344162, neg_mask = 0.6007007360458374
Training @ epoch = 127, 60/235, loss = 0.01419, pos_mask = 0.024047043174505234, neg_mask = 0.6359114646911621
Training @ epoch = 127, 120/235, loss = 0.01386, pos_mask = 0.0335482582449913, neg_mask = 0.6231509447097778
Training @ epoch = 127, 180/235, loss = 0.01411, pos_mask = 0.03158417344093323, neg_mask = 0.6089223027229309
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 81.45

Patience= -68, Time=55.47774, train_epoch_loss = 0.014052614930303808, test_epoch_acc = 81.45
                                                                                                    
Training @ epoch = 128, 0/235, loss = 0.01369, pos_mask = 0.04089018329977989, neg_mask = 0.5900505781173706
Training @ epoch = 128, 60/235, loss = 0.01343, pos_mask = 0.027754759415984154, neg_mask = 0.6179993152618408
Training @ epoch = 128, 120/235, loss = 0.01331, pos_mask = 0.025533374398946762, neg_mask = 0.6086723804473877
Training @ epoch = 128, 180/235, loss = 0.01367, pos_mask = 0.02892966940999031, neg_mask = 0.6234031319618225
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 80.56

Patience= -69, Time=55.91119, train_epoch_loss = 0.013910784802221238, test_epoch_acc = 80.56
                                                                                                    
Training @ epoch = 129, 0/235, loss = 0.01426, pos_mask = 0.01771668717265129, neg_mask = 0.641133189201355
Training @ epoch = 129, 60/235, loss = 0.01336, pos_mask = 0.028030458837747574, neg_mask = 0.6165515184402466
Training @ epoch = 129, 120/235, loss = 0.01363, pos_mask = 0.030293183401226997, neg_mask = 0.6184254884719849
Training @ epoch = 129, 180/235, loss = 0.01388, pos_mask = 0.026008419692516327, neg_mask = 0.6301939487457275
***********original test set **********
Accuracy: 99.24
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 80.01

Patience= -70, Time=56.34239, train_epoch_loss = 0.013727018506603038, test_epoch_acc = 80.01
                                                                                                    
Training @ epoch = 130, 0/235, loss = 0.01354, pos_mask = 0.025575201958417892, neg_mask = 0.6412239074707031
Training @ epoch = 130, 60/235, loss = 0.01356, pos_mask = 0.026392225176095963, neg_mask = 0.6226426362991333
Training @ epoch = 130, 120/235, loss = 0.01430, pos_mask = 0.018848871812224388, neg_mask = 0.6433686017990112
Training @ epoch = 130, 180/235, loss = 0.01302, pos_mask = 0.03856189548969269, neg_mask = 0.5806400775909424
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 98.99
***********invariance test set **********
Accuracy: 81.19

Patience= -71, Time=56.77410, train_epoch_loss = 0.01356923674887165, test_epoch_acc = 81.19
                                                                                                    
Training @ epoch = 131, 0/235, loss = 0.01355, pos_mask = 0.03207743540406227, neg_mask = 0.6116318106651306
Training @ epoch = 131, 60/235, loss = 0.01335, pos_mask = 0.02155023068189621, neg_mask = 0.6427127122879028
Training @ epoch = 131, 120/235, loss = 0.01327, pos_mask = 0.027130557224154472, neg_mask = 0.6355641484260559
Training @ epoch = 131, 180/235, loss = 0.01360, pos_mask = 0.019007641822099686, neg_mask = 0.6335230469703674
***********original test set **********
Accuracy: 99.25
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 80.43

Patience= -72, Time=57.20293, train_epoch_loss = 0.013427020252702085, test_epoch_acc = 80.43
                                                                                                    
Training @ epoch = 132, 0/235, loss = 0.01287, pos_mask = 0.027500011026859283, neg_mask = 0.5976245403289795
Training @ epoch = 132, 60/235, loss = 0.01378, pos_mask = 0.023448046296834946, neg_mask = 0.6242802739143372
Training @ epoch = 132, 120/235, loss = 0.09843, pos_mask = 0.27785634994506836, neg_mask = 0.43864959478378296
Training @ epoch = 132, 180/235, loss = 0.06290, pos_mask = 0.13007313013076782, neg_mask = 0.4509151577949524
***********original test set **********
Accuracy: 98.94
***********sensitivity test set **********
Accuracy: 98.81
***********invariance test set **********
Accuracy: 82.69

Patience= -73, Time=57.63874, train_epoch_loss = 0.032282794235234565, test_epoch_acc = 82.69
                                                                                                    
Training @ epoch = 133, 0/235, loss = 0.01821, pos_mask = 0.06589823216199875, neg_mask = 0.5455623865127563
Training @ epoch = 133, 60/235, loss = 0.01545, pos_mask = 0.054913654923439026, neg_mask = 0.5537033081054688
Training @ epoch = 133, 120/235, loss = 0.01512, pos_mask = 0.07251948118209839, neg_mask = 0.5321073532104492
Training @ epoch = 133, 180/235, loss = 0.01573, pos_mask = 0.05264770984649658, neg_mask = 0.5884926319122314
***********original test set **********
Accuracy: 99.06
***********sensitivity test set **********
Accuracy: 98.93
***********invariance test set **********
Accuracy: 81.41

Patience= -74, Time=58.07105, train_epoch_loss = 0.017408622662596247, test_epoch_acc = 81.41
                                                                                                    
Training @ epoch = 134, 0/235, loss = 0.01408, pos_mask = 0.0454576201736927, neg_mask = 0.593453049659729
Training @ epoch = 134, 60/235, loss = 0.01451, pos_mask = 0.04702063277363777, neg_mask = 0.5863317847251892
Training @ epoch = 134, 120/235, loss = 0.01511, pos_mask = 0.08909761905670166, neg_mask = 0.5215737223625183
Training @ epoch = 134, 180/235, loss = 0.01373, pos_mask = 0.051087964326143265, neg_mask = 0.5530298352241516
***********original test set **********
Accuracy: 99.11
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 81.57

Patience= -75, Time=58.50099, train_epoch_loss = 0.014290539377388802, test_epoch_acc = 81.57
                                                                                                    
Training @ epoch = 135, 0/235, loss = 0.01435, pos_mask = 0.040495723485946655, neg_mask = 0.6083403825759888
Training @ epoch = 135, 60/235, loss = 0.01386, pos_mask = 0.0462014302611351, neg_mask = 0.5804481506347656
Training @ epoch = 135, 120/235, loss = 0.01372, pos_mask = 0.04267563298344612, neg_mask = 0.5815644860267639
Training @ epoch = 135, 180/235, loss = 0.01428, pos_mask = 0.039601292461156845, neg_mask = 0.5945907235145569
***********original test set **********
Accuracy: 99.15
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 81.4

Patience= -76, Time=58.93292, train_epoch_loss = 0.01380557074270984, test_epoch_acc = 81.4
                                                                                                    
Training @ epoch = 136, 0/235, loss = 0.01368, pos_mask = 0.036237768828868866, neg_mask = 0.5991633534431458
Training @ epoch = 136, 60/235, loss = 0.01393, pos_mask = 0.04038509726524353, neg_mask = 0.5725792646408081
Training @ epoch = 136, 120/235, loss = 0.01331, pos_mask = 0.06581365317106247, neg_mask = 0.5802459120750427
Training @ epoch = 136, 180/235, loss = 0.01331, pos_mask = 0.044892653822898865, neg_mask = 0.5931391716003418
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.04
***********invariance test set **********
Accuracy: 81.96

Patience= -77, Time=59.36828, train_epoch_loss = 0.013592528432924697, test_epoch_acc = 81.96
                                                                                                    
Training @ epoch = 137, 0/235, loss = 0.01380, pos_mask = 0.03183848038315773, neg_mask = 0.6173368692398071
Training @ epoch = 137, 60/235, loss = 0.01395, pos_mask = 0.03167588263750076, neg_mask = 0.6040655374526978
Training @ epoch = 137, 120/235, loss = 0.01347, pos_mask = 0.03956080228090286, neg_mask = 0.6088565587997437
Training @ epoch = 137, 180/235, loss = 0.01338, pos_mask = 0.029997652396559715, neg_mask = 0.5868217945098877
***********original test set **********
Accuracy: 99.17
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 81.96

Patience= -78, Time=59.80244, train_epoch_loss = 0.013454555731980091, test_epoch_acc = 81.96
                                                                                                    
Training @ epoch = 138, 0/235, loss = 0.01364, pos_mask = 0.02800067886710167, neg_mask = 0.6002199649810791
Training @ epoch = 138, 60/235, loss = 0.01319, pos_mask = 0.04189600050449371, neg_mask = 0.6031274199485779
Training @ epoch = 138, 120/235, loss = 0.01371, pos_mask = 0.03564468026161194, neg_mask = 0.5927175283432007
Training @ epoch = 138, 180/235, loss = 0.01335, pos_mask = 0.03477213531732559, neg_mask = 0.5997833013534546
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 81.93

Patience= -79, Time=60.23287, train_epoch_loss = 0.013368933429901904, test_epoch_acc = 81.93
                                                                                                    
Training @ epoch = 139, 0/235, loss = 0.01294, pos_mask = 0.03774881362915039, neg_mask = 0.5972527861595154
Training @ epoch = 139, 60/235, loss = 0.01364, pos_mask = 0.02676655724644661, neg_mask = 0.6130270957946777
Training @ epoch = 139, 120/235, loss = 0.01307, pos_mask = 0.029998324811458588, neg_mask = 0.6191956996917725
Training @ epoch = 139, 180/235, loss = 0.01317, pos_mask = 0.0334894061088562, neg_mask = 0.6148380041122437
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 81.53

Patience= -80, Time=60.66239, train_epoch_loss = 0.013281326305041922, test_epoch_acc = 81.53
                                                                                                    
Training @ epoch = 140, 0/235, loss = 0.01346, pos_mask = 0.03405405208468437, neg_mask = 0.6224851608276367
Training @ epoch = 140, 60/235, loss = 0.01261, pos_mask = 0.03984317556023598, neg_mask = 0.5785905122756958
Training @ epoch = 140, 120/235, loss = 0.01314, pos_mask = 0.029981806874275208, neg_mask = 0.6052926778793335
Training @ epoch = 140, 180/235, loss = 0.01289, pos_mask = 0.024631110951304436, neg_mask = 0.6083875894546509
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 81.68

Patience= -81, Time=61.09721, train_epoch_loss = 0.013151534817161713, test_epoch_acc = 81.68
                                                                                                    
Training @ epoch = 141, 0/235, loss = 0.01336, pos_mask = 0.02787913754582405, neg_mask = 0.614761233329773
Training @ epoch = 141, 60/235, loss = 0.01380, pos_mask = 0.024553421884775162, neg_mask = 0.6143091917037964
Training @ epoch = 141, 120/235, loss = 0.01324, pos_mask = 0.04468157887458801, neg_mask = 0.5981004238128662
Training @ epoch = 141, 180/235, loss = 0.01297, pos_mask = 0.028486482799053192, neg_mask = 0.6236844062805176
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 81.51

Patience= -82, Time=61.52906, train_epoch_loss = 0.01307445718966266, test_epoch_acc = 81.51
                                                                                                    
Training @ epoch = 142, 0/235, loss = 0.01296, pos_mask = 0.03730699419975281, neg_mask = 0.5978351831436157
Training @ epoch = 142, 60/235, loss = 0.01260, pos_mask = 0.025856761261820793, neg_mask = 0.5971232652664185
Training @ epoch = 142, 120/235, loss = 0.01228, pos_mask = 0.03396342694759369, neg_mask = 0.6047452688217163
Training @ epoch = 142, 180/235, loss = 0.01263, pos_mask = 0.028853416442871094, neg_mask = 0.6164606809616089
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 81.89

Patience= -83, Time=61.96617, train_epoch_loss = 0.01299495270990945, test_epoch_acc = 81.89
                                                                                                    
Training @ epoch = 143, 0/235, loss = 0.01270, pos_mask = 0.030454881489276886, neg_mask = 0.6024932265281677
Training @ epoch = 143, 60/235, loss = 0.01266, pos_mask = 0.033297955989837646, neg_mask = 0.5927058458328247
Training @ epoch = 143, 120/235, loss = 0.01306, pos_mask = 0.028868023306131363, neg_mask = 0.6216845512390137
Training @ epoch = 143, 180/235, loss = 0.01249, pos_mask = 0.03283914178609848, neg_mask = 0.6063466668128967
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.09
***********invariance test set **********
Accuracy: 81.72

Patience= -84, Time=62.39927, train_epoch_loss = 0.012908399192259667, test_epoch_acc = 81.72
                                                                                                    
Training @ epoch = 144, 0/235, loss = 0.01262, pos_mask = 0.027761464938521385, neg_mask = 0.6074182987213135
Training @ epoch = 144, 60/235, loss = 0.01340, pos_mask = 0.021573415026068687, neg_mask = 0.6326344609260559
Training @ epoch = 144, 120/235, loss = 0.01230, pos_mask = 0.03735899180173874, neg_mask = 0.6048092842102051
Training @ epoch = 144, 180/235, loss = 0.01285, pos_mask = 0.026289593428373337, neg_mask = 0.6403112411499023
***********original test set **********
Accuracy: 99.24
***********sensitivity test set **********
Accuracy: 99.06
***********invariance test set **********
Accuracy: 81.44

Patience= -85, Time=62.82972, train_epoch_loss = 0.012807499886827266, test_epoch_acc = 81.44
                                                                                                    
Training @ epoch = 145, 0/235, loss = 0.01268, pos_mask = 0.03400566428899765, neg_mask = 0.6370342373847961
Training @ epoch = 145, 60/235, loss = 0.01293, pos_mask = 0.026957819238305092, neg_mask = 0.6057893633842468
Training @ epoch = 145, 120/235, loss = 0.01339, pos_mask = 0.02490312047302723, neg_mask = 0.605233907699585
Training @ epoch = 145, 180/235, loss = 0.01263, pos_mask = 0.030688684433698654, neg_mask = 0.6193503141403198
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.07
***********invariance test set **********
Accuracy: 80.84

Patience= -86, Time=63.26201, train_epoch_loss = 0.012736017241122876, test_epoch_acc = 80.84
                                                                                                    
Training @ epoch = 146, 0/235, loss = 0.01251, pos_mask = 0.028829459100961685, neg_mask = 0.622875452041626
Training @ epoch = 146, 60/235, loss = 0.01302, pos_mask = 0.0253317691385746, neg_mask = 0.6503852605819702
Training @ epoch = 146, 120/235, loss = 0.01271, pos_mask = 0.02699986658990383, neg_mask = 0.6152462959289551
Training @ epoch = 146, 180/235, loss = 0.01271, pos_mask = 0.027654210105538368, neg_mask = 0.6033663153648376
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.08
***********invariance test set **********
Accuracy: 81.76

Patience= -87, Time=63.69835, train_epoch_loss = 0.012650307006341345, test_epoch_acc = 81.76
                                                                                                    
Training @ epoch = 147, 0/235, loss = 0.01287, pos_mask = 0.022185342386364937, neg_mask = 0.633652925491333
Training @ epoch = 147, 60/235, loss = 0.01263, pos_mask = 0.024803031235933304, neg_mask = 0.6328546404838562
Training @ epoch = 147, 120/235, loss = 0.01272, pos_mask = 0.025096286088228226, neg_mask = 0.6236196756362915
Training @ epoch = 147, 180/235, loss = 0.01235, pos_mask = 0.02352386899292469, neg_mask = 0.6267908215522766
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 81.08

Patience= -88, Time=64.13265, train_epoch_loss = 0.012565742440997287, test_epoch_acc = 81.08
                                                                                                    
Training @ epoch = 148, 0/235, loss = 0.01222, pos_mask = 0.03340877592563629, neg_mask = 0.6270875930786133
Training @ epoch = 148, 60/235, loss = 0.01209, pos_mask = 0.029414385557174683, neg_mask = 0.6113939881324768
Training @ epoch = 148, 120/235, loss = 0.01256, pos_mask = 0.024507667869329453, neg_mask = 0.6394822597503662
Training @ epoch = 148, 180/235, loss = 0.01276, pos_mask = 0.026017777621746063, neg_mask = 0.6463078260421753
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.13
***********invariance test set **********
Accuracy: 81.04

Patience= -89, Time=64.56465, train_epoch_loss = 0.012461439004920898, test_epoch_acc = 81.04
                                                                                                    
Training @ epoch = 149, 0/235, loss = 0.01248, pos_mask = 0.033021677285432816, neg_mask = 0.6216006875038147
Training @ epoch = 149, 60/235, loss = 0.01232, pos_mask = 0.02640450745820999, neg_mask = 0.6433392763137817
Training @ epoch = 149, 120/235, loss = 0.01290, pos_mask = 0.02286001667380333, neg_mask = 0.6403981447219849
Training @ epoch = 149, 180/235, loss = 0.01275, pos_mask = 0.019162017852067947, neg_mask = 0.6327410340309143
***********original test set **********
Accuracy: 99.24
***********sensitivity test set **********
Accuracy: 99.13
***********invariance test set **********
Accuracy: 81.69

Patience= -90, Time=64.99806, train_epoch_loss = 0.012356602773070335, test_epoch_acc = 81.69
                                                                                                    
Training @ epoch = 150, 0/235, loss = 0.01160, pos_mask = 0.040132537484169006, neg_mask = 0.5840193033218384
Training @ epoch = 150, 60/235, loss = 0.01199, pos_mask = 0.031643424183130264, neg_mask = 0.624346137046814
Training @ epoch = 150, 120/235, loss = 0.01233, pos_mask = 0.018114328384399414, neg_mask = 0.637338399887085
Training @ epoch = 150, 180/235, loss = 0.01199, pos_mask = 0.02088356763124466, neg_mask = 0.6316647529602051
***********original test set **********
Accuracy: 99.21
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 81.08

Patience= -91, Time=65.42947, train_epoch_loss = 0.01225158783032539, test_epoch_acc = 81.08
                                                                                                    
Training @ epoch = 151, 0/235, loss = 0.01204, pos_mask = 0.027184709906578064, neg_mask = 0.6245651245117188
Training @ epoch = 151, 60/235, loss = 0.01176, pos_mask = 0.032471053302288055, neg_mask = 0.6131901741027832
Training @ epoch = 151, 120/235, loss = 0.01192, pos_mask = 0.02838372439146042, neg_mask = 0.6319755911827087
Training @ epoch = 151, 180/235, loss = 0.01237, pos_mask = 0.026455456390976906, neg_mask = 0.6427838802337646
***********original test set **********
Accuracy: 99.24
***********sensitivity test set **********
Accuracy: 99.12
***********invariance test set **********
Accuracy: 80.41

Patience= -92, Time=65.86141, train_epoch_loss = 0.012153881526690849, test_epoch_acc = 80.41
                                                                                                    
Training @ epoch = 152, 0/235, loss = 0.01207, pos_mask = 0.024295194074511528, neg_mask = 0.6458097100257874
Training @ epoch = 152, 60/235, loss = 0.01215, pos_mask = 0.022054722532629967, neg_mask = 0.6357607245445251
Training @ epoch = 152, 120/235, loss = 0.01215, pos_mask = 0.026636365801095963, neg_mask = 0.6403093338012695
Training @ epoch = 152, 180/235, loss = 0.01187, pos_mask = 0.02562030404806137, neg_mask = 0.6264094114303589
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.11
***********invariance test set **********
Accuracy: 80.24

Patience= -93, Time=66.29753, train_epoch_loss = 0.012063458185405173, test_epoch_acc = 80.24
                                                                                                    
Training @ epoch = 153, 0/235, loss = 0.01221, pos_mask = 0.02961484156548977, neg_mask = 0.6442244648933411
Training @ epoch = 153, 60/235, loss = 0.01170, pos_mask = 0.02179432474076748, neg_mask = 0.6182458996772766
Training @ epoch = 153, 120/235, loss = 0.01215, pos_mask = 0.022732950747013092, neg_mask = 0.6194905638694763
Training @ epoch = 153, 180/235, loss = 0.01206, pos_mask = 0.027873866260051727, neg_mask = 0.6429807543754578
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 80.11

Patience= -94, Time=66.72803, train_epoch_loss = 0.011936341515405381, test_epoch_acc = 80.11
                                                                                                    
Training @ epoch = 154, 0/235, loss = 0.01155, pos_mask = 0.026464862748980522, neg_mask = 0.6411723494529724
Training @ epoch = 154, 60/235, loss = 0.01146, pos_mask = 0.026360569521784782, neg_mask = 0.6278262138366699
Training @ epoch = 154, 120/235, loss = 0.01149, pos_mask = 0.024988345801830292, neg_mask = 0.6246784329414368
Training @ epoch = 154, 180/235, loss = 0.01250, pos_mask = 0.019495658576488495, neg_mask = 0.6481939554214478
***********original test set **********
Accuracy: 99.26
***********sensitivity test set **********
Accuracy: 99.13
***********invariance test set **********
Accuracy: 80.52

Patience= -95, Time=67.16375, train_epoch_loss = 0.011837127828534614, test_epoch_acc = 80.52
                                                                                                    
Training @ epoch = 155, 0/235, loss = 0.01182, pos_mask = 0.01707235909998417, neg_mask = 0.6423696279525757
Training @ epoch = 155, 60/235, loss = 0.01159, pos_mask = 0.01956099644303322, neg_mask = 0.6430772542953491
Training @ epoch = 155, 120/235, loss = 0.01160, pos_mask = 0.027049515396356583, neg_mask = 0.6246532201766968
Training @ epoch = 155, 180/235, loss = 0.01153, pos_mask = 0.020742585882544518, neg_mask = 0.6377578377723694
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.15
***********invariance test set **********
Accuracy: 80.53

Patience= -96, Time=67.59628, train_epoch_loss = 0.011736260402075788, test_epoch_acc = 80.53
                                                                                                    
Training @ epoch = 156, 0/235, loss = 0.01199, pos_mask = 0.026336289942264557, neg_mask = 0.6497302055358887
Training @ epoch = 156, 60/235, loss = 0.01251, pos_mask = 0.013723638840019703, neg_mask = 0.6585531234741211
Training @ epoch = 156, 120/235, loss = 0.01167, pos_mask = 0.020711898803710938, neg_mask = 0.6089308857917786
Training @ epoch = 156, 180/235, loss = 0.01183, pos_mask = 0.023974498733878136, neg_mask = 0.6486303210258484
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.12
***********invariance test set **********
Accuracy: 80.73

Patience= -97, Time=68.02947, train_epoch_loss = 0.011610492029564178, test_epoch_acc = 80.73
                                                                                                    
Training @ epoch = 157, 0/235, loss = 0.01109, pos_mask = 0.026225611567497253, neg_mask = 0.6187333464622498
Training @ epoch = 157, 60/235, loss = 0.01140, pos_mask = 0.025605134665966034, neg_mask = 0.6387580633163452
Training @ epoch = 157, 120/235, loss = 0.01157, pos_mask = 0.021116506308317184, neg_mask = 0.6300151348114014
Training @ epoch = 157, 180/235, loss = 0.01140, pos_mask = 0.024518469348549843, neg_mask = 0.656074047088623
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.13
***********invariance test set **********
Accuracy: 80.31

Patience= -98, Time=68.46155, train_epoch_loss = 0.011516497724075267, test_epoch_acc = 80.31
                                                                                                    
Training @ epoch = 158, 0/235, loss = 0.01142, pos_mask = 0.019546987488865852, neg_mask = 0.6279109716415405
Training @ epoch = 158, 60/235, loss = 0.01152, pos_mask = 0.022531380876898766, neg_mask = 0.6499617099761963
Training @ epoch = 158, 120/235, loss = 0.01128, pos_mask = 0.022868208587169647, neg_mask = 0.6286899447441101
Training @ epoch = 158, 180/235, loss = 0.01121, pos_mask = 0.02043958194553852, neg_mask = 0.6274514198303223
***********original test set **********
Accuracy: 99.25
***********sensitivity test set **********
Accuracy: 99.09
***********invariance test set **********
Accuracy: 80.88

Patience= -99, Time=68.89404, train_epoch_loss = 0.011405307331934888, test_epoch_acc = 80.88
                                                                                                    
Training @ epoch = 159, 0/235, loss = 0.01141, pos_mask = 0.023821279406547546, neg_mask = 0.624809205532074
Training @ epoch = 159, 60/235, loss = 0.01104, pos_mask = 0.02225147932767868, neg_mask = 0.6282936334609985
Training @ epoch = 159, 120/235, loss = 0.01108, pos_mask = 0.0265951044857502, neg_mask = 0.6439952254295349
Training @ epoch = 159, 180/235, loss = 0.01112, pos_mask = 0.028496865183115005, neg_mask = 0.6191439628601074
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 79.43

Patience= -100, Time=69.32684, train_epoch_loss = 0.011359090306498903, test_epoch_acc = 79.43
                                                                                                    
Training @ epoch = 160, 0/235, loss = 0.01119, pos_mask = 0.0204094797372818, neg_mask = 0.6452657580375671
Training @ epoch = 160, 60/235, loss = 0.01139, pos_mask = 0.02625586837530136, neg_mask = 0.6298555135726929
Training @ epoch = 160, 120/235, loss = 0.01079, pos_mask = 0.034987203776836395, neg_mask = 0.6266082525253296
Training @ epoch = 160, 180/235, loss = 0.01096, pos_mask = 0.021102629601955414, neg_mask = 0.6356054544448853
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.12
***********invariance test set **********
Accuracy: 80.18

Patience= -101, Time=69.76213, train_epoch_loss = 0.011209702075637401, test_epoch_acc = 80.18
                                                                                                    
Training @ epoch = 161, 0/235, loss = 0.01096, pos_mask = 0.0290907621383667, neg_mask = 0.6109203696250916
Training @ epoch = 161, 60/235, loss = 0.01146, pos_mask = 0.015974681824445724, neg_mask = 0.6400963068008423
Training @ epoch = 161, 120/235, loss = 0.01080, pos_mask = 0.021176951006054878, neg_mask = 0.6333741545677185
Training @ epoch = 161, 180/235, loss = 0.01067, pos_mask = 0.0330585241317749, neg_mask = 0.6215696334838867
***********original test set **********
Accuracy: 98.56
***********sensitivity test set **********
Accuracy: 98.28
***********invariance test set **********
Accuracy: 73.17

Patience= -102, Time=70.19445, train_epoch_loss = 0.014274749159812927, test_epoch_acc = 73.17
                                                                                                    
Training @ epoch = 162, 0/235, loss = 0.04731, pos_mask = 0.16009700298309326, neg_mask = 0.44046059250831604
Training @ epoch = 162, 60/235, loss = 0.02714, pos_mask = 0.09085288643836975, neg_mask = 0.44606146216392517
Training @ epoch = 162, 120/235, loss = 0.02029, pos_mask = 0.08858665823936462, neg_mask = 0.5474543571472168
Training @ epoch = 162, 180/235, loss = 0.01680, pos_mask = 0.09774843603372574, neg_mask = 0.510568380355835
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.03
***********invariance test set **********
Accuracy: 83.04

Patience= -103, Time=70.62663, train_epoch_loss = 0.027501305870394756, test_epoch_acc = 83.04
                                                                                                    
Training @ epoch = 163, 0/235, loss = 0.01375, pos_mask = 0.045073896646499634, neg_mask = 0.5928000211715698
Training @ epoch = 163, 60/235, loss = 0.01315, pos_mask = 0.06450389325618744, neg_mask = 0.5301145315170288
Training @ epoch = 163, 120/235, loss = 0.01212, pos_mask = 0.06192865967750549, neg_mask = 0.5447609424591064
Training @ epoch = 163, 180/235, loss = 0.01206, pos_mask = 0.05246957764029503, neg_mask = 0.5847835540771484
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 83.36

Patience= -104, Time=71.06280, train_epoch_loss = 0.012661779687759724, test_epoch_acc = 83.36
                                                                                                    
Training @ epoch = 164, 0/235, loss = 0.01160, pos_mask = 0.03484129160642624, neg_mask = 0.6012278199195862
Training @ epoch = 164, 60/235, loss = 0.01162, pos_mask = 0.032501038163900375, neg_mask = 0.5971002578735352
Training @ epoch = 164, 120/235, loss = 0.01192, pos_mask = 0.04000695049762726, neg_mask = 0.603148877620697
Training @ epoch = 164, 180/235, loss = 0.01163, pos_mask = 0.05122291296720505, neg_mask = 0.5974711179733276
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.15
***********invariance test set **********
Accuracy: 83.23

Patience= -105, Time=71.49578, train_epoch_loss = 0.011747025421008151, test_epoch_acc = 83.23
                                                                                                    
Training @ epoch = 165, 0/235, loss = 0.01180, pos_mask = 0.04683581367135048, neg_mask = 0.5824382305145264
Training @ epoch = 165, 60/235, loss = 0.01096, pos_mask = 0.036525122821331024, neg_mask = 0.5989829301834106
Training @ epoch = 165, 120/235, loss = 0.01206, pos_mask = 0.029470881447196007, neg_mask = 0.6026927828788757
Training @ epoch = 165, 180/235, loss = 0.01208, pos_mask = 0.032066673040390015, neg_mask = 0.6147153973579407
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.15
***********invariance test set **********
Accuracy: 82.87

Patience= -106, Time=71.92729, train_epoch_loss = 0.011507376723308512, test_epoch_acc = 82.87
                                                                                                    
Training @ epoch = 166, 0/235, loss = 0.01139, pos_mask = 0.03998839482665062, neg_mask = 0.5816362500190735
Training @ epoch = 166, 60/235, loss = 0.01115, pos_mask = 0.03668989986181259, neg_mask = 0.5973027944564819
Training @ epoch = 166, 120/235, loss = 0.01143, pos_mask = 0.03236844763159752, neg_mask = 0.6211450099945068
Training @ epoch = 166, 180/235, loss = 0.01179, pos_mask = 0.029187824577093124, neg_mask = 0.6298922300338745
***********original test set **********
Accuracy: 99.28
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 82.99

Patience= -107, Time=72.36582, train_epoch_loss = 0.011386026200303372, test_epoch_acc = 82.99
                                                                                                    
Training @ epoch = 167, 0/235, loss = 0.01110, pos_mask = 0.041463546454906464, neg_mask = 0.5857219696044922
Training @ epoch = 167, 60/235, loss = 0.01168, pos_mask = 0.02822321280837059, neg_mask = 0.6258760690689087
Training @ epoch = 167, 120/235, loss = 0.01130, pos_mask = 0.03414977714419365, neg_mask = 0.6039175391197205
Training @ epoch = 167, 180/235, loss = 0.01087, pos_mask = 0.039479002356529236, neg_mask = 0.5941729545593262
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.16
***********invariance test set **********
Accuracy: 82.99

Patience= -108, Time=72.79778, train_epoch_loss = 0.011295299426196738, test_epoch_acc = 82.99
                                                                                                    
Training @ epoch = 168, 0/235, loss = 0.01129, pos_mask = 0.043572038412094116, neg_mask = 0.6072936058044434
Training @ epoch = 168, 60/235, loss = 0.01088, pos_mask = 0.03386273607611656, neg_mask = 0.6029620170593262
Training @ epoch = 168, 120/235, loss = 0.01138, pos_mask = 0.028226355090737343, neg_mask = 0.6230508089065552
Training @ epoch = 168, 180/235, loss = 0.01061, pos_mask = 0.03327040746808052, neg_mask = 0.5977337956428528
***********original test set **********
Accuracy: 99.28
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 82.34

Patience= -109, Time=73.23631, train_epoch_loss = 0.011192736996615186, test_epoch_acc = 82.34
                                                                                                    
Training @ epoch = 169, 0/235, loss = 0.01139, pos_mask = 0.02473779395222664, neg_mask = 0.6383897066116333
Training @ epoch = 169, 60/235, loss = 0.01125, pos_mask = 0.02547597512602806, neg_mask = 0.639693558216095
Training @ epoch = 169, 120/235, loss = 0.01074, pos_mask = 0.03553847223520279, neg_mask = 0.6090510487556458
Training @ epoch = 169, 180/235, loss = 0.01052, pos_mask = 0.038055215030908585, neg_mask = 0.5731750726699829
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 82.34

Patience= -110, Time=73.67387, train_epoch_loss = 0.011100518980875928, test_epoch_acc = 82.34
                                                                                                    
Training @ epoch = 170, 0/235, loss = 0.01105, pos_mask = 0.022102370858192444, neg_mask = 0.6088056564331055
Training @ epoch = 170, 60/235, loss = 0.01135, pos_mask = 0.02811841294169426, neg_mask = 0.6247742176055908
Training @ epoch = 170, 120/235, loss = 0.01081, pos_mask = 0.03258919343352318, neg_mask = 0.6225820779800415
Training @ epoch = 170, 180/235, loss = 0.01098, pos_mask = 0.03903655335307121, neg_mask = 0.578707218170166
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.13
***********invariance test set **********
Accuracy: 82.17

Patience= -111, Time=74.10346, train_epoch_loss = 0.011055453628935712, test_epoch_acc = 82.17
                                                                                                    
Training @ epoch = 171, 0/235, loss = 0.01128, pos_mask = 0.02505955845117569, neg_mask = 0.6475046873092651
Training @ epoch = 171, 60/235, loss = 0.01090, pos_mask = 0.03838936239480972, neg_mask = 0.6056177616119385
Training @ epoch = 171, 120/235, loss = 0.01097, pos_mask = 0.02768012136220932, neg_mask = 0.6353373527526855
Training @ epoch = 171, 180/235, loss = 0.01117, pos_mask = 0.029803402721881866, neg_mask = 0.6383087635040283
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 82.46

Patience= -112, Time=74.53783, train_epoch_loss = 0.010961335730996538, test_epoch_acc = 82.46
                                                                                                    
Training @ epoch = 172, 0/235, loss = 0.01125, pos_mask = 0.024387497454881668, neg_mask = 0.6255146265029907
Training @ epoch = 172, 60/235, loss = 0.01066, pos_mask = 0.030656034126877785, neg_mask = 0.6134967803955078
Training @ epoch = 172, 120/235, loss = 0.01045, pos_mask = 0.03940354287624359, neg_mask = 0.5927985906600952
Training @ epoch = 172, 180/235, loss = 0.01118, pos_mask = 0.03075346164405346, neg_mask = 0.6003350019454956
***********original test set **********
Accuracy: 99.28
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 81.92

Patience= -113, Time=74.97057, train_epoch_loss = 0.010912415044421845, test_epoch_acc = 81.92
                                                                                                    
Training @ epoch = 173, 0/235, loss = 0.01072, pos_mask = 0.019752271473407745, neg_mask = 0.6351466774940491
Training @ epoch = 173, 60/235, loss = 0.01048, pos_mask = 0.032650504261255264, neg_mask = 0.6112356781959534
Training @ epoch = 173, 120/235, loss = 0.01053, pos_mask = 0.02593328431248665, neg_mask = 0.6364635229110718
Training @ epoch = 173, 180/235, loss = 0.01080, pos_mask = 0.02467259019613266, neg_mask = 0.6076964139938354
***********original test set **********
Accuracy: 99.3
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 81.77

Patience= -114, Time=75.40464, train_epoch_loss = 0.01084022278243557, test_epoch_acc = 81.77
                                                                                                    
Training @ epoch = 174, 0/235, loss = 0.01037, pos_mask = 0.030810827389359474, neg_mask = 0.6058692932128906
Training @ epoch = 174, 60/235, loss = 0.01065, pos_mask = 0.024346131831407547, neg_mask = 0.6167843341827393
Training @ epoch = 174, 120/235, loss = 0.01107, pos_mask = 0.025561701506376266, neg_mask = 0.6603609323501587
Training @ epoch = 174, 180/235, loss = 0.01039, pos_mask = 0.02894783951342106, neg_mask = 0.6197888851165771
***********original test set **********
Accuracy: 99.28
***********sensitivity test set **********
Accuracy: 99.13
***********invariance test set **********
Accuracy: 81.52

Patience= -115, Time=75.83811, train_epoch_loss = 0.01079424550320874, test_epoch_acc = 81.52
                                                                                                    
Training @ epoch = 175, 0/235, loss = 0.01046, pos_mask = 0.03246018663048744, neg_mask = 0.6086851358413696
Training @ epoch = 175, 60/235, loss = 0.01094, pos_mask = 0.030067957937717438, neg_mask = 0.6585962772369385
Training @ epoch = 175, 120/235, loss = 0.01050, pos_mask = 0.030181746929883957, neg_mask = 0.6348488330841064
Training @ epoch = 175, 180/235, loss = 0.01133, pos_mask = 0.020524755120277405, neg_mask = 0.647587776184082
***********original test set **********
Accuracy: 99.28
***********sensitivity test set **********
Accuracy: 99.16
***********invariance test set **********
Accuracy: 81.72

Patience= -116, Time=76.26834, train_epoch_loss = 0.010736878402531147, test_epoch_acc = 81.72
                                                                                                    
Training @ epoch = 176, 0/235, loss = 0.01090, pos_mask = 0.028706859797239304, neg_mask = 0.6265024542808533
Training @ epoch = 176, 60/235, loss = 0.01039, pos_mask = 0.04091871902346611, neg_mask = 0.6024882793426514
Training @ epoch = 176, 120/235, loss = 0.01046, pos_mask = 0.022834641858935356, neg_mask = 0.6295327544212341
Training @ epoch = 176, 180/235, loss = 0.01069, pos_mask = 0.027530759572982788, neg_mask = 0.631447434425354
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 81.81

Patience= -117, Time=76.70210, train_epoch_loss = 0.010664163422869875, test_epoch_acc = 81.81
                                                                                                    
Training @ epoch = 177, 0/235, loss = 0.01074, pos_mask = 0.021787971258163452, neg_mask = 0.6569833755493164
Training @ epoch = 177, 60/235, loss = 0.01015, pos_mask = 0.02977525070309639, neg_mask = 0.6137627363204956
Training @ epoch = 177, 120/235, loss = 0.01052, pos_mask = 0.03369499742984772, neg_mask = 0.6166599988937378
Training @ epoch = 177, 180/235, loss = 0.01086, pos_mask = 0.020166713744401932, neg_mask = 0.6503382921218872
***********original test set **********
Accuracy: 99.28
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 81.37

Patience= -118, Time=77.13771, train_epoch_loss = 0.010582415482148212, test_epoch_acc = 81.37
                                                                                                    
Training @ epoch = 178, 0/235, loss = 0.01016, pos_mask = 0.028886497020721436, neg_mask = 0.6156643629074097
Training @ epoch = 178, 60/235, loss = 0.01026, pos_mask = 0.028427964076399803, neg_mask = 0.6188657283782959
Training @ epoch = 178, 120/235, loss = 0.01084, pos_mask = 0.02140231989324093, neg_mask = 0.6493502855300903
Training @ epoch = 178, 180/235, loss = 0.01053, pos_mask = 0.021961744874715805, neg_mask = 0.6306161880493164
***********original test set **********
Accuracy: 99.28
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 81.71

Patience= -119, Time=77.57180, train_epoch_loss = 0.010543813294869787, test_epoch_acc = 81.71
                                                                                                    
Training @ epoch = 179, 0/235, loss = 0.01055, pos_mask = 0.029213394969701767, neg_mask = 0.6340193152427673
Training @ epoch = 179, 60/235, loss = 0.01039, pos_mask = 0.02949296124279499, neg_mask = 0.6220345497131348
Training @ epoch = 179, 120/235, loss = 0.01020, pos_mask = 0.027638912200927734, neg_mask = 0.6265906691551208
Training @ epoch = 179, 180/235, loss = 0.01006, pos_mask = 0.02463315799832344, neg_mask = 0.6235119104385376
***********original test set **********
Accuracy: 99.28
***********sensitivity test set **********
Accuracy: 99.13
***********invariance test set **********
Accuracy: 81.71

Patience= -120, Time=78.00582, train_epoch_loss = 0.010466420507811486, test_epoch_acc = 81.71
                                                                                                    
Training @ epoch = 180, 0/235, loss = 0.01101, pos_mask = 0.015207519754767418, neg_mask = 0.6672204732894897
Training @ epoch = 180, 60/235, loss = 0.01042, pos_mask = 0.021724140271544456, neg_mask = 0.6394182443618774
Training @ epoch = 180, 120/235, loss = 0.01039, pos_mask = 0.0249052494764328, neg_mask = 0.6284171342849731
Training @ epoch = 180, 180/235, loss = 0.01071, pos_mask = 0.021685434505343437, neg_mask = 0.6520769596099854
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 81.78

Patience= -121, Time=78.43757, train_epoch_loss = 0.010407903822178537, test_epoch_acc = 81.78
                                                                                                    
Training @ epoch = 181, 0/235, loss = 0.01009, pos_mask = 0.026810500770807266, neg_mask = 0.6218185424804688
Training @ epoch = 181, 60/235, loss = 0.01003, pos_mask = 0.020695995539426804, neg_mask = 0.6555646061897278
Training @ epoch = 181, 120/235, loss = 0.01041, pos_mask = 0.02154470607638359, neg_mask = 0.6301413178443909
Training @ epoch = 181, 180/235, loss = 0.00982, pos_mask = 0.035369351506233215, neg_mask = 0.6162126660346985
***********original test set **********
Accuracy: 99.25
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 80.44

Patience= -122, Time=78.87150, train_epoch_loss = 0.010315163140284253, test_epoch_acc = 80.44
                                                                                                    
Training @ epoch = 182, 0/235, loss = 0.00981, pos_mask = 0.021396197378635406, neg_mask = 0.6323279738426208
Training @ epoch = 182, 60/235, loss = 0.01073, pos_mask = 0.017598746344447136, neg_mask = 0.6535123586654663
Training @ epoch = 182, 120/235, loss = 0.01032, pos_mask = 0.026837637647986412, neg_mask = 0.6502158641815186
Training @ epoch = 182, 180/235, loss = 0.01023, pos_mask = 0.02051411382853985, neg_mask = 0.6587197780609131
***********original test set **********
Accuracy: 99.28
***********sensitivity test set **********
Accuracy: 99.15
***********invariance test set **********
Accuracy: 81.0

Patience= -123, Time=79.30515, train_epoch_loss = 0.010251011992705629, test_epoch_acc = 81.0
                                                                                                    
Training @ epoch = 183, 0/235, loss = 0.01018, pos_mask = 0.0152402613312006, neg_mask = 0.6436151266098022
Training @ epoch = 183, 60/235, loss = 0.00988, pos_mask = 0.02554657682776451, neg_mask = 0.6426700353622437
Training @ epoch = 183, 120/235, loss = 0.00988, pos_mask = 0.02497754618525505, neg_mask = 0.6389056444168091
Training @ epoch = 183, 180/235, loss = 0.01009, pos_mask = 0.023382533341646194, neg_mask = 0.6275029182434082
***********original test set **********
Accuracy: 99.26
***********sensitivity test set **********
Accuracy: 99.16
***********invariance test set **********
Accuracy: 80.29

Patience= -124, Time=79.73740, train_epoch_loss = 0.010182516970374483, test_epoch_acc = 80.29
                                                                                                    
Training @ epoch = 184, 0/235, loss = 0.01013, pos_mask = 0.02107309177517891, neg_mask = 0.6441800594329834
Training @ epoch = 184, 60/235, loss = 0.01056, pos_mask = 0.014758965000510216, neg_mask = 0.6552895307540894
Training @ epoch = 184, 120/235, loss = 0.00994, pos_mask = 0.022204779088497162, neg_mask = 0.626846969127655
Training @ epoch = 184, 180/235, loss = 0.00993, pos_mask = 0.020610909909009933, neg_mask = 0.6472165584564209
***********original test set **********
Accuracy: 99.23
***********sensitivity test set **********
Accuracy: 99.13
***********invariance test set **********
Accuracy: 80.71

Patience= -125, Time=80.17160, train_epoch_loss = 0.01011423007684185, test_epoch_acc = 80.71
                                                                                                    
Training @ epoch = 185, 0/235, loss = 0.01005, pos_mask = 0.018176082521677017, neg_mask = 0.6523662805557251
Training @ epoch = 185, 60/235, loss = 0.00963, pos_mask = 0.024874411523342133, neg_mask = 0.6266797780990601
Training @ epoch = 185, 120/235, loss = 0.00956, pos_mask = 0.024646209552884102, neg_mask = 0.6324664950370789
Training @ epoch = 185, 180/235, loss = 0.00990, pos_mask = 0.02087859809398651, neg_mask = 0.6283547282218933
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.15
***********invariance test set **********
Accuracy: 81.07

Patience= -126, Time=80.60312, train_epoch_loss = 0.010034862196350351, test_epoch_acc = 81.07
                                                                                                    
Training @ epoch = 186, 0/235, loss = 0.01041, pos_mask = 0.016628118231892586, neg_mask = 0.6465355157852173
Training @ epoch = 186, 60/235, loss = 0.01062, pos_mask = 0.015744809061288834, neg_mask = 0.6689270734786987
Training @ epoch = 186, 120/235, loss = 0.00999, pos_mask = 0.014962680637836456, neg_mask = 0.6457480192184448
Training @ epoch = 186, 180/235, loss = 0.01026, pos_mask = 0.01776619255542755, neg_mask = 0.6677956581115723
***********original test set **********
Accuracy: 99.24
***********sensitivity test set **********
Accuracy: 99.12
***********invariance test set **********
Accuracy: 80.41

Patience= -127, Time=81.03472, train_epoch_loss = 0.00996548649954035, test_epoch_acc = 80.41
                                                                                                    
Training @ epoch = 187, 0/235, loss = 0.00992, pos_mask = 0.01990870013833046, neg_mask = 0.646324634552002
Training @ epoch = 187, 60/235, loss = 0.00989, pos_mask = 0.025618774816393852, neg_mask = 0.6540800333023071
Training @ epoch = 187, 120/235, loss = 0.01009, pos_mask = 0.021764487028121948, neg_mask = 0.6657515168190002
Training @ epoch = 187, 180/235, loss = 0.00958, pos_mask = 0.020521387457847595, neg_mask = 0.6561615467071533
***********original test set **********
Accuracy: 99.28
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 81.06

Patience= -128, Time=81.46751, train_epoch_loss = 0.009856790240774764, test_epoch_acc = 81.06
                                                                                                    
Training @ epoch = 188, 0/235, loss = 0.00979, pos_mask = 0.017704641446471214, neg_mask = 0.6549109220504761
Training @ epoch = 188, 60/235, loss = 0.00945, pos_mask = 0.02134016528725624, neg_mask = 0.6542218923568726
Training @ epoch = 188, 120/235, loss = 0.00941, pos_mask = 0.020589817315340042, neg_mask = 0.6419028043746948
Training @ epoch = 188, 180/235, loss = 0.01011, pos_mask = 0.02014804817736149, neg_mask = 0.6460872888565063
***********original test set **********
Accuracy: 99.22
***********sensitivity test set **********
Accuracy: 99.18
***********invariance test set **********
Accuracy: 79.9

Patience= -129, Time=81.89983, train_epoch_loss = 0.009783527045015325, test_epoch_acc = 79.9
                                                                                                    
Training @ epoch = 189, 0/235, loss = 0.00963, pos_mask = 0.01945902220904827, neg_mask = 0.6370534896850586
Training @ epoch = 189, 60/235, loss = 0.00986, pos_mask = 0.021742835640907288, neg_mask = 0.6668633222579956
Training @ epoch = 189, 120/235, loss = 0.00986, pos_mask = 0.0160276610404253, neg_mask = 0.669776439666748
Training @ epoch = 189, 180/235, loss = 0.00938, pos_mask = 0.022829188033938408, neg_mask = 0.646582305431366
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.19
***********invariance test set **********
Accuracy: 80.12

Patience= -130, Time=82.32943, train_epoch_loss = 0.009710201006779011, test_epoch_acc = 80.12
                                                                                                    
Training @ epoch = 190, 0/235, loss = 0.00910, pos_mask = 0.0236796997487545, neg_mask = 0.6475316882133484
Training @ epoch = 190, 60/235, loss = 0.00974, pos_mask = 0.01645592600107193, neg_mask = 0.6483363509178162
Training @ epoch = 190, 120/235, loss = 0.00939, pos_mask = 0.016716377809643745, neg_mask = 0.640267014503479
Training @ epoch = 190, 180/235, loss = 0.00933, pos_mask = 0.01855912059545517, neg_mask = 0.6454820036888123
***********original test set **********
Accuracy: 99.27
***********sensitivity test set **********
Accuracy: 99.14
***********invariance test set **********
Accuracy: 80.02

Patience= -131, Time=82.75828, train_epoch_loss = 0.009623168515873717, test_epoch_acc = 80.02
                                                                                                    
Training @ epoch = 191, 0/235, loss = 0.00927, pos_mask = 0.016321612522006035, neg_mask = 0.6514939069747925
Training @ epoch = 191, 60/235, loss = 0.00909, pos_mask = 0.026242416352033615, neg_mask = 0.6194497346878052
Training @ epoch = 191, 120/235, loss = 0.00918, pos_mask = 0.030490340664982796, neg_mask = 0.6410682201385498
Training @ epoch = 191, 180/235, loss = 0.00927, pos_mask = 0.01982269436120987, neg_mask = 0.6358686089515686
***********original test set **********
Accuracy: 99.28
***********sensitivity test set **********
Accuracy: 99.13
***********invariance test set **********
Accuracy: 79.82

Patience= -132, Time=83.19481, train_epoch_loss = 0.009539071086080785, test_epoch_acc = 79.82
                                                                                                    
Training @ epoch = 192, 0/235, loss = 0.00943, pos_mask = 0.01834905706346035, neg_mask = 0.6470857858657837
Training @ epoch = 192, 60/235, loss = 0.00923, pos_mask = 0.02168242260813713, neg_mask = 0.6112397909164429
Training @ epoch = 192, 120/235, loss = 0.00952, pos_mask = 0.018412403762340546, neg_mask = 0.6716176271438599
Training @ epoch = 192, 180/235, loss = 0.00948, pos_mask = 0.015112243592739105, neg_mask = 0.6451770067214966
***********original test set **********
Accuracy: 99.24
***********sensitivity test set **********
Accuracy: 99.11
***********invariance test set **********
Accuracy: 80.14

Patience= -133, Time=83.62828, train_epoch_loss = 0.009481117394851878, test_epoch_acc = 80.14
                                                                                                    
Training @ epoch = 193, 0/235, loss = 0.00938, pos_mask = 0.02048572525382042, neg_mask = 0.6370804309844971
Training @ epoch = 193, 60/235, loss = 0.00978, pos_mask = 0.015493839047849178, neg_mask = 0.6716617345809937
Training @ epoch = 193, 120/235, loss = 0.00980, pos_mask = 0.013731120154261589, neg_mask = 0.6528493762016296
Training @ epoch = 193, 180/235, loss = 0.00936, pos_mask = 0.01569654792547226, neg_mask = 0.6593079566955566
***********original test set **********
Accuracy: 99.16
***********sensitivity test set **********
Accuracy: 99.16
***********invariance test set **********
Accuracy: 78.84

Patience= -134, Time=84.05621, train_epoch_loss = 0.009398904688497807, test_epoch_acc = 78.84
                                                                                                    
Training @ epoch = 194, 0/235, loss = 0.00941, pos_mask = 0.030412986874580383, neg_mask = 0.6121310591697693
Training @ epoch = 194, 60/235, loss = 0.01974, pos_mask = 0.11935485899448395, neg_mask = 0.44950735569000244
Training @ epoch = 194, 120/235, loss = 0.01325, pos_mask = 0.07668943703174591, neg_mask = 0.4522777199745178
Training @ epoch = 194, 180/235, loss = 0.01218, pos_mask = 0.05210199952125549, neg_mask = 0.5628609657287598
***********original test set **********
Accuracy: 99.04
***********sensitivity test set **********
Accuracy: 98.83
***********invariance test set **********
Accuracy: 78.42

Patience= -135, Time=84.48877, train_epoch_loss = 0.025566434206322153, test_epoch_acc = 78.42
                                                                                                    
Training @ epoch = 195, 0/235, loss = 0.01115, pos_mask = 0.06770618259906769, neg_mask = 0.5529259443283081
Training @ epoch = 195, 60/235, loss = 0.01003, pos_mask = 0.036409806460142136, neg_mask = 0.5729684233665466
Training @ epoch = 195, 120/235, loss = 0.01052, pos_mask = 0.03096979670226574, neg_mask = 0.6190563440322876
Training @ epoch = 195, 180/235, loss = 0.01019, pos_mask = 0.03284430503845215, neg_mask = 0.5971766710281372
***********original test set **********
Accuracy: 99.14
***********sensitivity test set **********
Accuracy: 99.05
***********invariance test set **********
Accuracy: 81.81

Patience= -136, Time=84.92039, train_epoch_loss = 0.011027561433296255, test_epoch_acc = 81.81
                                                                                                    
Training @ epoch = 196, 0/235, loss = 0.00991, pos_mask = 0.04398142546415329, neg_mask = 0.6014804840087891
Training @ epoch = 196, 60/235, loss = 0.01039, pos_mask = 0.02958700805902481, neg_mask = 0.6117422580718994
Training @ epoch = 196, 120/235, loss = 0.00997, pos_mask = 0.04328269511461258, neg_mask = 0.6061818599700928
Training @ epoch = 196, 180/235, loss = 0.00947, pos_mask = 0.04216648265719414, neg_mask = 0.5937996506690979
***********original test set **********
Accuracy: 99.2
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 82.32

Patience= -137, Time=85.35452, train_epoch_loss = 0.00996762067079544, test_epoch_acc = 82.32
                                                                                                    
Training @ epoch = 197, 0/235, loss = 0.01005, pos_mask = 0.03758404403924942, neg_mask = 0.6059436798095703
Training @ epoch = 197, 60/235, loss = 0.00982, pos_mask = 0.02927243895828724, neg_mask = 0.6129571199417114
Training @ epoch = 197, 120/235, loss = 0.00935, pos_mask = 0.03291443735361099, neg_mask = 0.5856513977050781
Training @ epoch = 197, 180/235, loss = 0.00968, pos_mask = 0.024143517017364502, neg_mask = 0.6301935911178589
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.09
***********invariance test set **********
Accuracy: 82.54

Patience= -138, Time=85.78631, train_epoch_loss = 0.009746555084402257, test_epoch_acc = 82.54
                                                                                                    
Training @ epoch = 198, 0/235, loss = 0.00969, pos_mask = 0.02999398484826088, neg_mask = 0.6039819717407227
Training @ epoch = 198, 60/235, loss = 0.00968, pos_mask = 0.02623428776860237, neg_mask = 0.6176121234893799
Training @ epoch = 198, 120/235, loss = 0.00988, pos_mask = 0.026187747716903687, neg_mask = 0.6298476457595825
Training @ epoch = 198, 180/235, loss = 0.00950, pos_mask = 0.03998395428061485, neg_mask = 0.6067155599594116
***********original test set **********
Accuracy: 99.18
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 82.56

Patience= -139, Time=86.21808, train_epoch_loss = 0.009656750339459865, test_epoch_acc = 82.56
                                                                                                    
Training @ epoch = 199, 0/235, loss = 0.00953, pos_mask = 0.027860159054398537, neg_mask = 0.6303712725639343
Training @ epoch = 199, 60/235, loss = 0.00966, pos_mask = 0.03662556782364845, neg_mask = 0.623183012008667
Training @ epoch = 199, 120/235, loss = 0.00978, pos_mask = 0.03075287863612175, neg_mask = 0.6061500310897827
Training @ epoch = 199, 180/235, loss = 0.00925, pos_mask = 0.03403615206480026, neg_mask = 0.6167786121368408
***********original test set **********
Accuracy: 99.19
***********sensitivity test set **********
Accuracy: 99.1
***********invariance test set **********
Accuracy: 82.83

Patience= -140, Time=86.64700, train_epoch_loss = 0.009543488297532213, test_epoch_acc = 82.83
                                                                                                    
*****Plotting embeddings at iter: 100****
Finished Training in: 86.66755!!
